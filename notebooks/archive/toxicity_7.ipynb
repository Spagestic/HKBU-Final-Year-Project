{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1f368d-ac24-44a9-ba9a-6f038b857511",
   "metadata": {},
   "source": [
    "Toxicity Dataset : https://archive.ics.uci.edu/dataset/728/toxicity-2\n",
    "\n",
    "The dataset includes 171 molecules designed for functional domains of a core clock protein, CRY1, responsible for generating circadian rhythm. 56 of the molecules are toxic and the rest are non-toxic. \n",
    "\n",
    "The data consists a complete set of 1203 molecular descriptors and needs feature selection before classification since some of the features are redundant. \n",
    "\n",
    "Introductory Paper:\n",
    "Structure-based design and classifications of small molecules regulating the circadian rhythm period\n",
    "By Seref Gul, F. Rahim, Safak Isin, Fatma Yilmaz, Nuri Ozturk, M. Turkay, I. Kavakli. 2021\n",
    "https://www.semanticscholar.org/paper/Structure-based-design-and-classifications-of-small-Gul-Rahim/5944836c47bc7d1a2b0464a9a1db94d4bc7f28ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a0694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:17.583532Z",
     "iopub.status.busy": "2025-11-03T07:26:17.583176Z",
     "iopub.status.idle": "2025-11-03T07:26:19.512616Z",
     "shell.execute_reply": "2025-11-03T07:26:19.511653Z",
     "shell.execute_reply.started": "2025-11-03T07:26:17.583494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f67d9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.514610Z",
     "iopub.status.busy": "2025-11-03T07:26:19.514207Z",
     "iopub.status.idle": "2025-11-03T07:26:19.632741Z",
     "shell.execute_reply": "2025-11-03T07:26:19.631668Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.514584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (171, 1204)\n",
      "Class distribution:\n",
      "Class\n",
      "NonToxic    115\n",
      "Toxic        56\n",
      "Name: count, dtype: int64\n",
      "Class balance:\n",
      "Class\n",
      "NonToxic    0.672515\n",
      "Toxic       0.327485\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"/kaggle/input/toxicity/data.csv\")\n",
    "X = data.drop('Class', axis=1) if 'Class' in data.columns else data.iloc[:, :-1]\n",
    "y = data['Class'] if 'Class' in data.columns else data.iloc[:, -1]\n",
    "y_binary = (y == 'NonToxic').astype(int)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Class distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Class balance:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a982a9bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.634102Z",
     "iopub.status.busy": "2025-11-03T07:26:19.633695Z",
     "iopub.status.idle": "2025-11-03T07:26:19.649890Z",
     "shell.execute_reply": "2025-11-03T07:26:19.648665Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.634071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Shuffle and split\n",
    "np.random.seed(42)\n",
    "shuffle_idx = np.random.permutation(len(X))\n",
    "X_shuffled, y_shuffled = X.iloc[shuffle_idx].reset_index(drop=True), y_binary.iloc[shuffle_idx].reset_index(drop=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=42, stratify=y_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdded5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.652557Z",
     "iopub.status.busy": "2025-11-03T07:26:19.652233Z",
     "iopub.status.idle": "2025-11-03T07:26:19.723027Z",
     "shell.execute_reply": "2025-11-03T07:26:19.721867Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.652519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a36dc4e-af1a-4df2-9503-82c9db4ed502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.724236Z",
     "iopub.status.busy": "2025-11-03T07:26:19.723960Z",
     "iopub.status.idle": "2025-11-03T07:26:19.730824Z",
     "shell.execute_reply": "2025-11-03T07:26:19.729309Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.724215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (136, 1203), Test set: (35, 1203)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set: {X_train_scaled.shape}, Test set: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ccabd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.732369Z",
     "iopub.status.busy": "2025-11-03T07:26:19.731686Z",
     "iopub.status.idle": "2025-11-03T07:26:19.752862Z",
     "shell.execute_reply": "2025-11-03T07:26:19.751741Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.732335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(penalty=None, max_iter=2000, solver='lbfgs'),\n",
    "    'Ridge LR (L2)': LogisticRegression(penalty='l2', max_iter=2000, solver='lbfgs', C=1.0),\n",
    "    'Lasso LR (L1)': LogisticRegression(penalty='l1', max_iter=2000, solver='saga', C=1.0),\n",
    "    'Elastic Net LR': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=2000, C=1.0),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False, max_depth=3, n_estimators=100),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7e3b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.754300Z",
     "iopub.status.busy": "2025-11-03T07:26:19.753933Z",
     "iopub.status.idle": "2025-11-03T07:26:19.781390Z",
     "shell.execute_reply": "2025-11-03T07:26:19.780205Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.754274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Evaluate a classification model and return metrics\"\"\"\n",
    "    X_train_selected, X_test_selected = X_train, X_test\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_selected)\n",
    "    y_test_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # Probabilities\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_train_proba = model.predict_proba(X_train_selected)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    else:\n",
    "        y_train_proba = model.decision_function(X_train_selected)\n",
    "        y_test_proba = model.decision_function(X_test_selected)\n",
    "    \n",
    "    return {\n",
    "        'train_acc': accuracy_score(y_train, y_train_pred),\n",
    "        'test_acc': accuracy_score(y_test, y_test_pred),\n",
    "        'train_auc': roc_auc_score(y_train, y_train_proba),\n",
    "        'test_auc': roc_auc_score(y_test, y_test_proba),\n",
    "        'precision': precision_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'f1': f1_score(y_test, y_test_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104e44f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:19.783001Z",
     "iopub.status.busy": "2025-11-03T07:26:19.782698Z",
     "iopub.status.idle": "2025-11-03T07:26:33.187802Z",
     "shell.execute_reply": "2025-11-03T07:26:33.186262Z",
     "shell.execute_reply.started": "2025-11-03T07:26:19.782959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING MODELS WITHOUT CLASS WEIGHTS\n",
      "================================================================================\n",
      "Training Logistic Regression...\n",
      "  Test Accuracy: 0.5714, Test AUC: 0.5871\n",
      "Training Ridge LR (L2)...\n",
      "  Test Accuracy: 0.5714, Test AUC: 0.5644\n",
      "Training Lasso LR (L1)...\n",
      "  Test Accuracy: 0.6000, Test AUC: 0.5455\n",
      "Training Elastic Net LR...\n",
      "  Test Accuracy: 0.6000, Test AUC: 0.5417\n",
      "Training Decision Tree...\n",
      "  Test Accuracy: 0.6000, Test AUC: 0.5852\n",
      "Training XGBoost...\n",
      "  Test Accuracy: 0.6571, Test AUC: 0.6667\n",
      "Training SVM (RBF)...\n",
      "  Test Accuracy: 0.6857, Test AUC: 0.3826\n",
      "Training KNeighbors...\n",
      "  Test Accuracy: 0.6571, Test AUC: 0.7027\n",
      "Training Neural Network...\n",
      "  Test Accuracy: 0.6286, Test AUC: 0.5360\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models (WITHOUT class weights)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING MODELS WITHOUT CLASS WEIGHTS\")\n",
    "print(\"=\"*80)\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    metrics = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    metrics['model'] = name\n",
    "    results.append(metrics)\n",
    "    print(f\"  Test Accuracy: {metrics['test_acc']:.4f}, Test AUC: {metrics['test_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef92fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:33.188898Z",
     "iopub.status.busy": "2025-11-03T07:26:33.188616Z",
     "iopub.status.idle": "2025-11-03T07:26:33.213554Z",
     "shell.execute_reply": "2025-11-03T07:26:33.212748Z",
     "shell.execute_reply.started": "2025-11-03T07:26:33.188876Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL COMPARISON (NO CLASS WEIGHTS) ===\n",
      "              model  train_acc  test_acc  train_auc  test_auc  precision   recall       f1\n",
      "          SVM (RBF)   0.727941  0.685714   0.010501  0.382576   0.685714 1.000000 0.813559\n",
      "            XGBoost   1.000000  0.657143   1.000000  0.666667   0.714286 0.833333 0.769231\n",
      "         KNeighbors   0.713235  0.657143   0.757021  0.702652   0.714286 0.833333 0.769231\n",
      "     Neural Network   1.000000  0.628571   1.000000  0.535985   0.739130 0.708333 0.723404\n",
      "      Lasso LR (L1)   0.992647  0.600000   0.999267  0.545455   0.708333 0.708333 0.708333\n",
      "     Elastic Net LR   0.992647  0.600000   1.000000  0.541667   0.708333 0.708333 0.708333\n",
      "      Decision Tree   1.000000  0.600000   1.000000  0.585227   0.750000 0.625000 0.681818\n",
      "Logistic Regression   1.000000  0.571429   1.000000  0.587121   0.714286 0.625000 0.666667\n",
      "      Ridge LR (L2)   1.000000  0.571429   1.000000  0.564394   0.695652 0.666667 0.680851\n"
     ]
    }
   ],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['model', 'train_acc', 'test_acc', 'train_auc', 'test_auc', 'precision', 'recall', 'f1']]\n",
    "results_df = results_df.sort_values('test_acc', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== MODEL COMPARISON (NO CLASS WEIGHTS) ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c76df29-3bc3-40ff-8239-ebfe4f73e6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:33.219151Z",
     "iopub.status.busy": "2025-11-03T07:26:33.218783Z",
     "iopub.status.idle": "2025-11-03T07:26:33.229265Z",
     "shell.execute_reply": "2025-11-03T07:26:33.228337Z",
     "shell.execute_reply.started": "2025-11-03T07:26:33.219126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE COMPARISON WITH ORIGINAL STUDY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===== FEATURE IMPORTANCE ANALYSIS =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE COMPARISON WITH ORIGINAL STUDY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Original study's important features\n",
    "original_features = ['MDEC-23', 'MATS2v', 'ATSC8s', 'VE3_Dt', 'CrippenMR', 'SpMax7_Bhe',\n",
    "                     'SpMin1_Bhs', 'C1SP2', 'GATS8e', 'GATS8s', 'SpMax5_Bhv', 'VE3_Dzi', 'VPC-4']\n",
    "\n",
    "feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e7adcb7-6c5e-4ea1-a603-b985281ce327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:33.233229Z",
     "iopub.status.busy": "2025-11-03T07:26:33.231959Z",
     "iopub.status.idle": "2025-11-03T07:26:33.247434Z",
     "shell.execute_reply": "2025-11-03T07:26:33.246529Z",
     "shell.execute_reply.started": "2025-11-03T07:26:33.233194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Extract feature importance for different model types\"\"\"\n",
    "    # Tree-based models: use built-in feature_importances_\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        method = \"Built-in (Impurity-based)\"\n",
    "    # Linear models: use absolute coefficient values\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "        method = \"Coefficients\"\n",
    "    # Other models: use permutation importance\n",
    "    else:\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
    "        )\n",
    "        importances = perm_importance.importances_mean\n",
    "        method = \"Permutation\"\n",
    "    \n",
    "    # Create DataFrame with feature importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6cce8d-e5ec-49cf-be29-7a376fb75caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:33.250560Z",
     "iopub.status.busy": "2025-11-03T07:26:33.250060Z",
     "iopub.status.idle": "2025-11-03T07:26:33.278826Z",
     "shell.execute_reply": "2025-11-03T07:26:33.277705Z",
     "shell.execute_reply.started": "2025-11-03T07:26:33.250529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original study identified 13 important features using DTC:\n",
      "['MDEC-23', 'MATS2v', 'ATSC8s', 'VE3_Dt', 'CrippenMR', 'SpMax7_Bhe', 'SpMin1_Bhs', 'C1SP2', 'GATS8e', 'GATS8s', 'SpMax5_Bhv', 'VE3_Dzi', 'VPC-4']\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importance for each trained model\n",
    "print(f\"\\nOriginal study identified {len(original_features)} important features using DTC:\")\n",
    "print(original_features)\n",
    "print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018cc492-dfa8-427f-b4d9-0a0af32ac086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:26:33.280397Z",
     "iopub.status.busy": "2025-11-03T07:26:33.279781Z",
     "iopub.status.idle": "2025-11-03T07:27:33.732949Z",
     "shell.execute_reply": "2025-11-03T07:27:33.731343Z",
     "shell.execute_reply.started": "2025-11-03T07:26:33.280359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Logistic Regression ###\n",
      "Method: Coefficients\n",
      "\n",
      "Top 13 Features:\n",
      "        feature  importance\n",
      "           JGI7    4.427035\n",
      "       maxsssCH    4.049126\n",
      "        nHBint3    3.663130\n",
      "      topoShape    3.568342\n",
      "         ALogp2    3.528732\n",
      "         WTPT-2    3.461760\n",
      "PetitjeanNumber    3.400879\n",
      "          C3SP3    3.381391\n",
      "      minHBint4    3.334651\n",
      "      maxHBint4    3.254575\n",
      "        minssNH    3.167231\n",
      "        maxssNH    3.122925\n",
      "        nF6Ring    3.050619\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### Ridge LR (L2) ###\n",
      "Method: Coefficients\n",
      "\n",
      "Top 13 Features:\n",
      "  feature  importance\n",
      "   ALogp2    0.485300\n",
      " BCUTw-1l    0.450650\n",
      " maxsssCH    0.418850\n",
      "    minsF    0.418486\n",
      "    maxsF    0.407373\n",
      "    nBase    0.396368\n",
      "  minssNH    0.381735\n",
      "   MATS1s    0.373555\n",
      "  maxssNH    0.368521\n",
      "maxHBint5    0.357965\n",
      "  VE3_Dzs    0.346970\n",
      "    C3SP3    0.345447\n",
      "minHCsatu    0.336533\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### Lasso LR (L1) ###\n",
      "Method: Coefficients\n",
      "\n",
      "Top 13 Features:\n",
      "  feature  importance\n",
      "     JGI7    0.502660\n",
      "minHBint4    0.351879\n",
      "minHCsatu    0.351458\n",
      "  minssNH    0.347392\n",
      "  maxssNH    0.338179\n",
      "maxHBint4    0.323298\n",
      "   MATS1s    0.295117\n",
      "    C3SP3    0.293685\n",
      "   ALogp2    0.292476\n",
      "     GGI7    0.282097\n",
      "    EE_Dt    0.279185\n",
      "    nBase    0.267753\n",
      "maxHCsatu    0.265740\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### Elastic Net LR ###\n",
      "Method: Coefficients\n",
      "\n",
      "Top 13 Features:\n",
      "  feature  importance\n",
      "     JGI7    0.398615\n",
      "    nBase    0.358037\n",
      "   ALogp2    0.354660\n",
      "minHCsatu    0.342739\n",
      " maxsssCH    0.333195\n",
      "  minssNH    0.325919\n",
      "   MATS1s    0.325054\n",
      "  maxssNH    0.318108\n",
      "minHBint4    0.311561\n",
      "    C3SP3    0.311160\n",
      "maxHBint4    0.303191\n",
      "maxHCsatu    0.293274\n",
      "    minsF    0.277028\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### Decision Tree ###\n",
      "Method: Built-in (Impurity-based)\n",
      "\n",
      "Top 13 Features:\n",
      "  feature  importance\n",
      "SpDiam_Dt    0.118306\n",
      "   MATS5i    0.102682\n",
      "    ATS5v    0.099443\n",
      "maxHBint3    0.095346\n",
      "  AATSC4s    0.078238\n",
      "   MATS5p    0.077719\n",
      "  VE2_Dzp    0.076318\n",
      "  AATSC4m    0.073880\n",
      "   MATS6i    0.059042\n",
      " maxHaaCH    0.053464\n",
      "       Mi    0.044282\n",
      "   GATS7m    0.032519\n",
      "   AATS8i    0.032025\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### XGBoost ###\n",
      "Method: Built-in (Impurity-based)\n",
      "\n",
      "Top 13 Features:\n",
      "      feature  importance\n",
      "        ATS3m    0.080561\n",
      "ETA_Epsilon_4    0.037329\n",
      "        ATS2p    0.032870\n",
      "       ATSC5i    0.031158\n",
      "       MATS3s    0.029200\n",
      "   SpMax4_Bhm    0.026982\n",
      "       GATS1i    0.026230\n",
      "       MATS7p    0.026002\n",
      "   SpMax6_Bhv    0.025148\n",
      "   SpMin3_Bhe    0.024725\n",
      "    SpDiam_Dt    0.023027\n",
      "        ASP-6    0.018997\n",
      "         CIC2    0.017939\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### SVM (RBF) ###\n",
      "Method: Permutation\n",
      "\n",
      "Top 13 Features:\n",
      "    feature  importance\n",
      "     MATS3v         0.0\n",
      "       ndNH         0.0\n",
      "        JGT         0.0\n",
      "      ATS2i         0.0\n",
      "CrippenLogP         0.0\n",
      "      ATS2s         0.0\n",
      "      ATS2p         0.0\n",
      "      ATS2v         0.0\n",
      "   SHBint10         0.0\n",
      "    AATSC4i         0.0\n",
      "    AATSC4m         0.0\n",
      "    AATSC4c         0.0\n",
      "    AATSC4e         0.0\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### KNeighbors ###\n",
      "Method: Permutation\n",
      "\n",
      "Top 13 Features:\n",
      "    feature  importance\n",
      "       VC-4    0.020000\n",
      "     GATS2e    0.005714\n",
      "    MDEO-22    0.002857\n",
      "    MDEO-12    0.002857\n",
      "    nHBint3    0.002857\n",
      "       SssO    0.002857\n",
      "      C2SP3    0.000000\n",
      "      C2SP2    0.000000\n",
      "      C2SP1    0.000000\n",
      "     GATS2p    0.000000\n",
      "      AVP-4    0.000000\n",
      "       SssS    0.000000\n",
      "ETA_Shape_Y    0.000000\n",
      "\n",
      "Overlap with original study: 0/13 (0.0%)\n",
      "\n",
      "### Neural Network ###\n",
      "Method: Permutation\n",
      "\n",
      "Top 13 Features:\n",
      "       feature  importance\n",
      "       nHBint5    0.040000\n",
      "       SHBint6    0.037143\n",
      "       AATSC6s    0.037143\n",
      "       SHBint5    0.025714\n",
      "     maxHBint5    0.025714\n",
      "       AATSC6e    0.022857\n",
      "         minsF    0.022857\n",
      "         C1SP2    0.022857\n",
      "         maxsF    0.022857\n",
      "          JGI4    0.020000\n",
      "ETA_BetaP_ns_d    0.017143\n",
      " ETA_Beta_ns_d    0.014286\n",
      "        ATSC1v    0.011429\n",
      "\n",
      "Overlap with original study: 1/13 (7.7%)\n",
      "Matching features: ['C1SP2']\n"
     ]
    }
   ],
   "source": [
    "feature_comparison = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n### {name} ###\")\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance_df, method = get_feature_importance(model, name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # Get top 13 features (same number as original study)\n",
    "    top_13 = importance_df.head(13)\n",
    "    top_13_features = top_13['feature'].tolist()\n",
    "    \n",
    "    # Calculate overlap with original study\n",
    "    overlap = set(top_13_features) & set(original_features)\n",
    "    overlap_count = len(overlap)\n",
    "    overlap_pct = (overlap_count / len(original_features)) * 100\n",
    "    \n",
    "    print(f\"Method: {method}\")\n",
    "    print(f\"\\nTop 13 Features:\")\n",
    "    print(top_13.to_string(index=False))\n",
    "    print(f\"\\nOverlap with original study: {overlap_count}/{len(original_features)} ({overlap_pct:.1f}%)\")\n",
    "    if overlap:\n",
    "        print(f\"Matching features: {sorted(overlap)}\")\n",
    "    \n",
    "    feature_comparison[name] = {\n",
    "        'top_13': top_13_features,\n",
    "        'overlap_count': overlap_count,\n",
    "        'overlap_features': sorted(overlap),\n",
    "        'method': method\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "141f02f1-0953-440e-a338-d1cfd3ced58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:33.734627Z",
     "iopub.status.busy": "2025-11-03T07:27:33.734175Z",
     "iopub.status.idle": "2025-11-03T07:27:33.745502Z",
     "shell.execute_reply": "2025-11-03T07:27:33.744031Z",
     "shell.execute_reply.started": "2025-11-03T07:27:33.734560Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY: OVERLAP WITH ORIGINAL STUDY\n",
      "================================================================================\n",
      "              Model  Overlap Count  Overlap %                    Method\n",
      "     Neural Network              1   7.692308               Permutation\n",
      "Logistic Regression              0   0.000000              Coefficients\n",
      "      Ridge LR (L2)              0   0.000000              Coefficients\n",
      "      Lasso LR (L1)              0   0.000000              Coefficients\n",
      "     Elastic Net LR              0   0.000000              Coefficients\n",
      "      Decision Tree              0   0.000000 Built-in (Impurity-based)\n",
      "            XGBoost              0   0.000000 Built-in (Impurity-based)\n",
      "          SVM (RBF)              0   0.000000               Permutation\n",
      "         KNeighbors              0   0.000000               Permutation\n"
     ]
    }
   ],
   "source": [
    "# Summary comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: OVERLAP WITH ORIGINAL STUDY\")\n",
    "print(\"=\"*80)\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': list(feature_comparison.keys()),\n",
    "    'Overlap Count': [v['overlap_count'] for v in feature_comparison.values()],\n",
    "    'Overlap %': [(v['overlap_count']/13)*100 for v in feature_comparison.values()],\n",
    "    'Method': [v['method'] for v in feature_comparison.values()]\n",
    "}).sort_values('Overlap Count', ascending=False)\n",
    "\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa8061a-88eb-4883-a323-3947d2edc1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:33.746966Z",
     "iopub.status.busy": "2025-11-03T07:27:33.746619Z",
     "iopub.status.idle": "2025-11-03T07:27:33.768207Z",
     "shell.execute_reply": "2025-11-03T07:27:33.767035Z",
     "shell.execute_reply.started": "2025-11-03T07:27:33.746937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURES SELECTED BY MULTIPLE MODELS (in top 13)\n",
      "================================================================================\n",
      "\n",
      "Features selected by 3+ models:\n",
      "  [ ] minssNH: 4/9 models\n",
      "  [ ] ALogp2: 4/9 models\n",
      "  [ ] C3SP3: 4/9 models\n",
      "  [ ] maxssNH: 4/9 models\n",
      "  [ ] JGI7: 3/9 models\n",
      "  [ ] maxsssCH: 3/9 models\n",
      "  [ ] minHCsatu: 3/9 models\n",
      "  [ ] MATS1s: 3/9 models\n",
      "  [ ] minsF: 3/9 models\n",
      "  [ ] nBase: 3/9 models\n",
      "  [ ] maxHBint4: 3/9 models\n",
      "  [ ] minHBint4: 3/9 models\n"
     ]
    }
   ],
   "source": [
    "# Find features commonly selected across multiple models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURES SELECTED BY MULTIPLE MODELS (in top 13)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_top_features = []\n",
    "for comp in feature_comparison.values():\n",
    "    all_top_features.extend(comp['top_13'])\n",
    "\n",
    "feature_counts = pd.Series(all_top_features).value_counts()\n",
    "frequent_features = feature_counts[feature_counts >= 3]\n",
    "\n",
    "if len(frequent_features) > 0:\n",
    "    print(f\"\\nFeatures selected by 3+ models:\")\n",
    "    for feat, count in frequent_features.items():\n",
    "        in_original = \"✓\" if feat in original_features else \" \"\n",
    "        print(f\"  [{in_original}] {feat}: {count}/{len(models)} models\")\n",
    "else:\n",
    "    print(\"No features were consistently selected across 3+ models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43cb9843-b0c3-430b-a2bb-320f332160da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:32:34.960567Z",
     "iopub.status.busy": "2025-11-03T07:32:34.960097Z",
     "iopub.status.idle": "2025-11-03T07:32:34.974562Z",
     "shell.execute_reply": "2025-11-03T07:32:34.973449Z",
     "shell.execute_reply.started": "2025-11-03T07:32:34.960537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rank</th>\n",
       "      <th>feature</th>\n",
       "      <th>in_original_study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>JGI7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>maxsssCH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>nHBint3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>4</td>\n",
       "      <td>topoShape</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>ALogp2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>9</td>\n",
       "      <td>maxsF</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>10</td>\n",
       "      <td>JGI4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>11</td>\n",
       "      <td>ETA_BetaP_ns_d</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>12</td>\n",
       "      <td>ETA_Beta_ns_d</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>13</td>\n",
       "      <td>ATSC1v</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  rank         feature  in_original_study\n",
       "0    Logistic Regression     1            JGI7              False\n",
       "1    Logistic Regression     2        maxsssCH              False\n",
       "2    Logistic Regression     3         nHBint3              False\n",
       "3    Logistic Regression     4       topoShape              False\n",
       "4    Logistic Regression     5          ALogp2              False\n",
       "..                   ...   ...             ...                ...\n",
       "112       Neural Network     9           maxsF              False\n",
       "113       Neural Network    10            JGI4              False\n",
       "114       Neural Network    11  ETA_BetaP_ns_d              False\n",
       "115       Neural Network    12   ETA_Beta_ns_d              False\n",
       "116       Neural Network    13          ATSC1v              False\n",
       "\n",
       "[117 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save detailed comparison\n",
    "comparison_results = []\n",
    "for model_name, comp in feature_comparison.items():\n",
    "    for i, feat in enumerate(comp['top_13'], 1):\n",
    "        comparison_results.append({\n",
    "            'model': model_name,\n",
    "            'rank': i,\n",
    "            'feature': feat,\n",
    "            'in_original_study': feat in original_features\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df\n",
    "# comparison_df.to_csv('feature_importance_comparison.csv', index=False)\n",
    "# print(\"\\n✓ Feature importance saved to 'feature_importance_comparison.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a51f80f-6347-4a51-84fe-19274e0620c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:33.801303Z",
     "iopub.status.busy": "2025-11-03T07:27:33.800936Z",
     "iopub.status.idle": "2025-11-03T07:27:33.815804Z",
     "shell.execute_reply": "2025-11-03T07:27:33.814766Z",
     "shell.execute_reply.started": "2025-11-03T07:27:33.801271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING MODELS WITH CLASS WEIGHTS\n",
      "================================================================================\n",
      "\n",
      "Computed class weights: {0: 1.511111111111111, 1: 0.7472527472527473}\n",
      "Toxic (0): 1.511, NonToxic (1): 0.747\n",
      "XGBoost scale_pos_weight: 0.495\n"
     ]
    }
   ],
   "source": [
    "# ===== CLASS WEIGHT COMPARISON =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING MODELS WITH CLASS WEIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(f\"\\nComputed class weights: {weight_dict}\")\n",
    "print(f\"Toxic (0): {class_weights[0]:.3f}, NonToxic (1): {class_weights[1]:.3f}\")\n",
    "\n",
    "# Calculate scale_pos_weight for XGBoost\n",
    "n_toxic = np.sum(y_train == 0)\n",
    "n_nontoxic = np.sum(y_train == 1)\n",
    "scale_pos_weight = n_toxic / n_nontoxic\n",
    "print(f\"XGBoost scale_pos_weight: {scale_pos_weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ba5d4b-a1f6-4ad5-9db8-056366ccc92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:33.817889Z",
     "iopub.status.busy": "2025-11-03T07:27:33.816853Z",
     "iopub.status.idle": "2025-11-03T07:27:33.836924Z",
     "shell.execute_reply": "2025-11-03T07:27:33.835588Z",
     "shell.execute_reply.started": "2025-11-03T07:27:33.817850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define models WITH class weights\n",
    "models_weighted = {\n",
    "    'Logistic Regression': LogisticRegression(penalty=None, max_iter=2000, solver='lbfgs', class_weight='balanced'),\n",
    "    'Ridge LR (L2)': LogisticRegression(penalty='l2', max_iter=2000, solver='lbfgs', C=1.0, class_weight='balanced'),\n",
    "    'Lasso LR (L1)': LogisticRegression(penalty='l1', max_iter=2000, solver='saga', C=1.0, class_weight='balanced'),\n",
    "    'Elastic Net LR': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=2000, C=1.0, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False, scale_pos_weight=scale_pos_weight, max_depth=3, n_estimators=100),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d7d5474-b532-4962-9c16-c8d2c5125b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:33.838712Z",
     "iopub.status.busy": "2025-11-03T07:27:33.838075Z",
     "iopub.status.idle": "2025-11-03T07:27:47.040460Z",
     "shell.execute_reply": "2025-11-03T07:27:47.037329Z",
     "shell.execute_reply.started": "2025-11-03T07:27:33.838677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression (weighted)...\n",
      "  Test Accuracy: 0.6000, Test AUC: 0.5682\n",
      "Training Ridge LR (L2) (weighted)...\n",
      "  Test Accuracy: 0.5714, Test AUC: 0.5644\n",
      "Training Lasso LR (L1) (weighted)...\n",
      "  Test Accuracy: 0.6000, Test AUC: 0.5417\n",
      "Training Elastic Net LR (weighted)...\n",
      "  Test Accuracy: 0.5714, Test AUC: 0.5455\n",
      "Training Decision Tree (weighted)...\n",
      "  Test Accuracy: 0.5143, Test AUC: 0.4735\n",
      "Training XGBoost (weighted)...\n",
      "  Test Accuracy: 0.5429, Test AUC: 0.5303\n",
      "Training SVM (RBF) (weighted)...\n",
      "  Test Accuracy: 0.5143, Test AUC: 0.3826\n",
      "Training KNeighbors (weighted)...\n",
      "  Test Accuracy: 0.6571, Test AUC: 0.7027\n",
      "Training Neural Network (weighted)...\n",
      "  Test Accuracy: 0.6286, Test AUC: 0.5360\n"
     ]
    }
   ],
   "source": [
    "# Train weighted models\n",
    "results_weighted = []\n",
    "for name, model in models_weighted.items():\n",
    "    print(f\"Training {name} (weighted)...\")\n",
    "    metrics = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    metrics['model'] = name\n",
    "    results_weighted.append(metrics)\n",
    "    print(f\"  Test Accuracy: {metrics['test_acc']:.4f}, Test AUC: {metrics['test_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3f78025-1ad3-47af-9349-54a99773abf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:47.042066Z",
     "iopub.status.busy": "2025-11-03T07:27:47.041408Z",
     "iopub.status.idle": "2025-11-03T07:27:47.049352Z",
     "shell.execute_reply": "2025-11-03T07:27:47.048100Z",
     "shell.execute_reply.started": "2025-11-03T07:27:47.042039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create comparison DataFrames\n",
    "results_df_weighted = pd.DataFrame(results_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "013587d2-070e-476f-a7b5-39eaa2213f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:47.050312Z",
     "iopub.status.busy": "2025-11-03T07:27:47.050038Z",
     "iopub.status.idle": "2025-11-03T07:27:47.075293Z",
     "shell.execute_reply": "2025-11-03T07:27:47.074402Z",
     "shell.execute_reply.started": "2025-11-03T07:27:47.050290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Merge for side-by-side comparison\n",
    "comparison = pd.merge(\n",
    "    results_df[['model', 'test_acc', 'precision', 'recall', 'f1']],\n",
    "    results_df_weighted[['model', 'test_acc', 'precision', 'recall', 'f1']],\n",
    "    on='model',\n",
    "    suffixes=('_original', '_weighted')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f30b8512-adf6-4ab3-9de4-977f0c01e8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:29:52.477273Z",
     "iopub.status.busy": "2025-11-03T07:29:52.476889Z",
     "iopub.status.idle": "2025-11-03T07:29:52.504499Z",
     "shell.execute_reply": "2025-11-03T07:29:52.503217Z",
     "shell.execute_reply.started": "2025-11-03T07:29:52.477248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_acc_original</th>\n",
       "      <th>precision_original</th>\n",
       "      <th>recall_original</th>\n",
       "      <th>f1_original</th>\n",
       "      <th>test_acc_weighted</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>acc_change</th>\n",
       "      <th>recall_change</th>\n",
       "      <th>f1_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>-0.171429</td>\n",
       "      <td>-0.541667</td>\n",
       "      <td>-0.249457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-0.114286</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso LR (L1)</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elastic Net LR</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.027482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.059596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge LR (L2)</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  test_acc_original  precision_original  \\\n",
       "0            SVM (RBF)           0.685714            0.685714   \n",
       "1              XGBoost           0.657143            0.714286   \n",
       "2           KNeighbors           0.657143            0.714286   \n",
       "3       Neural Network           0.628571            0.739130   \n",
       "4        Lasso LR (L1)           0.600000            0.708333   \n",
       "5       Elastic Net LR           0.600000            0.708333   \n",
       "6        Decision Tree           0.600000            0.750000   \n",
       "7  Logistic Regression           0.571429            0.714286   \n",
       "8        Ridge LR (L2)           0.571429            0.695652   \n",
       "\n",
       "   recall_original  f1_original  test_acc_weighted  precision_weighted  \\\n",
       "0         1.000000     0.813559           0.514286            0.733333   \n",
       "1         0.833333     0.769231           0.542857            0.642857   \n",
       "2         0.833333     0.769231           0.657143            0.714286   \n",
       "3         0.708333     0.723404           0.628571            0.739130   \n",
       "4         0.708333     0.708333           0.600000            0.708333   \n",
       "5         0.708333     0.708333           0.571429            0.695652   \n",
       "6         0.625000     0.681818           0.514286            0.666667   \n",
       "7         0.625000     0.666667           0.600000            0.750000   \n",
       "8         0.666667     0.680851           0.571429            0.695652   \n",
       "\n",
       "   recall_weighted  f1_weighted  acc_change  recall_change  f1_change  \n",
       "0         0.458333     0.564103   -0.171429      -0.541667  -0.249457  \n",
       "1         0.750000     0.692308   -0.114286      -0.083333  -0.076923  \n",
       "2         0.833333     0.769231    0.000000       0.000000   0.000000  \n",
       "3         0.708333     0.723404    0.000000       0.000000   0.000000  \n",
       "4         0.708333     0.708333    0.000000       0.000000   0.000000  \n",
       "5         0.666667     0.680851   -0.028571      -0.041667  -0.027482  \n",
       "6         0.583333     0.622222   -0.085714      -0.041667  -0.059596  \n",
       "7         0.625000     0.681818    0.028571       0.000000   0.015152  \n",
       "8         0.666667     0.680851    0.000000       0.000000   0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate improvements\n",
    "comparison['acc_change'] = comparison['test_acc_weighted'] - comparison['test_acc_original']\n",
    "comparison['recall_change'] = comparison['recall_weighted'] - comparison['recall_original']\n",
    "comparison['f1_change'] = comparison['f1_weighted'] - comparison['f1_original']\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9582998c-0ac3-41ad-a713-5a8554aff733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:47.107628Z",
     "iopub.status.busy": "2025-11-03T07:27:47.107366Z",
     "iopub.status.idle": "2025-11-03T07:27:47.189184Z",
     "shell.execute_reply": "2025-11-03T07:27:47.188223Z",
     "shell.execute_reply.started": "2025-11-03T07:27:47.107605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "CONFUSION MATRIX COMPARISON (Original vs Weighted)\n",
      "====================================================================================================\n",
      "\n",
      "### Logistic Regression ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            5                   6\n",
      "Actual NonToxic         9                  15\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            6                   5\n",
      "Actual NonToxic         9                  15\n",
      "\n",
      "Recall for Toxic class: 0.455 → 0.545 (Δ=+0.091)\n",
      "False Negatives (Toxic → NonToxic): 6 → 5 (Δ=-1)\n",
      "\n",
      "### Ridge LR (L2) ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic         8                  16\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic         8                  16\n",
      "\n",
      "Recall for Toxic class: 0.364 → 0.364 (Δ=+0.000)\n",
      "False Negatives (Toxic → NonToxic): 7 → 7 (Δ=+0)\n",
      "\n",
      "### Lasso LR (L1) ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic         7                  17\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic         7                  17\n",
      "\n",
      "Recall for Toxic class: 0.364 → 0.364 (Δ=+0.000)\n",
      "False Negatives (Toxic → NonToxic): 7 → 7 (Δ=+0)\n",
      "\n",
      "### Elastic Net LR ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic         7                  17\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic         8                  16\n",
      "\n",
      "Recall for Toxic class: 0.364 → 0.364 (Δ=+0.000)\n",
      "False Negatives (Toxic → NonToxic): 7 → 7 (Δ=+0)\n",
      "\n",
      "### Decision Tree ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            6                   5\n",
      "Actual NonToxic         9                  15\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            4                   7\n",
      "Actual NonToxic        10                  14\n",
      "\n",
      "Recall for Toxic class: 0.545 → 0.364 (Δ=-0.182)\n",
      "False Negatives (Toxic → NonToxic): 5 → 7 (Δ=+2)\n",
      "\n",
      "### XGBoost ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            3                   8\n",
      "Actual NonToxic         4                  20\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            1                  10\n",
      "Actual NonToxic         6                  18\n",
      "\n",
      "Recall for Toxic class: 0.273 → 0.091 (Δ=-0.182)\n",
      "False Negatives (Toxic → NonToxic): 8 → 10 (Δ=+2)\n",
      "\n",
      "### SVM (RBF) ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            0                  11\n",
      "Actual NonToxic         0                  24\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            7                   4\n",
      "Actual NonToxic        13                  11\n",
      "\n",
      "Recall for Toxic class: 0.000 → 0.636 (Δ=+0.636)\n",
      "False Negatives (Toxic → NonToxic): 11 → 4 (Δ=-7)\n",
      "\n",
      "### KNeighbors ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            3                   8\n",
      "Actual NonToxic         4                  20\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            3                   8\n",
      "Actual NonToxic         4                  20\n",
      "\n",
      "Recall for Toxic class: 0.273 → 0.273 (Δ=+0.000)\n",
      "False Negatives (Toxic → NonToxic): 8 → 8 (Δ=+0)\n",
      "\n",
      "### Neural Network ###\n",
      "\n",
      "Original (No Class Weights):\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            5                   6\n",
      "Actual NonToxic         7                  17\n",
      "\n",
      "With Class Weights:\n",
      "                Predicted Toxic    Predicted NonToxic\n",
      "Actual Toxic            5                   6\n",
      "Actual NonToxic         7                  17\n",
      "\n",
      "Recall for Toxic class: 0.455 → 0.455 (Δ=+0.000)\n",
      "False Negatives (Toxic → NonToxic): 6 → 6 (Δ=+0)\n"
     ]
    }
   ],
   "source": [
    "# Detailed confusion matrix comparison\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CONFUSION MATRIX COMPARISON (Original vs Weighted)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for name, model_original in models.items():\n",
    "    model_weighted = models_weighted[name]\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_original = model_original.predict(X_test_scaled)\n",
    "    y_pred_weighted = model_weighted.predict(X_test_scaled)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    cm_original = confusion_matrix(y_test, y_pred_original)\n",
    "    cm_weighted = confusion_matrix(y_test, y_pred_weighted)\n",
    "    \n",
    "    print(f\"\\n### {name} ###\")\n",
    "    print(\"\\nOriginal (No Class Weights):\")\n",
    "    print(f\"                Predicted Toxic    Predicted NonToxic\")\n",
    "    print(f\"Actual Toxic          {cm_original[0,0]:3d}                 {cm_original[0,1]:3d}\")\n",
    "    print(f\"Actual NonToxic       {cm_original[1,0]:3d}                 {cm_original[1,1]:3d}\")\n",
    "    \n",
    "    print(\"\\nWith Class Weights:\")\n",
    "    print(f\"                Predicted Toxic    Predicted NonToxic\")\n",
    "    print(f\"Actual Toxic          {cm_weighted[0,0]:3d}                 {cm_weighted[0,1]:3d}\")\n",
    "    print(f\"Actual NonToxic       {cm_weighted[1,0]:3d}                 {cm_weighted[1,1]:3d}\")\n",
    "    \n",
    "    # Calculate recall for minority class\n",
    "    recall_toxic_orig = cm_original[0,0] / (cm_original[0,0] + cm_original[0,1]) if (cm_original[0,0] + cm_original[0,1]) > 0 else 0\n",
    "    recall_toxic_weighted = cm_weighted[0,0] / (cm_weighted[0,0] + cm_weighted[0,1]) if (cm_weighted[0,0] + cm_weighted[0,1]) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nRecall for Toxic class: {recall_toxic_orig:.3f} → {recall_toxic_weighted:.3f} (Δ={recall_toxic_weighted-recall_toxic_orig:+.3f})\")\n",
    "    \n",
    "    # False negatives\n",
    "    fn_orig = cm_original[0,1]\n",
    "    fn_weighted = cm_weighted[0,1]\n",
    "    print(f\"False Negatives (Toxic → NonToxic): {fn_orig} → {fn_weighted} (Δ={fn_weighted-fn_orig:+d})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a337206f-8f05-4d26-a169-f0d9d540a82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T07:27:47.199395Z",
     "iopub.status.busy": "2025-11-03T07:27:47.199002Z",
     "iopub.status.idle": "2025-11-03T07:27:47.221859Z",
     "shell.execute_reply": "2025-11-03T07:27:47.220899Z",
     "shell.execute_reply.started": "2025-11-03T07:27:47.199365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save all comparisons\n",
    "# comparison.to_csv('class_weight_comparison.csv', index=False)\n",
    "# results_df.to_csv('model_results_original.csv', index=False)\n",
    "# results_df_weighted.to_csv('model_results_weighted.csv', index=False)\n",
    "# print(\"\\n✓ All results saved to CSV files\")\n",
    "# print(\"  - model_results_original.csv\")\n",
    "# print(\"  - model_results_weighted.csv\")\n",
    "# print(\"  - class_weight_comparison.csv\")\n",
    "# print(\"  - feature_importance_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28b8fd-d752-48dd-b8e4-4fa64481a352",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a590b3-a7bf-48a9-a497-69b9a70bed43",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51947737-d1b0-4686-9342-980c08d8a51a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8362584,
     "sourceId": 13195792,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
