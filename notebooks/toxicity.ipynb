{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toxicity Dataset : https://archive.ics.uci.edu/dataset/728/toxicity-2\n",
    "\n",
    "The dataset includes 171 molecules designed for functional domains of a core clock protein, CRY1, responsible for generating circadian rhythm. 56 of the molecules are toxic and the rest are non-toxic. \n",
    "\n",
    "The data consists a complete set of 1203 molecular descriptors and needs feature selection before classification since some of the features are redundant. \n",
    "\n",
    "Introductory Paper:\n",
    "Structure-based design and classifications of small molecules regulating the circadian rhythm period\n",
    "By Seref Gul, F. Rahim, Safak Isin, Fatma Yilmaz, Nuri Ozturk, M. Turkay, I. Kavakli. 2021\n",
    "https://www.semanticscholar.org/paper/Structure-based-design-and-classifications-of-small-Gul-Rahim/5944836c47bc7d1a2b0464a9a1db94d4bc7f28ce\n",
    "Published in Scientific reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:07.970883Z",
     "iopub.status.busy": "2025-09-18T04:07:07.970487Z",
     "iopub.status.idle": "2025-09-18T04:07:07.979245Z",
     "shell.execute_reply": "2025-09-18T04:07:07.977849Z",
     "shell.execute_reply.started": "2025-09-18T04:07:07.970858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the toxicity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:12.702310Z",
     "iopub.status.busy": "2025-09-18T04:07:12.701902Z",
     "iopub.status.idle": "2025-09-18T04:07:14.072099Z",
     "shell.execute_reply": "2025-09-18T04:07:14.070911Z",
     "shell.execute_reply.started": "2025-09-18T04:07:12.702270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (171, 1204)\n",
      "\n",
      "First few rows:\n",
      "   MATS3v  nHBint10  MATS3s  MATS3p  nHBDon_Lipinski  minHBint8  MATS3e  \\\n",
      "0  0.0908         0  0.0075  0.0173                0        0.0 -0.0436   \n",
      "1  0.0213         0  0.1144 -0.0410                0        0.0  0.1231   \n",
      "2  0.0018         0 -0.0156 -0.0765                2        0.0 -0.1138   \n",
      "3 -0.0251         0 -0.0064 -0.0894                3        0.0 -0.0747   \n",
      "4  0.0135         0  0.0424 -0.0353                0        0.0 -0.0638   \n",
      "\n",
      "   MATS3c  minHBint2  MATS3m  ...   WTPT-4   WTPT-5  ETA_EtaP_L  ETA_EtaP_F  \\\n",
      "0  0.0409        0.0  0.1368  ...   0.0000   0.0000      0.1780      1.5488   \n",
      "1 -0.0316        0.0  0.1318  ...   8.8660  19.3525      0.1739      1.3718   \n",
      "2 -0.1791        0.0  0.0615  ...   5.2267  27.8796      0.1688      1.4395   \n",
      "3 -0.1151        0.0  0.0361  ...   7.7896  24.7336      0.1702      1.4654   \n",
      "4  0.0307        0.0  0.0306  ...  12.3240  19.7486      0.1789      1.4495   \n",
      "\n",
      "   ETA_EtaP_B  nT5Ring  SHdNH  ETA_dEpsilon_C  MDEO-22     Class  \n",
      "0      0.0088        0    0.0         -0.0868     0.00  NonToxic  \n",
      "1      0.0048        2    0.0         -0.0810     0.25  NonToxic  \n",
      "2      0.0116        2    0.0         -0.1004     0.00  NonToxic  \n",
      "3      0.0133        2    0.0         -0.1010     0.00  NonToxic  \n",
      "4      0.0120        2    0.0         -0.1071     0.00  NonToxic  \n",
      "\n",
      "[5 rows x 1204 columns]\n",
      "\n",
      "Column names:\n",
      "['MATS3v', 'nHBint10', 'MATS3s', 'MATS3p', 'nHBDon_Lipinski', 'minHBint8', 'MATS3e', 'MATS3c', 'minHBint2', 'MATS3m', 'minHBint6', 'minHBint7', 'minHBint4', 'MATS3i', 'VR3_Dt', 'SpMax8_Bhi', 'SdsN', 'SpMax8_Bhm', 'SpMax8_Bhe', 'ECCEN', 'MDEC-14', 'SpMax8_Bhs', 'SpMax8_Bhp', 'SpMax8_Bhv', 'MDEC-11', 'MDEC-12', 'MDEC-13', 'VR2_Dt', 'BIC5', 'ATS7s', 'ATS7p', 'ATS7v', 'ATS7i', 'ATS7m', 'ATS7e', 'mintN', 'nHsNH2', 'khs.sssCH', 'minHBint3', 'maxdssC', 'nT6Ring', 'minHBint5', 'nF8Ring', 'minssCH2', 'SpMax_DzZ', 'ETA_EtaP', 'nHsOH', 'SpMin1_Bhe', 'maxHother', 'nHBAcc_Lipinski', 'StN', 'khs.aaS', 'khs.aaO', 'khs.aaN', 'Sare', 'SHAvin', 'SpMax3_Bhv', 'SpMax3_Bhp', 'SpMax3_Bhs', 'SpMax3_Bhe', 'SpMin6_Bhi', 'SpMax3_Bhm', 'SpMax3_Bhi', 'ETA_EtaP_F_L', 'mindCH2', 'AATSC2e', 'AATSC2c', 'AATSC2m', 'AATSC2i', 'nsBr', 'AATS5p', 'AATSC2v', 'AATSC2p', 'AATSC2s', 'VABC', 'maxdNH', 'khs.ddsN', 'RotBtFrac', 'ATS4e', 'ATS4m', 'nFRing', 'ATS4i', 'EE_DzZ', 'ATS4s', 'ATS4p', 'ETA_Alpha', 'khs.sssN', 'EE_Dzi', 'MAXDN', 'EE_Dzm', 'EE_Dze', 'EE_Dzs', 'EE_Dzp', 'EE_Dzv', 'ATS8e', 'maxsOH', 'minssssNp', 'maxsOm', 'MDEC-23', 'MDEC-22', 'MDEC-24', 'nFG12HeteroRing', 'ATS8s', 'ATS8v', 'SP-6', 'SP-7', 'SHsNH2', 'SP-5', 'SP-2', 'SP-3', 'SP-0', 'SP-1', 'minHsOH', 'ATSC8v', 'MATS2v', 'ATSC8s', 'MATS2p', 'MATS2s', 'ATSC8p', 'MATS2e', 'ATSC8e', 'ATSC8c', 'MATS2c', 'MATS2m', 'topoDiameter', 'ATSC8m', 'MATS2i', 'ATSC8i', 'ntN', 'khs.ssCH2', 'SpAD_Dt', 'ETA_Eta_R_L', 'SHdsCH', 'SaasN', 'SC-4', 'SaasC', 'minaaCH', 'AATSC3c', 'AATSC3e', 'AATSC3i', 'AATSC3m', 'AATSC3s', 'AATSC3p', 'AATSC3v', 'SpMax2_Bhp', 'nF8HeteroRing', 'AATS8e', 'AATS8i', 'AATS8m', 'AATS8s', 'AATS8p', 'AATS8v', 'VE3_Dt', 'XLogP', 'SpMax2_Bhi', 'maxssCH2', 'minaaS', 'SpMax4_Bhv', 'SpMax4_Bhs', 'SpMax4_Bhp', 'SpMax4_Bhm', 'minHaaNH', 'SpMax4_Bhi', 'minaaN', 'SpMax4_Bhe', 'StsC', 'SssCH2', 'maxHdNH', 'MATS1p', 'R_TpiPCTPC', 'MATS1s', 'MATS1v', 'JGI10', 'MATS1c', 'MATS1e', 'VR2_DzZ', 'MATS1i', 'MATS1m', 'MDEC-34', 'MDEC-33', 'VR2_Dze', 'VR2_Dzm', 'VR2_Dzs', 'VR2_Dzp', 'khs.ssssC', 'nTG12Ring', 'khs.ssssN', 'ATS5e', 'gmin', 'VR2_D', 'ATS5m', 'ATS5p', 'ATS5s', 'ATS5v', 'AATSC5p', 'TpiPC', 'maxsCH3', 'SdS', 'khs.ssO', 'ETA_Eta_F_L', 'khs.ssS', 'SdO', 'VE2_Dt', 'maxHtCH', 'SpMax_Dze', 'SpMax_Dzm', 'SpMax_Dzi', 'ETA_dEpsilon_B', 'SpMax_Dzv', 'ETA_dEpsilon_A', 'SpMax_Dzs', 'ETA_dEpsilon_D', 'SpMax_Dzp', 'SsNH2', 'StCH', 'SsCH3', 'CIC5', 'CIC4', 'CIC1', 'CIC0', 'CIC3', 'CIC2', 'nF10HeteroRing', 'maxssO', 'WPOL', 'n5HeteroRing', 'maxHAvin', 'fragC', 'ETA_Eta_B_RC', 'AATS7m', 'SpDiam_Dt', 'SdssC', 'ETA_Epsilon_3', 'AATS7i', 'AATS7e', 'nT9Ring', 'minsCl', 'AATS7v', 'AATS7s', 'AATS7p', 'nHdCH2', 'ETA_Epsilon_5', 'ETA_Epsilon_4', 'SsssCH', 'maxHsOH', 'GATS1v', 'maxaaaC', 'GATS1s', 'minsNH2', 'BIC4', 'SpMin7_Bhs', 'SpMin7_Bhp', 'SpMin7_Bhv', 'nHtCH', 'GATS1e', 'mintsC', 'GATS1c', 'SpMin7_Bhm', 'GATS1m', 'SpMin7_Bhe', 'GATS1i', 'maxtsC', 'minHAvin', 'MDEC-44', 'AATS2v', 'SPC-6', 'SPC-4', 'SPC-5', 'SpAD_D', 'MATS6c', 'ETA_BetaP_s', 'minaasC', 'minaasN', 'minssNH', 'nT7HeteroRing', 'RotBFrac', 'nF10Ring', 'ETA_BetaP_ns', 'nH', 'nL', 'nN', 'nO', 'nA', 'nC', 'nF', 'nX', 'nQ', 'nS', 'nV', 'ATS1m', 'SdNH', 'mindsN', 'SHCsats', 'SHCsatu', 'CrippenMR', 'GATS1p', 'SRW10', 'ETA_dPsi_A', 'AATS6m', 'AATS6i', 'AATS6e', 'minsBr', 'nF9HeteroRing', 'SpMin7_Bhi', 'AATS6v', 'AATS6p', 'AATS6s', 'naAromAtom', 'nBase', 'minHBint10', 'SpDiam_DzZ', 'SaaNH', 'nssssC', 'khs.dNH', 'maxaaN', 'maxaaO', 'SpDiam_Dzv', 'SpDiam_Dzs', 'SpDiam_Dzp', 'SpDiam_Dze', 'SpDiam_Dzm', 'GATS6i', 'SpDiam_Dzi', 'Mi', 'Mv', 'Mp', 'GGI10', 'nBr', 'bpol', 'MW', 'GATS6v', 'MATS7s', 'MATS7p', 'C1SP1', 'MATS7v', 'MATS7i', 'MATS7m', 'MATS7c', 'GATS6s', 'MATS7e', 'maxtN', 'SpMin8_Bhe', 'SpMin8_Bhi', 'SpMin8_Bhm', 'SpMin8_Bhp', 'SpMin8_Bhs', 'SpMin8_Bhv', 'maxHCsatu', 'maxHCsats', 'ATSC3v', 'ATSC3s', 'ATSC3p', 'minHdCH2', 'ATSC3e', 'ATSC3c', 'maxssNH', 'ATSC3m', 'ATSC3i', 'minHCsatu', 'minHCsats', 'SpMax7_Bhe', 'SpMax7_Bhi', 'SpMax7_Bhm', 'ETA_BetaP_ns_d', 'SpMax7_Bhp', 'SpMax7_Bhs', 'SpMax7_Bhv', 'SdsCH', 'minssO', 'minssS', 'SpMin3_Bhe', 'SpMin3_Bhm', 'SpMin3_Bhi', 'SpMin3_Bhv', 'nT8Ring', 'SpMin3_Bhs', 'SpMin3_Bhp', 'TPC', 'khs.tCH', 'VP-5', 'VP-4', 'VP-7', 'VP-6', 'VP-1', 'VP-0', 'VP-3', 'VP-2', 'MIC5', 'MIC4', 'MIC3', 'MIC2', 'MIC1', 'MIC0', 'ATSC5p', 'piPC10', 'ATSC5s', 'minsOm', 'nT10HeteroRing', 'nHBa', 'nHBd', 'SddssS', 'nCl', 'minsOH', 'SHaaCH', 'nHBDon', 'nF11HeteroRing', 'AATS5i', 'AATS5m', 'SpMin6_Bhs', 'SpMin6_Bhp', 'SpMin6_Bhv', 'AATS5e', 'ETA_dBeta', 'khs.sCH3', 'ALogP', 'SpMin6_Bhm', 'BCUTp-1l', 'AATS5s', 'BCUTp-1h', 'AATS5v', 'SpMin6_Bhe', 'ATS8i', 'ATS8m', 'BCUTw-1h', 'BCUTw-1l', 'nBondsS3', 'nBondsS2', 'ATS8p', 'GATS3p', 'GATS3s', 'GATS3v', 'GATS3c', 'GATS3e', 'SC-5', 'GATS3i', 'SC-6', 'GATS3m', 'SC-3', 'minsCH3', 'SssssC', 'nAtomLC', 'nT12HeteroRing', 'minHaaCH', 'MLFER_BH', 'MLFER_BO', 'SaaaC', 'mindsCH', 'nddssS', 'maxaasC', 'maxsssN', 'MATS6p', 'MATS6s', 'MATS6v', 'MATS6i', 'MATS6m', 'MATS6e', 'ETA_Beta_ns_d', 'hmax', 'ETA_Beta_s', 'nHaaCH', 'khs.aaaC', 'khs.sNH2', 'ETA_AlphaP', 'nAromBond', 'ATSC2v', 'ATSC2p', 'ATSC2s', 'ATS4v', 'ATSC2e', 'ATSC2c', 'ATSC2m', 'ATSC2i', 'AATS4v', 'AATS4s', 'AATS4p', 'AATS4e', 'ETA_BetaP', 'AATS4m', 'khs.sOH', 'AATS4i', 'SHsOH', 'SpMax_D', 'MDEN-13', 'MDEN-12', 'MDEN-11', 'ntsC', 'ATS3m', 'PetitjeanNumber', 'khs.aasN', 'khs.aasC', 'MWC10', 'MPC7', 'TWC', 'topoRadius', 'WPATH', 'nG', 'ndsN', 'MAXDP', 'naaaC', 'SM1_DzZ', 'SpAbs_DzZ', 'SpAbs_Dze', 'khs.aaNH', 'SpAbs_Dzm', 'SM1_Dzv', 'SpAbs_Dzi', 'SM1_Dzp', 'SM1_Dzs', 'SM1_Dzm', 'SpAbs_Dzv', 'SM1_Dzi', 'SpAbs_Dzp', 'SpAbs_Dzs', 'SM1_Dze', 'maxaaCH', 'maxdO', 'nF11Ring', 'GATS2v', 'GATS2s', 'ETA_Beta', 'GATS2m', 'GATS2i', 'maxdS', 'GATS2e', 'GATS2c', 'nHaaNH', 'ATSC1p', 'ATSC1s', 'ATSC1v', 'ATSC1c', 'ATSC1e', 'ATSC1i', 'ATSC1m', 'MWC9', 'MWC8', 'MWC5', 'MWC4', 'MWC7', 'MWC6', 'ndssC', 'MWC2', 'MAXDN2', 'MATS5e', 'SpMin2_Bhe', 'MATS5c', 'MATS5m', 'SpMin2_Bhm', 'MATS5i', 'SpMin2_Bhi', 'SpMin2_Bhv', 'MATS5v', 'MATS5p', 'SpMin2_Bhs', 'SpMin2_Bhp', 'VE1_Dzi', 'Mare', 'BCUTc-1l', 'BCUTc-1h', 'SssNH', 'MPC9', 'VE1_Dzp', 'naaN', 'naaO', 'naaS', 'SsBr', 'SHBd', 'TSRW', 'SHBa', 'khs.ssNH', 'nT9HeteroRing', 'SpMax6_Bhp', 'SpMax6_Bhs', 'SpMAD_Dzv', 'SpMax6_Bhv', 'SpMax6_Bhe', 'SpMAD_Dze', 'SpMax6_Bhi', 'SpMAD_Dzi', 'SpMax6_Bhm', 'SpMAD_Dzm', 'SpMAD_DzZ', 'AATSC8s', 'AATSC8p', 'AATSC8v', 'minHssNH', 'AATSC8c', 'AATSC8e', 'AATSC8i', 'AATSC8m', 'AATS3s', 'AATS3p', 'AATS3v', 'SpMin5_Bhv', 'SpMin5_Bhp', 'SpMin5_Bhs', 'SpMin5_Bhm', 'SpMin5_Bhi', 'AATS3e', 'SpMin5_Bhe', 'AATS3i', 'SpMAD_Dzs', 'AATS3m', 'n7Ring', 'maxdCH2', 'MLFER_L', 'GATS5s', 'GATS5p', 'GATS5v', 'MLFER_A', 'GATS5i', 'GATS5m', 'IC3', 'IC2', 'IC1', 'IC0', 'khs.tN', 'IC5', 'IC4', 'ETA_Eta_R', 'ETA_Eta_L', 'SHdCH2', 'ETA_Eta_B', 'ETA_Eta_F', 'SaaCH', 'nAcid', 'maxsssCH', 'SsCl', 'nF6Ring', 'maxsF', 'MATS4c', 'MATS4e', 'MATS4i', 'SP-4', 'MATS4m', 'MATS4s', 'MATS4p', 'MATS4v', 'minHdNH', 'VC-6', 'SsssN', 'minaaaC', 'minwHBa', 'nT6HeteroRing', 'khs.dssC', 'AATSC0m', 'EE_Dt', 'minsF', 'ATSC0v', 'ATSC0s', 'ATSC0p', 'ATSC0m', 'ATSC0i', 'ATSC0e', 'ATSC0c', 'VE2_D', 'SpMAD_D', 'nHBint2', 'nHBint3', 'ETA_Epsilon_1', 'nHBint6', 'nHBint7', 'nHBint4', 'nHBint5', 'nHBint8', 'nHBint9', 'nBondsS', 'AATS2p', 'AATS2s', 'nBondsT', 'AATS2e', 'nBondsD', 'AATS2i', 'AATS2m', 'nBondsM', 'nBonds2', 'MDEN-33', 'Sp', 'Sv', 'Si', 'FMF', 'nRotB', 'n7HeteroRing', 'minssssC', 'SwHBa', 'Zagreb', 'SRW6', 'SRW7', 'SRW4', 'SRW5', 'SRW2', 'khs.sCl', 'SRW8', 'SRW9', 'maxHsNH2', 'SCH-5', 'SCH-6', 'SCH-7', 'khs.sF', 'nF9Ring', 'ATS6p', 'maxaasN', 'MAXDP2', 'minHtCH', 'nsNH2', 'nFG12Ring', 'VE1_DzZ', 'VE1_Dze', 'GATS4p', 'GATS4s', 'VE1_Dzm', 'GATS4v', 'GATS4i', 'VE1_Dzs', 'GATS4m', 'ndsCH', 'VE1_Dzv', 'GATS4c', 'GATS4e', 'ETA_Beta_ns', 'McGowan_Volume', 'n5Ring', 'ETA_dAlpha_B', 'ATSC7s', 'ATSC7p', 'ETA_dAlpha_A', 'ATSC7v', 'ATSC7i', 'ATSC7m', 'ATSC7c', 'VC-4', 'VC-5', 'VC-3', 'ATSC7e', 'maxssssNp', 'JGI2', 'JGI3', 'JGI1', 'JGI6', 'JGI7', 'JGI4', 'JGI5', 'JGI8', 'JGI9', 'SpAD_DzZ', 'SpAD_Dze', 'SpAD_Dzm', 'SpAD_Dzi', 'SpAD_Dzv', 'SpAD_Dzp', 'SpAD_Dzs', 'nsssCH', 'nBonds', 'LipinskiFailures', 'SpDiam_D', 'minHdsCH', 'SssO', 'SssS', 'C2SP3', 'C2SP2', 'C2SP1', 'GATS2p', 'ETA_Shape_X', 'ETA_Shape_Y', 'ETA_Shape_P', 'naaNH', 'khs.dCH2', 'AVP-5', 'AVP-4', 'AVP-7', 'AVP-1', 'AVP-0', 'AVP-2', 'AATS1v', 'AATS1p', 'AATS1s', 'AATS1m', 'MDEN-22', 'AATS1i', 'AATS1e', 'maxaaNH', 'maxHaaNH', 'nT8HeteroRing', 'GATS7c', 'GATS7m', 'GATS7v', 'GATS7p', 'GATS7s', 'SsOm', 'SsOH', 'AATSC4v', 'maxHBd', 'AATSC4s', 'khs.sBr', 'maxHBa', 'khs.dsN', 'SHssNH', 'AATSC4e', 'AATSC4c', 'AATSC4m', 'AATSC4i', 'SHBint10', 'ATS2v', 'ATS2p', 'ATS2s', 'CrippenLogP', 'ATS2i', 'JGT', 'MPC10', 'ndNH', 'VAdjMat', 'khs.ddssS', 'nT7Ring', 'khs.dsCH', 'ATSC6p', 'ATSC6s', 'ATSC6v', 'ATSC6i', 'ATSC6m', 'ATSC6c', 'ATSC6e', 'SpMin1_Bhi', 'SpMin1_Bhm', 'SpMin1_Bhp', 'SpMin1_Bhs', 'nT11HeteroRing', 'SpMin1_Bhv', 'SHother', 'AATS0s', 'SpMin4_Bhv', 'AATS0p', 'SpMin4_Bhp', 'AATS0v', 'SpMin4_Bhs', 'SpMin4_Bhm', 'AATS0i', 'SpMin4_Bhi', 'AATS0m', 'minsssCH', 'SpMin4_Bhe', 'nAtomLAC', 'AATS0e', 'nsCH3', 'MWC3', 'ATSC5v', 'MLFER_S', 'ETA_dBetaP', 'AATSC4p', 'nRotBt', 'nsOm', 'SHaaNH', 'nsOH', 'AATSC5v', 'AATSC5s', 'nssssNp', 'AATSC5e', 'naasN', 'AATSC5c', 'AATSC5m', 'nsssN', 'SpMax_Dt', 'AATSC5i', 'naasC', 'VR3_D', 'VR1_D', 'VR1_Dt', 'ETA_Epsilon_2', 'MLogP', 'nHBAcc2', 'nHBAcc3', 'AMR', 'AMW', 'GATS6c', 'sumI', 'GATS6e', 'gmax', 'maxHssNH', 'MATS5s', 'maxsNH2', 'GATS6m', 'maxHBint8', 'maxHBint9', 'GATS6p', 'C1SP2', 'C1SP3', 'khs.tsC', 'maxHBint2', 'maxHBint3', 'maxHBint4', 'maxHBint5', 'maxHBint6', 'maxHBint7', 'AVP-6', 'nHdNH', 'ATSC5e', 'C4SP3', 'AVP-3', 'ATSC5c', 'ATSC5m', 'nHother', 'ATSC5i', 'VCH-5', 'VCH-7', 'VCH-6', 'Mse', 'nsF', 'DELS2', 'MATS8m', 'ATS3v', 'ATS3s', 'ATS3p', 'ATS3e', 'MATS8i', 'Kier2', 'Kier3', 'Kier1', 'HybRatio', 'ATS3i', 'MDEN-23', 'SHBint9', 'SHBint8', 'SHBint3', 'SHBint2', 'SHBint7', 'SHBint6', 'SHBint5', 'SHBint4', 'DELS', 'minHsNH2', 'nHeteroRing', 'GATS7e', 'ETA_Psi_1', 'mindssC', 'nwHBa', 'maxHBint10', 'mindNH', 'GATS7i', 'nHssNH', 'nAtom', 'Spe', 'khs.dS', 'khs.dO', 'maxwHBa', 'AATSC6p', 'AATSC6s', 'AATSC6v', 'AATSC6c', 'AATSC6e', 'AATSC6i', 'AATSC6m', 'SssssNp', 'AATSC7c', 'nssCH2', 'ASP-2', 'ASP-3', 'ASP-0', 'ASP-1', 'ASP-6', 'ASP-7', 'ASP-4', 'ASP-5', 'ATS0s', 'MATS8v', 'ATS0p', 'MATS8s', 'ATS0v', 'MATS8p', 'MATS8e', 'MATS8c', 'ATS0e', 'ATS0i', 'ATS0m', 'GGI9', 'GGI8', 'GGI1', 'GGI3', 'GGI2', 'GGI5', 'GGI4', 'GGI7', 'GGI6', 'nTRing', 'nT10Ring', 'TIC0', 'TIC1', 'TIC2', 'TIC3', 'TIC4', 'TIC5', 'maxsCl', 'ntCH', 'khs.aaCH', 'ZMIC4', 'ZMIC5', 'ZMIC0', 'ZMIC1', 'ZMIC2', 'ZMIC3', 'minHother', 'ATSC4c', 'ATSC4e', 'ATSC4i', 'ATSC4m', 'ATSC4s', 'ATSC4p', 'ATSC4v', 'SpMax1_Bhs', 'SpMax1_Bhp', 'SpMax1_Bhv', 'hmin', 'SpMax1_Bhe', 'SpMax1_Bhi', 'SpMax1_Bhm', 'MPC6', 'nAtomP', 'MPC4', 'MPC5', 'MPC2', 'VR3_Dzv', 'VR3_Dzs', 'MPC8', 'VR3_Dzp', 'VR3_Dzm', 'SpMAD_Dzp', 'VR3_Dzi', 'VR3_Dze', 'SsF', 'minaaO', 'VR3_DzZ', 'mintCH', 'Sse', 'C3SP2', 'VR1_DzZ', 'VR1_Dzp', 'VR1_Dzs', 'SdCH2', 'SHtCH', 'VR1_Dzi', 'VR1_Dzm', 'VR1_Dze', 'maxdsN', 'AATSC7v', 'AATSC7s', 'AATSC7p', 'AATSC7m', 'AATSC7i', 'nHdsCH', 'AATSC7e', 'BIC2', 'BIC3', 'BIC0', 'BIC1', 'SIC5', 'SIC4', 'SIC1', 'SIC0', 'SIC3', 'SIC2', 'naaCH', 'minHBd', 'minHBa', 'AATSC1p', 'nssO', 'AATSC0i', 'ALogp2', 'nssS', 'AATSC1i', 'SaaS', 'SaaO', 'SaaN', 'maxsBr', 'GATS8m', 'SpMax2_Bhv', 'GATS8i', 'SpMax2_Bhs', 'GATS8e', 'GATS8c', 'SpMax2_Bhe', 'SpMax2_Bhm', 'GATS8v', 'GATS8p', 'GATS8s', 'piPC3', 'piPC2', 'piPC1', 'piPC7', 'piPC6', 'piPC5', 'piPC4', 'piPC9', 'piPC8', 'maxHdsCH', 'nT11Ring', 'ATS1v', 'ATS1p', 'ATS1s', 'ATS1i', 'SpMAD_Dt', 'ATS1e', 'VR2_Dzi', 'n6HeteroRing', 'MPC3', 'ATS2e', 'VR2_Dzv', 'minHBint9', 'VE2_Dzs', 'VE2_Dzp', 'VE2_Dzv', 'ATS2m', 'VE2_Dzi', 'VE2_Dzm', 'maxtCH', 'minaaNH', 'VE2_Dze', 'VE2_DzZ', 'nHAvin', 'meanI', 'nHCsatu', 'nHCsats', 'apol', 'ATS5i', 'nF12Ring', 'mindS', 'mindO', 'MolIP', 'maxdsCH', 'ndCH2', 'TopoPSA', 'ETA_EtaP_B_RC', 'MDEO-11', 'MDEO-12', 'AATSC0s', 'SpMax5_Bhv', 'AATSC0p', 'SpMax5_Bhs', 'AATSC0v', 'SpMax5_Bhp', 'SpMax5_Bhm', 'SpMax5_Bhi', 'AATSC0c', 'SpMax5_Bhe', 'AATSC0e', 'EE_D', 'VE3_DzZ', 'C3SP3', 'VE3_Dzv', 'minddssS', 'ATS6s', 'VE3_Dzs', 'VE3_Dzp', 'ATS6v', 'ATS6i', 'VE3_Dzm', 'ATS6m', 'VE3_Dzi', 'VE3_Dze', 'ATS6e', 'nTG12HeteroRing', 'VPC-6', 'VPC-5', 'VPC-4', 'MLFER_E', 'nBondsD2', 'nT12Ring', 'Mpe', 'maxHdCH2', 'nT5HeteroRing', 'nHeavyAtom', 'nRing', 'GATS5c', 'nF12HeteroRing', 'GATS5e', 'VR1_Dzv', 'minsssN', 'topoShape', 'ndO', 'ndS', 'nssNH', 'VE1_Dt', 'maxHaaCH', 'nHBAcc', 'VE3_D', 'nsCl', 'VE1_D', 'AATSC1s', 'AATSC1v', 'AATSC1m', 'AATSC1c', 'AATSC1e', 'LipoaffinityIndex', 'n6Ring', 'ETA_Eta', 'WTPT-1', 'WTPT-2', 'WTPT-3', 'WTPT-4', 'WTPT-5', 'ETA_EtaP_L', 'ETA_EtaP_F', 'ETA_EtaP_B', 'nT5Ring', 'SHdNH', 'ETA_dEpsilon_C', 'MDEO-22', 'Class']\n",
      "\n",
      "Features shape: (171, 1203)\n",
      "Target shape: (171,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Separate features and target\n",
    "# Assuming the last column or a column named 'Class' contains the target\n",
    "if 'Class' in data.columns:\n",
    "    X = data.drop('Class', axis=1)\n",
    "    y = data['Class']\n",
    "else:\n",
    "    # Assume last column is the target\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.075327Z",
     "iopub.status.busy": "2025-09-18T04:07:14.074981Z",
     "iopub.status.idle": "2025-09-18T04:07:14.091774Z",
     "shell.execute_reply": "2025-09-18T04:07:14.090085Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.075303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA EXPLORATION ===\n",
      "Shape of features (X): (171, 1203)\n",
      "Shape of target (y): (171,)\n",
      "\n",
      "Target distribution:\n",
      "Class\n",
      "NonToxic    115\n",
      "Toxic        56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance:\n",
      "Class\n",
      "NonToxic    0.672515\n",
      "Toxic       0.327485\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target data type: object\n",
      "Unique target values: ['NonToxic' 'Toxic']\n"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(\"\\n=== DATA EXPLORATION ===\")\n",
    "print(f\"Shape of features (X): {X.shape}\")\n",
    "print(f\"Shape of target (y): {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass balance:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Check target data type and unique values\n",
    "print(f\"\\nTarget data type: {y.dtype}\")\n",
    "print(f\"Unique target values: {y.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.092964Z",
     "iopub.status.busy": "2025-09-18T04:07:14.092654Z",
     "iopub.status.idle": "2025-09-18T04:07:14.127069Z",
     "shell.execute_reply": "2025-09-18T04:07:14.125982Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.092939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in features: 0\n",
      "Missing values in target: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(f\"\\nMissing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.128382Z",
     "iopub.status.busy": "2025-09-18T04:07:14.128095Z",
     "iopub.status.idle": "2025-09-18T04:07:14.163758Z",
     "shell.execute_reply": "2025-09-18T04:07:14.162588Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.128359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPROCESSING ===\n",
      "Missing values in features: 0\n",
      "Missing values in target: 0\n",
      "\n",
      "Binary target distribution:\n",
      "Class\n",
      "1    115\n",
      "0     56\n",
      "Name: count, dtype: int64\n",
      "Class balance: Class\n",
      "1    0.672515\n",
      "0    0.327485\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Mapping verification:\n",
      "Original 'NonToxic' ‚Üí Binary 1: [1]\n",
      "Original 'Toxic' ‚Üí Binary 0: [0]\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values if any\n",
    "print(\"=== PREPROCESSING ===\")\n",
    "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n",
    "\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    # Option 1: Drop columns with too many missing values\n",
    "    missing_threshold = 0.3  # Drop columns with >30% missing\n",
    "    missing_prop = X.isnull().sum() / len(X)\n",
    "    cols_to_drop = missing_prop[missing_prop > missing_threshold].index\n",
    "    X = X.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Option 2: Impute remaining missing values\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    print(f\"Missing values imputed\")\n",
    "\n",
    "# Convert target to binary (1 for NonToxic, 0 for Toxic) - FLIPPED LABELS\n",
    "y_binary = (y == 'NonToxic').astype(int)\n",
    "\n",
    "# Verify the binary conversion\n",
    "print(\"\\nBinary target distribution:\")\n",
    "print(y_binary.value_counts())\n",
    "print(f\"Class balance: {y_binary.value_counts(normalize=True)}\")\n",
    "\n",
    "# Double-check the conversion is correct\n",
    "print(f\"\\nMapping verification:\")\n",
    "print(f\"Original 'NonToxic' ‚Üí Binary 1: {y_binary[y == 'NonToxic'].unique()}\")\n",
    "print(f\"Original 'Toxic' ‚Üí Binary 0: {y_binary[y == 'Toxic'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.165321Z",
     "iopub.status.busy": "2025-09-18T04:07:14.165004Z",
     "iopub.status.idle": "2025-09-18T04:07:14.910757Z",
     "shell.execute_reply": "2025-09-18T04:07:14.909482Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.165298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE PREPROCESSING ===\n",
      "Removed 0 constant features\n",
      "Remaining features after variance filtering: 994\n",
      "Removed 434 highly correlated features\n",
      "Final feature count: 560\n"
     ]
    }
   ],
   "source": [
    "# Feature preprocessing\n",
    "print(\"\\n=== FEATURE PREPROCESSING ===\")\n",
    "\n",
    "# Remove constant features\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "X_filtered = constant_filter.fit_transform(X)\n",
    "constant_columns = X.columns[~constant_filter.get_support()]\n",
    "print(f\"Removed {len(constant_columns)} constant features\")\n",
    "\n",
    "# Remove quasi-constant features (variance < 0.01)\n",
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)\n",
    "X_filtered = quasi_constant_filter.fit_transform(X_filtered)\n",
    "selected_features = X.columns[constant_filter.get_support()][quasi_constant_filter.get_support()]\n",
    "X_filtered = pd.DataFrame(X_filtered, columns=selected_features)\n",
    "print(f\"Remaining features after variance filtering: {X_filtered.shape[1]}\")\n",
    "\n",
    "# Remove highly correlated features\n",
    "correlation_matrix = X_filtered.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(\n",
    "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "high_corr_features = [column for column in upper_triangle.columns \n",
    "                      if any(upper_triangle[column] > 0.95)]\n",
    "X_filtered = X_filtered.drop(columns=high_corr_features)\n",
    "print(f\"Removed {len(high_corr_features)} highly correlated features\")\n",
    "print(f\"Final feature count: {X_filtered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.912087Z",
     "iopub.status.busy": "2025-09-18T04:07:14.911762Z",
     "iopub.status.idle": "2025-09-18T04:07:14.946771Z",
     "shell.execute_reply": "2025-09-18T04:07:14.945787Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.912060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (136, 560)\n",
      "Test set size: (35, 560)\n",
      "\n",
      "Train set class distribution:\n",
      "Class\n",
      "1    0.669118\n",
      "0    0.330882\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "Class\n",
      "1    0.685714\n",
      "0    0.314286\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data with stratification to ensure balanced folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Add some randomness to address potential ordering issues\n",
    "np.random.seed(42)\n",
    "shuffle_idx = np.random.permutation(len(X_filtered))\n",
    "X_shuffled = X_filtered.iloc[shuffle_idx].reset_index(drop=True)\n",
    "y_shuffled = y_binary.iloc[shuffle_idx].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_shuffled, y_shuffled, test_size=0.2, random_state=42, \n",
    "    stratify=y_shuffled, shuffle=True\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train_scaled.shape}\")\n",
    "print(f\"Test set size: {X_test_scaled.shape}\")\n",
    "\n",
    "# Check class distribution in train and test sets\n",
    "print(f\"\\nTrain set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.948302Z",
     "iopub.status.busy": "2025-09-18T04:07:14.947976Z",
     "iopub.status.idle": "2025-09-18T04:07:14.956524Z",
     "shell.execute_reply": "2025-09-18T04:07:14.955228Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.948279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate a classification model and return metrics\"\"\"\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Probabilities for AUC\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_train_proba = model.decision_function(X_train)\n",
    "        y_test_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'train_auc': roc_auc_score(y_train, y_train_proba),\n",
    "        'test_auc': roc_auc_score(y_test, y_test_proba),\n",
    "        'precision': precision_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'f1': f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_test_pred, y_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.960480Z",
     "iopub.status.busy": "2025-09-18T04:07:14.960129Z",
     "iopub.status.idle": "2025-09-18T04:07:14.990137Z",
     "shell.execute_reply": "2025-09-18T04:07:14.988942Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.960456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize results storage\n",
    "results = []\n",
    "all_predictions = {}\n",
    "all_probabilities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.991219Z",
     "iopub.status.busy": "2025-09-18T04:07:14.990992Z",
     "iopub.status.idle": "2025-09-18T04:07:15.021271Z",
     "shell.execute_reply": "2025-09-18T04:07:15.019782Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.991202Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON: ORDINARY VS PENALIZED REGRESSION\n",
      "================================================================================\n",
      "\n",
      "This analysis compares the following models:\n",
      "1. Ordinary Logistic Regression (no regularization) - Baseline\n",
      "2. Ridge Regression (L2 penalty) - Shrinks coefficients\n",
      "3. Lasso Regression (L1 penalty) - Feature selection + shrinkage  \n",
      "4. Elastic Net (L1 + L2 penalty) - Combines both approaches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON: ORDINARY VS PENALIZED REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This analysis compares the following models:\n",
    "1. Ordinary Logistic Regression (no regularization) - Baseline\n",
    "2. Ridge Regression (L2 penalty) - Shrinks coefficients\n",
    "3. Lasso Regression (L1 penalty) - Feature selection + shrinkage  \n",
    "4. Elastic Net (L1 + L2 penalty) - Combines both approaches\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0. ORDINARY LOGISTIC REGRESSION (BASELINE)\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.6286\n",
      "Test AUC: 0.5909\n",
      "Precision: 0.7619\n",
      "Recall: 0.6667\n",
      "F1-Score: 0.7111\n",
      "Overfitting Gap (Train - Test Accuracy): 0.3714\n",
      "‚ö†Ô∏è  Significant overfitting detected - penalized methods should help!\n"
     ]
    }
   ],
   "source": [
    "# 0. Ordinary Logistic Regression (Baseline)\n",
    "print(\"\\n0. ORDINARY LOGISTIC REGRESSION (BASELINE)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# No regularization - this is our baseline to compare against penalized methods\n",
    "ordinary_lr = LogisticRegression(penalty=None, max_iter=2000, solver='lbfgs')\n",
    "ordinary_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate ordinary logistic regression\n",
    "ordinary_metrics, ordinary_pred, ordinary_proba = evaluate_model(\n",
    "    ordinary_lr, X_train_scaled, X_test_scaled, y_train, y_test, 'Ordinary LR'\n",
    ")\n",
    "results.append(ordinary_metrics)\n",
    "all_predictions['Ordinary LR'] = ordinary_pred\n",
    "all_probabilities['Ordinary LR'] = ordinary_proba\n",
    "\n",
    "print(f\"Training Accuracy: {ordinary_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {ordinary_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {ordinary_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {ordinary_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ordinary_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {ordinary_metrics['f1']:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfitting = ordinary_metrics['train_accuracy'] - ordinary_metrics['test_accuracy']\n",
    "print(f\"Overfitting Gap (Train - Test Accuracy): {overfitting:.4f}\")\n",
    "if overfitting > 0.05:\n",
    "    print(\"‚ö†Ô∏è  Significant overfitting detected - penalized methods should help!\")\n",
    "else:\n",
    "    print(\"‚úì Low overfitting - but regularization may still improve generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:15.023125Z",
     "iopub.status.busy": "2025-09-18T04:07:15.022853Z",
     "iopub.status.idle": "2025-09-18T04:07:15.225523Z",
     "shell.execute_reply": "2025-09-18T04:07:15.223612Z",
     "shell.execute_reply.started": "2025-09-18T04:07:15.023105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. RIDGE REGRESSION (L2 REGULARIZATION)\n",
      "--------------------------------------------------\n",
      "Best Ridge parameter (C): 0.000001\n",
      "Best CV AUC score: 0.4270\n",
      "Training Accuracy: 0.6691\n",
      "Test Accuracy: 0.6857\n",
      "Test AUC: 0.5530\n",
      "Precision: 0.6857\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8136\n",
      "\n",
      "Improvement over Ordinary LR:\n",
      "  AUC: -0.0379\n",
      "  Accuracy: +0.0571\n"
     ]
    }
   ],
   "source": [
    "# Define stratified cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# 1. Ridge Regression (L2 Regularization)\n",
    "print(\"\\n1. RIDGE REGRESSION (L2 REGULARIZATION)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use broad parameter range for comprehensive comparison\n",
    "ridge_params = {'C': np.logspace(-6, 6, 25)}  # Broader range\n",
    "ridge = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=2000)\n",
    "\n",
    "# Use StratifiedKFold to ensure balanced folds\n",
    "ridge_cv = GridSearchCV(\n",
    "    ridge, ridge_params, \n",
    "    cv=stratified_cv, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best Ridge parameter (C): {ridge_cv.best_params_['C']:.6f}\")\n",
    "print(f\"Best CV AUC score: {ridge_cv.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "ridge_metrics, ridge_pred, ridge_proba = evaluate_model(\n",
    "    ridge_cv.best_estimator_, X_train_scaled, X_test_scaled, y_train, y_test, 'Ridge'\n",
    ")\n",
    "results.append(ridge_metrics)\n",
    "all_predictions['Ridge'] = ridge_pred\n",
    "all_probabilities['Ridge'] = ridge_proba\n",
    "\n",
    "# Display results\n",
    "print(f\"Training Accuracy: {ridge_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {ridge_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {ridge_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {ridge_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ridge_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {ridge_metrics['f1']:.4f}\")\n",
    "\n",
    "# Compare with ordinary LR\n",
    "improvement_auc = ridge_metrics['test_auc'] - ordinary_metrics['test_auc']\n",
    "improvement_acc = ridge_metrics['test_accuracy'] - ordinary_metrics['test_accuracy']\n",
    "print(f\"\\nImprovement over Ordinary LR:\")\n",
    "print(f\"  AUC: {improvement_auc:+.4f}\")\n",
    "print(f\"  Accuracy: {improvement_acc:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-18T04:07:15.226355Z",
     "iopub.status.idle": "2025-09-18T04:07:15.226666Z",
     "shell.execute_reply": "2025-09-18T04:07:15.226550Z",
     "shell.execute_reply.started": "2025-09-18T04:07:15.226537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. LASSO REGRESSION (L1 REGULARIZATION) - IMPROVED ANALYSIS\n",
      "------------------------------------------------------------\n",
      "üîç DIAGNOSTIC: Testing different regularization strengths...\n",
      "C=100.00:  105 features, AUC=0.5114, max|coef|=5.352088\n",
      "C= 50.00:  103 features, AUC=0.5076, max|coef|=5.096339\n",
      "C= 20.00:   90 features, AUC=0.5303, max|coef|=4.379703\n",
      "C= 10.00:   92 features, AUC=0.5265, max|coef|=3.826230\n",
      "C=  5.00:   87 features, AUC=0.5265, max|coef|=2.938843\n",
      "C=  2.00:   88 features, AUC=0.5455, max|coef|=1.553257\n",
      "C=  1.00:   80 features, AUC=0.5492, max|coef|=1.012076\n",
      "C=  0.50:   70 features, AUC=0.5720, max|coef|=0.781104\n",
      "C=  0.10:    4 features, AUC=0.5114, max|coef|=0.099917\n",
      "C=  0.05:    0 features, AUC=0.5000, max|coef|=0.000000\n",
      "C=  0.01:    0 features, AUC=0.5000, max|coef|=0.000000\n",
      "\n",
      "üìä Features selected in C range: [0.10, 100.00]\n",
      "üéØ Using focused C range: [0.100, 100.000]\n",
      "\n",
      "üîÑ Running Grid Search with 20 parameter values...\n",
      "‚úÖ Best Lasso parameter (C): 0.100000\n",
      "‚úÖ Best CV AUC score: 0.4352\n",
      "\n",
      "üìà LASSO RESULTS:\n",
      "Training Accuracy: 0.6691\n",
      "Test Accuracy: 0.6857\n",
      "Test AUC: 0.5114\n",
      "Precision: 0.6857\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8136\n",
      "\n",
      "üéØ FEATURE SELECTION ANALYSIS:\n",
      "Features selected: 4/560 (0.7%)\n",
      "Maximum coefficient magnitude: 0.099872\n",
      "\n",
      "üèÜ TOP 10 SELECTED FEATURES:\n",
      " 1. Feature_397 ‚Üì  -0.0999\n",
      " 2. Feature_210 ‚Üì  -0.0634\n",
      " 3. Feature_317 ‚Üì  -0.0407\n",
      " 4. Feature_351 ‚Üì  -0.0350\n",
      "\n",
      "üìä IMPROVEMENT OVER ORDINARY LR:\n",
      "  AUC improvement: -0.0795\n",
      "  Accuracy improvement: +0.0571\n",
      "  Feature reduction: 556 features removed\n",
      "‚ö†Ô∏è Performance decreased - regularization may be too strong\n",
      "\n",
      "üìä CROSS-VALIDATION SCORE DISTRIBUTION:\n",
      "   Mean CV AUC: 0.3926 ¬± 0.0187\n",
      "   Min CV AUC:  0.3564\n",
      "   Max CV AUC:  0.4352\n",
      "   ‚úÖ Reasonably stable performance\n"
     ]
    }
   ],
   "source": [
    "# 2. Lasso Regression (L1 Regularization) - IMPROVED ANALYSIS\n",
    "print(\"\\n2. LASSO REGRESSION (L1 REGULARIZATION) - IMPROVED ANALYSIS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Test multiple C ranges to understand the behavior\n",
    "print(\"üîç DIAGNOSTIC: Testing different regularization strengths...\")\n",
    "\n",
    "# Start with very weak regularization to see if any features can be selected\n",
    "test_c_values = [100, 50, 20, 10, 5, 2, 1, 0.5, 0.1, 0.05, 0.01]\n",
    "diagnostic_results = []\n",
    "\n",
    "for c_val in test_c_values:\n",
    "    test_lasso = LogisticRegression(penalty='l1', solver='liblinear', C=c_val, max_iter=2000)\n",
    "    test_lasso.fit(X_train_scaled, y_train)\n",
    "    n_selected = np.sum(test_lasso.coef_[0] != 0)\n",
    "    test_proba = test_lasso.predict_proba(X_test_scaled)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "    \n",
    "    diagnostic_results.append({\n",
    "        'C': c_val,\n",
    "        'n_features': n_selected,\n",
    "        'test_auc': test_auc,\n",
    "        'max_coef': np.max(np.abs(test_lasso.coef_[0])) if n_selected > 0 else 0\n",
    "    })\n",
    "    \n",
    "    print(f\"C={c_val:6.2f}: {n_selected:4d} features, AUC={test_auc:.4f}, max|coef|={np.max(np.abs(test_lasso.coef_[0])):.6f}\")\n",
    "\n",
    "# Find the range where features start being selected\n",
    "non_zero_results = [r for r in diagnostic_results if r['n_features'] > 0]\n",
    "if non_zero_results:\n",
    "    min_c_with_features = min(r['C'] for r in non_zero_results)\n",
    "    max_c_with_features = max(r['C'] for r in non_zero_results)\n",
    "    print(f\"\\nüìä Features selected in C range: [{min_c_with_features:.2f}, {max_c_with_features:.2f}]\")\n",
    "    \n",
    "    # Use a focused range around where features are actually selected\n",
    "    if min_c_with_features <= 10:\n",
    "        lasso_params = {'C': np.logspace(np.log10(max(min_c_with_features/2, 0.1)), \n",
    "                                        np.log10(min(max_c_with_features*2, 100)), 20)}\n",
    "    else:\n",
    "        lasso_params = {'C': np.logspace(1, 2, 20)}  # Focus on C=[10, 100]\n",
    "    \n",
    "    print(f\"üéØ Using focused C range: [{min(lasso_params['C']):.3f}, {max(lasso_params['C']):.3f}]\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: No features selected even with very weak regularization (C=100)\")\n",
    "    print(\"This strongly suggests that predictor effects are extremely weak relative to noise.\")\n",
    "    print(\"Using minimal regularization range for analysis...\")\n",
    "    lasso_params = {'C': np.logspace(1, 3, 20)}  # C from 10 to 1000\n",
    "\n",
    "# Create stratified CV if not already defined\n",
    "if 'stratified_cv' not in locals():\n",
    "    stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search with the focused parameter range\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', max_iter=2000)\n",
    "lasso_cv = GridSearchCV(\n",
    "    lasso, lasso_params, \n",
    "    cv=stratified_cv, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÑ Running Grid Search with {len(lasso_params['C'])} parameter values...\")\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"‚úÖ Best Lasso parameter (C): {lasso_cv.best_params_['C']:.6f}\")\n",
    "print(f\"‚úÖ Best CV AUC score: {lasso_cv.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "lasso_metrics, lasso_pred, lasso_proba = evaluate_model(\n",
    "    lasso_cv.best_estimator_, X_train_scaled, X_test_scaled, y_train, y_test, 'Lasso'\n",
    ")\n",
    "results.append(lasso_metrics)\n",
    "all_predictions['Lasso'] = lasso_pred\n",
    "all_probabilities['Lasso'] = lasso_proba\n",
    "\n",
    "# Detailed coefficient analysis\n",
    "lasso_coef = lasso_cv.best_estimator_.coef_[0]\n",
    "n_selected_features = np.sum(lasso_coef != 0)\n",
    "max_coef_magnitude = np.max(np.abs(lasso_coef)) if n_selected_features > 0 else 0\n",
    "\n",
    "# Display comprehensive results\n",
    "print(f\"\\nüìà LASSO RESULTS:\")\n",
    "print(f\"Training Accuracy: {lasso_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {lasso_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {lasso_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {lasso_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {lasso_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {lasso_metrics['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ FEATURE SELECTION ANALYSIS:\")\n",
    "print(f\"Features selected: {n_selected_features}/{X_train_scaled.shape[1]} ({n_selected_features/X_train_scaled.shape[1]*100:.1f}%)\")\n",
    "print(f\"Maximum coefficient magnitude: {max_coef_magnitude:.6f}\")\n",
    "\n",
    "if n_selected_features > 0:\n",
    "    # Show the most important selected features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature_idx': range(len(lasso_coef)),\n",
    "        'coefficient': lasso_coef,\n",
    "        'abs_coefficient': np.abs(lasso_coef)\n",
    "    })\n",
    "    \n",
    "    selected_features = feature_importance[feature_importance['coefficient'] != 0]\n",
    "    selected_features = selected_features.sort_values('abs_coefficient', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüèÜ TOP 10 SELECTED FEATURES:\")\n",
    "    for i, (_, row) in enumerate(selected_features.head(10).iterrows(), 1):\n",
    "        direction = \"‚Üë\" if row['coefficient'] > 0 else \"‚Üì\"\n",
    "        print(f\"{i:2d}. Feature_{int(row['feature_idx']):3d} {direction} {row['coefficient']:8.4f}\")\n",
    "    \n",
    "    # Compare with ordinary LR if available\n",
    "    if 'ordinary_metrics' in locals():\n",
    "        improvement_auc = lasso_metrics['test_auc'] - ordinary_metrics['test_auc']\n",
    "        improvement_acc = lasso_metrics['test_accuracy'] - ordinary_metrics['test_accuracy']\n",
    "        print(f\"\\nüìä IMPROVEMENT OVER ORDINARY LR:\")\n",
    "        print(f\"  AUC improvement: {improvement_auc:+.4f}\")\n",
    "        print(f\"  Accuracy improvement: {improvement_acc:+.4f}\")\n",
    "        print(f\"  Feature reduction: {X_train_scaled.shape[1] - n_selected_features} features removed\")\n",
    "        \n",
    "        if improvement_auc > 0.01:\n",
    "            print(\"‚úÖ Meaningful improvement achieved through regularization\")\n",
    "        elif improvement_auc > -0.01:\n",
    "            print(\"‚ûñ Modest performance with significant dimensionality reduction\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Performance decreased - regularization may be too strong\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO FEATURES SELECTED - COMPLETE FEATURE ELIMINATION\")\n",
    "    print(\"\\nüî¨ DETAILED ANALYSIS:\")\n",
    "    print(f\"   ‚Ä¢ Best C parameter: {lasso_cv.best_params_['C']:.6f}\")\n",
    "    print(f\"   ‚Ä¢ All {X_train_scaled.shape[1]} coefficients set to exactly zero\")\n",
    "    print(f\"   ‚Ä¢ Model defaults to predicting class proportions (AUC ‚âà 0.5)\")\n",
    "    print(f\"   ‚Ä¢ This indicates extremely weak signal-to-noise ratio\")\n",
    "    \n",
    "    print(f\"\\nüí° IMPLICATIONS:\")\n",
    "    print(f\"   ‚Ä¢ Individual features have negligible predictive power\")\n",
    "    print(f\"   ‚Ä¢ High dimensionality (p={X_train_scaled.shape[1]}) vs sample size (n={X_train_scaled.shape[0]})\")\n",
    "    print(f\"   ‚Ä¢ Possible multicollinearity masking true relationships\")\n",
    "    print(f\"   ‚Ä¢ Data may require different modeling approaches (ensemble methods, dimensionality reduction)\")\n",
    "    \n",
    "    print(f\"\\nüéØ RECOMMENDATIONS:\")\n",
    "    print(f\"   ‚Ä¢ Consider PCA or other dimensionality reduction before modeling\")\n",
    "    print(f\"   ‚Ä¢ Try ensemble methods (Random Forest, Gradient Boosting)\")\n",
    "    print(f\"   ‚Ä¢ Investigate feature engineering opportunities\")\n",
    "    print(f\"   ‚Ä¢ Consider non-linear modeling approaches\")\n",
    "\n",
    "# Show CV scores distribution for transparency\n",
    "cv_scores = lasso_cv.cv_results_['mean_test_score']\n",
    "print(f\"\\nüìä CROSS-VALIDATION SCORE DISTRIBUTION:\")\n",
    "print(f\"   Mean CV AUC: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "print(f\"   Min CV AUC:  {np.min(cv_scores):.4f}\")\n",
    "print(f\"   Max CV AUC:  {np.max(cv_scores):.4f}\")\n",
    "\n",
    "if np.std(cv_scores) < 0.01:\n",
    "    print(\"   ‚úÖ Very stable across different C values\")\n",
    "elif np.std(cv_scores) < 0.05:\n",
    "    print(\"   ‚úÖ Reasonably stable performance\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è High variance across C values - consider model stability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-18T04:07:15.229052Z",
     "iopub.status.idle": "2025-09-18T04:07:15.229608Z",
     "shell.execute_reply": "2025-09-18T04:07:15.229274Z",
     "shell.execute_reply.started": "2025-09-18T04:07:15.229256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ELASTIC NET (L1 + L2 REGULARIZATION)\n",
      "--------------------------------------------------\n",
      "Best Elastic Net parameters:\n",
      "  Alpha: 0.138950\n",
      "  L1 ratio: 0.90\n",
      "Best CV AUC score: 0.5080\n",
      "Training Accuracy: 0.6691\n",
      "Test Accuracy: 0.6857\n",
      "Test AUC: 0.5000\n",
      "Precision: 0.6857\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8136\n",
      "\n",
      "Improvement over Ordinary LR:\n",
      "  AUC: -0.0909\n",
      "  Accuracy: +0.0571\n",
      "  Regularization: Mostly Lasso-like (L1 dominant)\n"
     ]
    }
   ],
   "source": [
    "# 3. Elastic Net (L1 + L2 Regularization)\n",
    "print(\"\\n3. ELASTIC NET (L1 + L2 REGULARIZATION)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use broader parameter search for better results\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "elastic_params = {\n",
    "    'alpha': np.logspace(-6, 2, 15),\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "elastic = SGDClassifier(\n",
    "    loss='log_loss', \n",
    "    penalty='elasticnet', \n",
    "    max_iter=2000, \n",
    "    random_state=42,\n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "# Use StratifiedKFold to ensure balanced folds\n",
    "elastic_cv = GridSearchCV(\n",
    "    elastic, elastic_params, \n",
    "    cv=stratified_cv, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "elastic_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best Elastic Net parameters:\")\n",
    "print(f\"  Alpha: {elastic_cv.best_params_['alpha']:.6f}\")\n",
    "print(f\"  L1 ratio: {elastic_cv.best_params_['l1_ratio']:.2f}\")\n",
    "print(f\"Best CV AUC score: {elastic_cv.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "elastic_metrics, elastic_pred, elastic_proba = evaluate_model(\n",
    "    elastic_cv.best_estimator_, X_train_scaled, X_test_scaled, y_train, y_test, 'Elastic Net'\n",
    ")\n",
    "results.append(elastic_metrics)\n",
    "all_predictions['Elastic Net'] = elastic_pred\n",
    "all_probabilities['Elastic Net'] = elastic_proba\n",
    "\n",
    "# Display results\n",
    "print(f\"Training Accuracy: {elastic_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {elastic_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {elastic_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {elastic_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {elastic_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {elastic_metrics['f1']:.4f}\")\n",
    "\n",
    "# Compare with ordinary LR\n",
    "improvement_auc = elastic_metrics['test_auc'] - ordinary_metrics['test_auc']\n",
    "improvement_acc = elastic_metrics['test_accuracy'] - ordinary_metrics['test_accuracy']\n",
    "print(f\"\\nImprovement over Ordinary LR:\")\n",
    "print(f\"  AUC: {improvement_auc:+.4f}\")\n",
    "print(f\"  Accuracy: {improvement_acc:+.4f}\")\n",
    "\n",
    "# Interpret the L1 ratio\n",
    "l1_ratio = elastic_cv.best_params_['l1_ratio']\n",
    "if l1_ratio < 0.3:\n",
    "    print(f\"  Regularization: Mostly Ridge-like (L2 dominant)\")\n",
    "elif l1_ratio > 0.7:\n",
    "    print(f\"  Regularization: Mostly Lasso-like (L1 dominant)\")\n",
    "else:\n",
    "    print(f\"  Regularization: Balanced L1/L2 combination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-18T04:07:15.230757Z",
     "iopub.status.idle": "2025-09-18T04:07:15.231052Z",
     "shell.execute_reply": "2025-09-18T04:07:15.230915Z",
     "shell.execute_reply.started": "2025-09-18T04:07:15.230905Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "Performance Metrics Table:\n",
      "         model  train_accuracy  test_accuracy  train_auc  test_auc  precision  \\\n",
      "0  Ordinary LR          1.0000         0.6286     1.0000    0.5909     0.7619   \n",
      "1        Ridge          0.6691         0.6857     0.7221    0.5530     0.6857   \n",
      "2        Lasso          0.6691         0.6857     0.6947    0.5114     0.6857   \n",
      "3  Elastic Net          0.6691         0.6857     0.5000    0.5000     0.6857   \n",
      "\n",
      "   recall      f1  \n",
      "0  0.6667  0.7111  \n",
      "1  1.0000  0.8136  \n",
      "2  1.0000  0.8136  \n",
      "3  1.0000  0.8136  \n",
      "\n",
      "Relative Improvements over Ordinary Logistic Regression:\n",
      "\n",
      "Ridge:\n",
      "  AUC improvement: -0.0379\n",
      "  Accuracy improvement: +0.0571\n",
      "  Overfitting reduction: +0.3880\n",
      "\n",
      "Lasso:\n",
      "  AUC improvement: -0.0795\n",
      "  Accuracy improvement: +0.0571\n",
      "  Overfitting reduction: +0.3880\n",
      "\n",
      "Elastic Net:\n",
      "  AUC improvement: -0.0909\n",
      "  Accuracy improvement: +0.0571\n",
      "  Overfitting reduction: +0.3880\n",
      "\n",
      "üèÜ Best Model (by AUC): Ordinary LR with AUC = 0.5909\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive results comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display results table\n",
    "print(\"\\nPerformance Metrics Table:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Calculate relative improvements over ordinary logistic regression\n",
    "print(\"\\nRelative Improvements over Ordinary Logistic Regression:\")\n",
    "baseline_metrics = results_df[results_df['model'] == 'Ordinary LR'].iloc[0]\n",
    "for idx, row in results_df.iterrows():\n",
    "    if row['model'] != 'Ordinary LR':\n",
    "        auc_improvement = row['test_auc'] - baseline_metrics['test_auc']\n",
    "        acc_improvement = row['test_accuracy'] - baseline_metrics['test_accuracy']\n",
    "        overfitting_reduction = (baseline_metrics['train_accuracy'] - baseline_metrics['test_accuracy']) - \\\n",
    "                               (row['train_accuracy'] - row['test_accuracy'])\n",
    "        print(f\"\\n{row['model']}:\")\n",
    "        print(f\"  AUC improvement: {auc_improvement:+.4f}\")\n",
    "        print(f\"  Accuracy improvement: {acc_improvement:+.4f}\")\n",
    "        print(f\"  Overfitting reduction: {overfitting_reduction:+.4f}\")\n",
    "\n",
    "# Find best performing model\n",
    "best_auc_idx = results_df['test_auc'].idxmax()\n",
    "best_model = results_df.loc[best_auc_idx]\n",
    "print(f\"\\nüèÜ Best Model (by AUC): {best_model['model']} with AUC = {best_model['test_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-18T04:07:15.251351Z",
     "iopub.status.idle": "2025-09-18T04:07:15.251751Z",
     "shell.execute_reply": "2025-09-18T04:07:15.251583Z",
     "shell.execute_reply.started": "2025-09-18T04:07:15.251570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION STABILITY ANALYSIS\n",
      "================================================================================\n",
      "Performing 10-fold cross-validation for stability assessment...\n",
      "\n",
      "Ordinary LR:\n",
      "  AUC: 0.4131 ¬± 0.1296 (95% CI)\n",
      "  Accuracy: 0.4637 ¬± 0.1643\n",
      "  F1-Score: 0.5439 ¬± 0.2437\n",
      "  Stability: üî¥ Unstable (std = 0.0648)\n",
      "\n",
      "Ridge:\n",
      "  AUC: 0.4919 ¬± 0.2339 (95% CI)\n",
      "  Accuracy: 0.6698 ¬± 0.0553\n",
      "  F1-Score: 0.8019 ¬± 0.0395\n",
      "  Stability: üî¥ Unstable (std = 0.1169)\n",
      "\n",
      "Lasso:\n",
      "  AUC: 0.4975 ¬± 0.2262 (95% CI)\n",
      "  Accuracy: 0.6626 ¬± 0.0485\n",
      "  F1-Score: 0.7968 ¬± 0.0349\n",
      "  Stability: üî¥ Unstable (std = 0.1131)\n",
      "\n",
      "Elastic Net:\n",
      "  AUC: 0.5000 ¬± 0.0000 (95% CI)\n",
      "  Accuracy: 0.6698 ¬± 0.0553\n",
      "  F1-Score: 0.8019 ¬± 0.0395\n",
      "  Stability: üü¢ Very Stable (std = 0.0000)\n",
      "\n",
      "üìä STABILITY RANKING (by AUC standard deviation):\n",
      "1. Elastic Net     (std = 0.0000)\n",
      "2. Ordinary LR     (std = 0.0648)\n",
      "3. Lasso           (std = 0.1131)\n",
      "4. Ridge           (std = 0.1169)\n"
     ]
    }
   ],
   "source": [
    "# CROSS-VALIDATION STABILITY ANALYSIS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION STABILITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Perform detailed cross-validation for each model\n",
    "cv_results = {}\n",
    "models_for_cv = {}\n",
    "\n",
    "# Prepare models for CV analysis\n",
    "if 'ordinary_lr' in locals():\n",
    "    models_for_cv['Ordinary LR'] = ordinary_lr\n",
    "if 'ridge_cv' in locals():\n",
    "    models_for_cv['Ridge'] = ridge_cv.best_estimator_\n",
    "if 'lasso_cv' in locals():\n",
    "    models_for_cv['Lasso'] = lasso_cv.best_estimator_\n",
    "if 'elastic_cv' in locals():\n",
    "    models_for_cv['Elastic Net'] = elastic_cv.best_estimator_\n",
    "\n",
    "print(\"Performing 10-fold cross-validation for stability assessment...\")\n",
    "\n",
    "for name, model in models_for_cv.items():\n",
    "    # Perform cross-validation with multiple metrics\n",
    "    cv_scores_auc = cross_val_score(model, X_train_scaled, y_train, cv=10, scoring='roc_auc')\n",
    "    cv_scores_acc = cross_val_score(model, X_train_scaled, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores_f1 = cross_val_score(model, X_train_scaled, y_train, cv=10, scoring='f1')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'auc_mean': cv_scores_auc.mean(),\n",
    "        'auc_std': cv_scores_auc.std(),\n",
    "        'auc_scores': cv_scores_auc,\n",
    "        'acc_mean': cv_scores_acc.mean(),\n",
    "        'acc_std': cv_scores_acc.std(),\n",
    "        'acc_scores': cv_scores_acc,\n",
    "        'f1_mean': cv_scores_f1.mean(),\n",
    "        'f1_std': cv_scores_f1.std(),\n",
    "        'f1_scores': cv_scores_f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  AUC: {cv_scores_auc.mean():.4f} ¬± {cv_scores_auc.std()*2:.4f} (95% CI)\")\n",
    "    print(f\"  Accuracy: {cv_scores_acc.mean():.4f} ¬± {cv_scores_acc.std()*2:.4f}\")\n",
    "    print(f\"  F1-Score: {cv_scores_f1.mean():.4f} ¬± {cv_scores_f1.std()*2:.4f}\")\n",
    "    \n",
    "    # Stability assessment\n",
    "    if cv_scores_auc.std() < 0.02:\n",
    "        stability = \"üü¢ Very Stable\"\n",
    "    elif cv_scores_auc.std() < 0.05:\n",
    "        stability = \"üü° Moderately Stable\"\n",
    "    else:\n",
    "        stability = \"üî¥ Unstable\"\n",
    "    print(f\"  Stability: {stability} (std = {cv_scores_auc.std():.4f})\")\n",
    "\n",
    "print(f\"\\nüìä STABILITY RANKING (by AUC standard deviation):\")\n",
    "stability_ranking = sorted(cv_results.items(), key=lambda x: x[1]['auc_std'])\n",
    "for i, (name, results) in enumerate(stability_ranking, 1):\n",
    "    print(f\"{i}. {name:<15} (std = {results['auc_std']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
