{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toxicity Dataset : https://archive.ics.uci.edu/dataset/728/toxicity-2\n",
    "\n",
    "The dataset includes 171 molecules designed for functional domains of a core clock protein, CRY1, responsible for generating circadian rhythm. 56 of the molecules are toxic and the rest are non-toxic. \n",
    "\n",
    "The data consists a complete set of 1203 molecular descriptors and needs feature selection before classification since some of the features are redundant. \n",
    "\n",
    "Introductory Paper:\n",
    "Structure-based design and classifications of small molecules regulating the circadian rhythm period\n",
    "By Seref Gul, F. Rahim, Safak Isin, Fatma Yilmaz, Nuri Ozturk, M. Turkay, I. Kavakli. 2021\n",
    "https://www.semanticscholar.org/paper/Structure-based-design-and-classifications-of-small-Gul-Rahim/5944836c47bc7d1a2b0464a9a1db94d4bc7f28ce\n",
    "Published in Scientific reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:07.970883Z",
     "iopub.status.busy": "2025-09-18T04:07:07.970487Z",
     "iopub.status.idle": "2025-09-18T04:07:07.979245Z",
     "shell.execute_reply": "2025-09-18T04:07:07.977849Z",
     "shell.execute_reply.started": "2025-09-18T04:07:07.970858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the toxicity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:12.702310Z",
     "iopub.status.busy": "2025-09-18T04:07:12.701902Z",
     "iopub.status.idle": "2025-09-18T04:07:14.072099Z",
     "shell.execute_reply": "2025-09-18T04:07:14.070911Z",
     "shell.execute_reply.started": "2025-09-18T04:07:12.702270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (171, 1204)\n",
      "\n",
      "First few rows:\n",
      "   MATS3v  nHBint10  MATS3s  MATS3p  nHBDon_Lipinski  minHBint8  MATS3e  \\\n",
      "0  0.0908         0  0.0075  0.0173                0        0.0 -0.0436   \n",
      "1  0.0213         0  0.1144 -0.0410                0        0.0  0.1231   \n",
      "2  0.0018         0 -0.0156 -0.0765                2        0.0 -0.1138   \n",
      "3 -0.0251         0 -0.0064 -0.0894                3        0.0 -0.0747   \n",
      "4  0.0135         0  0.0424 -0.0353                0        0.0 -0.0638   \n",
      "\n",
      "   MATS3c  minHBint2  MATS3m  ...   WTPT-4   WTPT-5  ETA_EtaP_L  ETA_EtaP_F  \\\n",
      "0  0.0409        0.0  0.1368  ...   0.0000   0.0000      0.1780      1.5488   \n",
      "1 -0.0316        0.0  0.1318  ...   8.8660  19.3525      0.1739      1.3718   \n",
      "2 -0.1791        0.0  0.0615  ...   5.2267  27.8796      0.1688      1.4395   \n",
      "3 -0.1151        0.0  0.0361  ...   7.7896  24.7336      0.1702      1.4654   \n",
      "4  0.0307        0.0  0.0306  ...  12.3240  19.7486      0.1789      1.4495   \n",
      "\n",
      "   ETA_EtaP_B  nT5Ring  SHdNH  ETA_dEpsilon_C  MDEO-22     Class  \n",
      "0      0.0088        0    0.0         -0.0868     0.00  NonToxic  \n",
      "1      0.0048        2    0.0         -0.0810     0.25  NonToxic  \n",
      "2      0.0116        2    0.0         -0.1004     0.00  NonToxic  \n",
      "3      0.0133        2    0.0         -0.1010     0.00  NonToxic  \n",
      "4      0.0120        2    0.0         -0.1071     0.00  NonToxic  \n",
      "\n",
      "[5 rows x 1204 columns]\n",
      "\n",
      "Column names:\n",
      "['MATS3v', 'nHBint10', 'MATS3s', 'MATS3p', 'nHBDon_Lipinski', 'minHBint8', 'MATS3e', 'MATS3c', 'minHBint2', 'MATS3m', 'minHBint6', 'minHBint7', 'minHBint4', 'MATS3i', 'VR3_Dt', 'SpMax8_Bhi', 'SdsN', 'SpMax8_Bhm', 'SpMax8_Bhe', 'ECCEN', 'MDEC-14', 'SpMax8_Bhs', 'SpMax8_Bhp', 'SpMax8_Bhv', 'MDEC-11', 'MDEC-12', 'MDEC-13', 'VR2_Dt', 'BIC5', 'ATS7s', 'ATS7p', 'ATS7v', 'ATS7i', 'ATS7m', 'ATS7e', 'mintN', 'nHsNH2', 'khs.sssCH', 'minHBint3', 'maxdssC', 'nT6Ring', 'minHBint5', 'nF8Ring', 'minssCH2', 'SpMax_DzZ', 'ETA_EtaP', 'nHsOH', 'SpMin1_Bhe', 'maxHother', 'nHBAcc_Lipinski', 'StN', 'khs.aaS', 'khs.aaO', 'khs.aaN', 'Sare', 'SHAvin', 'SpMax3_Bhv', 'SpMax3_Bhp', 'SpMax3_Bhs', 'SpMax3_Bhe', 'SpMin6_Bhi', 'SpMax3_Bhm', 'SpMax3_Bhi', 'ETA_EtaP_F_L', 'mindCH2', 'AATSC2e', 'AATSC2c', 'AATSC2m', 'AATSC2i', 'nsBr', 'AATS5p', 'AATSC2v', 'AATSC2p', 'AATSC2s', 'VABC', 'maxdNH', 'khs.ddsN', 'RotBtFrac', 'ATS4e', 'ATS4m', 'nFRing', 'ATS4i', 'EE_DzZ', 'ATS4s', 'ATS4p', 'ETA_Alpha', 'khs.sssN', 'EE_Dzi', 'MAXDN', 'EE_Dzm', 'EE_Dze', 'EE_Dzs', 'EE_Dzp', 'EE_Dzv', 'ATS8e', 'maxsOH', 'minssssNp', 'maxsOm', 'MDEC-23', 'MDEC-22', 'MDEC-24', 'nFG12HeteroRing', 'ATS8s', 'ATS8v', 'SP-6', 'SP-7', 'SHsNH2', 'SP-5', 'SP-2', 'SP-3', 'SP-0', 'SP-1', 'minHsOH', 'ATSC8v', 'MATS2v', 'ATSC8s', 'MATS2p', 'MATS2s', 'ATSC8p', 'MATS2e', 'ATSC8e', 'ATSC8c', 'MATS2c', 'MATS2m', 'topoDiameter', 'ATSC8m', 'MATS2i', 'ATSC8i', 'ntN', 'khs.ssCH2', 'SpAD_Dt', 'ETA_Eta_R_L', 'SHdsCH', 'SaasN', 'SC-4', 'SaasC', 'minaaCH', 'AATSC3c', 'AATSC3e', 'AATSC3i', 'AATSC3m', 'AATSC3s', 'AATSC3p', 'AATSC3v', 'SpMax2_Bhp', 'nF8HeteroRing', 'AATS8e', 'AATS8i', 'AATS8m', 'AATS8s', 'AATS8p', 'AATS8v', 'VE3_Dt', 'XLogP', 'SpMax2_Bhi', 'maxssCH2', 'minaaS', 'SpMax4_Bhv', 'SpMax4_Bhs', 'SpMax4_Bhp', 'SpMax4_Bhm', 'minHaaNH', 'SpMax4_Bhi', 'minaaN', 'SpMax4_Bhe', 'StsC', 'SssCH2', 'maxHdNH', 'MATS1p', 'R_TpiPCTPC', 'MATS1s', 'MATS1v', 'JGI10', 'MATS1c', 'MATS1e', 'VR2_DzZ', 'MATS1i', 'MATS1m', 'MDEC-34', 'MDEC-33', 'VR2_Dze', 'VR2_Dzm', 'VR2_Dzs', 'VR2_Dzp', 'khs.ssssC', 'nTG12Ring', 'khs.ssssN', 'ATS5e', 'gmin', 'VR2_D', 'ATS5m', 'ATS5p', 'ATS5s', 'ATS5v', 'AATSC5p', 'TpiPC', 'maxsCH3', 'SdS', 'khs.ssO', 'ETA_Eta_F_L', 'khs.ssS', 'SdO', 'VE2_Dt', 'maxHtCH', 'SpMax_Dze', 'SpMax_Dzm', 'SpMax_Dzi', 'ETA_dEpsilon_B', 'SpMax_Dzv', 'ETA_dEpsilon_A', 'SpMax_Dzs', 'ETA_dEpsilon_D', 'SpMax_Dzp', 'SsNH2', 'StCH', 'SsCH3', 'CIC5', 'CIC4', 'CIC1', 'CIC0', 'CIC3', 'CIC2', 'nF10HeteroRing', 'maxssO', 'WPOL', 'n5HeteroRing', 'maxHAvin', 'fragC', 'ETA_Eta_B_RC', 'AATS7m', 'SpDiam_Dt', 'SdssC', 'ETA_Epsilon_3', 'AATS7i', 'AATS7e', 'nT9Ring', 'minsCl', 'AATS7v', 'AATS7s', 'AATS7p', 'nHdCH2', 'ETA_Epsilon_5', 'ETA_Epsilon_4', 'SsssCH', 'maxHsOH', 'GATS1v', 'maxaaaC', 'GATS1s', 'minsNH2', 'BIC4', 'SpMin7_Bhs', 'SpMin7_Bhp', 'SpMin7_Bhv', 'nHtCH', 'GATS1e', 'mintsC', 'GATS1c', 'SpMin7_Bhm', 'GATS1m', 'SpMin7_Bhe', 'GATS1i', 'maxtsC', 'minHAvin', 'MDEC-44', 'AATS2v', 'SPC-6', 'SPC-4', 'SPC-5', 'SpAD_D', 'MATS6c', 'ETA_BetaP_s', 'minaasC', 'minaasN', 'minssNH', 'nT7HeteroRing', 'RotBFrac', 'nF10Ring', 'ETA_BetaP_ns', 'nH', 'nL', 'nN', 'nO', 'nA', 'nC', 'nF', 'nX', 'nQ', 'nS', 'nV', 'ATS1m', 'SdNH', 'mindsN', 'SHCsats', 'SHCsatu', 'CrippenMR', 'GATS1p', 'SRW10', 'ETA_dPsi_A', 'AATS6m', 'AATS6i', 'AATS6e', 'minsBr', 'nF9HeteroRing', 'SpMin7_Bhi', 'AATS6v', 'AATS6p', 'AATS6s', 'naAromAtom', 'nBase', 'minHBint10', 'SpDiam_DzZ', 'SaaNH', 'nssssC', 'khs.dNH', 'maxaaN', 'maxaaO', 'SpDiam_Dzv', 'SpDiam_Dzs', 'SpDiam_Dzp', 'SpDiam_Dze', 'SpDiam_Dzm', 'GATS6i', 'SpDiam_Dzi', 'Mi', 'Mv', 'Mp', 'GGI10', 'nBr', 'bpol', 'MW', 'GATS6v', 'MATS7s', 'MATS7p', 'C1SP1', 'MATS7v', 'MATS7i', 'MATS7m', 'MATS7c', 'GATS6s', 'MATS7e', 'maxtN', 'SpMin8_Bhe', 'SpMin8_Bhi', 'SpMin8_Bhm', 'SpMin8_Bhp', 'SpMin8_Bhs', 'SpMin8_Bhv', 'maxHCsatu', 'maxHCsats', 'ATSC3v', 'ATSC3s', 'ATSC3p', 'minHdCH2', 'ATSC3e', 'ATSC3c', 'maxssNH', 'ATSC3m', 'ATSC3i', 'minHCsatu', 'minHCsats', 'SpMax7_Bhe', 'SpMax7_Bhi', 'SpMax7_Bhm', 'ETA_BetaP_ns_d', 'SpMax7_Bhp', 'SpMax7_Bhs', 'SpMax7_Bhv', 'SdsCH', 'minssO', 'minssS', 'SpMin3_Bhe', 'SpMin3_Bhm', 'SpMin3_Bhi', 'SpMin3_Bhv', 'nT8Ring', 'SpMin3_Bhs', 'SpMin3_Bhp', 'TPC', 'khs.tCH', 'VP-5', 'VP-4', 'VP-7', 'VP-6', 'VP-1', 'VP-0', 'VP-3', 'VP-2', 'MIC5', 'MIC4', 'MIC3', 'MIC2', 'MIC1', 'MIC0', 'ATSC5p', 'piPC10', 'ATSC5s', 'minsOm', 'nT10HeteroRing', 'nHBa', 'nHBd', 'SddssS', 'nCl', 'minsOH', 'SHaaCH', 'nHBDon', 'nF11HeteroRing', 'AATS5i', 'AATS5m', 'SpMin6_Bhs', 'SpMin6_Bhp', 'SpMin6_Bhv', 'AATS5e', 'ETA_dBeta', 'khs.sCH3', 'ALogP', 'SpMin6_Bhm', 'BCUTp-1l', 'AATS5s', 'BCUTp-1h', 'AATS5v', 'SpMin6_Bhe', 'ATS8i', 'ATS8m', 'BCUTw-1h', 'BCUTw-1l', 'nBondsS3', 'nBondsS2', 'ATS8p', 'GATS3p', 'GATS3s', 'GATS3v', 'GATS3c', 'GATS3e', 'SC-5', 'GATS3i', 'SC-6', 'GATS3m', 'SC-3', 'minsCH3', 'SssssC', 'nAtomLC', 'nT12HeteroRing', 'minHaaCH', 'MLFER_BH', 'MLFER_BO', 'SaaaC', 'mindsCH', 'nddssS', 'maxaasC', 'maxsssN', 'MATS6p', 'MATS6s', 'MATS6v', 'MATS6i', 'MATS6m', 'MATS6e', 'ETA_Beta_ns_d', 'hmax', 'ETA_Beta_s', 'nHaaCH', 'khs.aaaC', 'khs.sNH2', 'ETA_AlphaP', 'nAromBond', 'ATSC2v', 'ATSC2p', 'ATSC2s', 'ATS4v', 'ATSC2e', 'ATSC2c', 'ATSC2m', 'ATSC2i', 'AATS4v', 'AATS4s', 'AATS4p', 'AATS4e', 'ETA_BetaP', 'AATS4m', 'khs.sOH', 'AATS4i', 'SHsOH', 'SpMax_D', 'MDEN-13', 'MDEN-12', 'MDEN-11', 'ntsC', 'ATS3m', 'PetitjeanNumber', 'khs.aasN', 'khs.aasC', 'MWC10', 'MPC7', 'TWC', 'topoRadius', 'WPATH', 'nG', 'ndsN', 'MAXDP', 'naaaC', 'SM1_DzZ', 'SpAbs_DzZ', 'SpAbs_Dze', 'khs.aaNH', 'SpAbs_Dzm', 'SM1_Dzv', 'SpAbs_Dzi', 'SM1_Dzp', 'SM1_Dzs', 'SM1_Dzm', 'SpAbs_Dzv', 'SM1_Dzi', 'SpAbs_Dzp', 'SpAbs_Dzs', 'SM1_Dze', 'maxaaCH', 'maxdO', 'nF11Ring', 'GATS2v', 'GATS2s', 'ETA_Beta', 'GATS2m', 'GATS2i', 'maxdS', 'GATS2e', 'GATS2c', 'nHaaNH', 'ATSC1p', 'ATSC1s', 'ATSC1v', 'ATSC1c', 'ATSC1e', 'ATSC1i', 'ATSC1m', 'MWC9', 'MWC8', 'MWC5', 'MWC4', 'MWC7', 'MWC6', 'ndssC', 'MWC2', 'MAXDN2', 'MATS5e', 'SpMin2_Bhe', 'MATS5c', 'MATS5m', 'SpMin2_Bhm', 'MATS5i', 'SpMin2_Bhi', 'SpMin2_Bhv', 'MATS5v', 'MATS5p', 'SpMin2_Bhs', 'SpMin2_Bhp', 'VE1_Dzi', 'Mare', 'BCUTc-1l', 'BCUTc-1h', 'SssNH', 'MPC9', 'VE1_Dzp', 'naaN', 'naaO', 'naaS', 'SsBr', 'SHBd', 'TSRW', 'SHBa', 'khs.ssNH', 'nT9HeteroRing', 'SpMax6_Bhp', 'SpMax6_Bhs', 'SpMAD_Dzv', 'SpMax6_Bhv', 'SpMax6_Bhe', 'SpMAD_Dze', 'SpMax6_Bhi', 'SpMAD_Dzi', 'SpMax6_Bhm', 'SpMAD_Dzm', 'SpMAD_DzZ', 'AATSC8s', 'AATSC8p', 'AATSC8v', 'minHssNH', 'AATSC8c', 'AATSC8e', 'AATSC8i', 'AATSC8m', 'AATS3s', 'AATS3p', 'AATS3v', 'SpMin5_Bhv', 'SpMin5_Bhp', 'SpMin5_Bhs', 'SpMin5_Bhm', 'SpMin5_Bhi', 'AATS3e', 'SpMin5_Bhe', 'AATS3i', 'SpMAD_Dzs', 'AATS3m', 'n7Ring', 'maxdCH2', 'MLFER_L', 'GATS5s', 'GATS5p', 'GATS5v', 'MLFER_A', 'GATS5i', 'GATS5m', 'IC3', 'IC2', 'IC1', 'IC0', 'khs.tN', 'IC5', 'IC4', 'ETA_Eta_R', 'ETA_Eta_L', 'SHdCH2', 'ETA_Eta_B', 'ETA_Eta_F', 'SaaCH', 'nAcid', 'maxsssCH', 'SsCl', 'nF6Ring', 'maxsF', 'MATS4c', 'MATS4e', 'MATS4i', 'SP-4', 'MATS4m', 'MATS4s', 'MATS4p', 'MATS4v', 'minHdNH', 'VC-6', 'SsssN', 'minaaaC', 'minwHBa', 'nT6HeteroRing', 'khs.dssC', 'AATSC0m', 'EE_Dt', 'minsF', 'ATSC0v', 'ATSC0s', 'ATSC0p', 'ATSC0m', 'ATSC0i', 'ATSC0e', 'ATSC0c', 'VE2_D', 'SpMAD_D', 'nHBint2', 'nHBint3', 'ETA_Epsilon_1', 'nHBint6', 'nHBint7', 'nHBint4', 'nHBint5', 'nHBint8', 'nHBint9', 'nBondsS', 'AATS2p', 'AATS2s', 'nBondsT', 'AATS2e', 'nBondsD', 'AATS2i', 'AATS2m', 'nBondsM', 'nBonds2', 'MDEN-33', 'Sp', 'Sv', 'Si', 'FMF', 'nRotB', 'n7HeteroRing', 'minssssC', 'SwHBa', 'Zagreb', 'SRW6', 'SRW7', 'SRW4', 'SRW5', 'SRW2', 'khs.sCl', 'SRW8', 'SRW9', 'maxHsNH2', 'SCH-5', 'SCH-6', 'SCH-7', 'khs.sF', 'nF9Ring', 'ATS6p', 'maxaasN', 'MAXDP2', 'minHtCH', 'nsNH2', 'nFG12Ring', 'VE1_DzZ', 'VE1_Dze', 'GATS4p', 'GATS4s', 'VE1_Dzm', 'GATS4v', 'GATS4i', 'VE1_Dzs', 'GATS4m', 'ndsCH', 'VE1_Dzv', 'GATS4c', 'GATS4e', 'ETA_Beta_ns', 'McGowan_Volume', 'n5Ring', 'ETA_dAlpha_B', 'ATSC7s', 'ATSC7p', 'ETA_dAlpha_A', 'ATSC7v', 'ATSC7i', 'ATSC7m', 'ATSC7c', 'VC-4', 'VC-5', 'VC-3', 'ATSC7e', 'maxssssNp', 'JGI2', 'JGI3', 'JGI1', 'JGI6', 'JGI7', 'JGI4', 'JGI5', 'JGI8', 'JGI9', 'SpAD_DzZ', 'SpAD_Dze', 'SpAD_Dzm', 'SpAD_Dzi', 'SpAD_Dzv', 'SpAD_Dzp', 'SpAD_Dzs', 'nsssCH', 'nBonds', 'LipinskiFailures', 'SpDiam_D', 'minHdsCH', 'SssO', 'SssS', 'C2SP3', 'C2SP2', 'C2SP1', 'GATS2p', 'ETA_Shape_X', 'ETA_Shape_Y', 'ETA_Shape_P', 'naaNH', 'khs.dCH2', 'AVP-5', 'AVP-4', 'AVP-7', 'AVP-1', 'AVP-0', 'AVP-2', 'AATS1v', 'AATS1p', 'AATS1s', 'AATS1m', 'MDEN-22', 'AATS1i', 'AATS1e', 'maxaaNH', 'maxHaaNH', 'nT8HeteroRing', 'GATS7c', 'GATS7m', 'GATS7v', 'GATS7p', 'GATS7s', 'SsOm', 'SsOH', 'AATSC4v', 'maxHBd', 'AATSC4s', 'khs.sBr', 'maxHBa', 'khs.dsN', 'SHssNH', 'AATSC4e', 'AATSC4c', 'AATSC4m', 'AATSC4i', 'SHBint10', 'ATS2v', 'ATS2p', 'ATS2s', 'CrippenLogP', 'ATS2i', 'JGT', 'MPC10', 'ndNH', 'VAdjMat', 'khs.ddssS', 'nT7Ring', 'khs.dsCH', 'ATSC6p', 'ATSC6s', 'ATSC6v', 'ATSC6i', 'ATSC6m', 'ATSC6c', 'ATSC6e', 'SpMin1_Bhi', 'SpMin1_Bhm', 'SpMin1_Bhp', 'SpMin1_Bhs', 'nT11HeteroRing', 'SpMin1_Bhv', 'SHother', 'AATS0s', 'SpMin4_Bhv', 'AATS0p', 'SpMin4_Bhp', 'AATS0v', 'SpMin4_Bhs', 'SpMin4_Bhm', 'AATS0i', 'SpMin4_Bhi', 'AATS0m', 'minsssCH', 'SpMin4_Bhe', 'nAtomLAC', 'AATS0e', 'nsCH3', 'MWC3', 'ATSC5v', 'MLFER_S', 'ETA_dBetaP', 'AATSC4p', 'nRotBt', 'nsOm', 'SHaaNH', 'nsOH', 'AATSC5v', 'AATSC5s', 'nssssNp', 'AATSC5e', 'naasN', 'AATSC5c', 'AATSC5m', 'nsssN', 'SpMax_Dt', 'AATSC5i', 'naasC', 'VR3_D', 'VR1_D', 'VR1_Dt', 'ETA_Epsilon_2', 'MLogP', 'nHBAcc2', 'nHBAcc3', 'AMR', 'AMW', 'GATS6c', 'sumI', 'GATS6e', 'gmax', 'maxHssNH', 'MATS5s', 'maxsNH2', 'GATS6m', 'maxHBint8', 'maxHBint9', 'GATS6p', 'C1SP2', 'C1SP3', 'khs.tsC', 'maxHBint2', 'maxHBint3', 'maxHBint4', 'maxHBint5', 'maxHBint6', 'maxHBint7', 'AVP-6', 'nHdNH', 'ATSC5e', 'C4SP3', 'AVP-3', 'ATSC5c', 'ATSC5m', 'nHother', 'ATSC5i', 'VCH-5', 'VCH-7', 'VCH-6', 'Mse', 'nsF', 'DELS2', 'MATS8m', 'ATS3v', 'ATS3s', 'ATS3p', 'ATS3e', 'MATS8i', 'Kier2', 'Kier3', 'Kier1', 'HybRatio', 'ATS3i', 'MDEN-23', 'SHBint9', 'SHBint8', 'SHBint3', 'SHBint2', 'SHBint7', 'SHBint6', 'SHBint5', 'SHBint4', 'DELS', 'minHsNH2', 'nHeteroRing', 'GATS7e', 'ETA_Psi_1', 'mindssC', 'nwHBa', 'maxHBint10', 'mindNH', 'GATS7i', 'nHssNH', 'nAtom', 'Spe', 'khs.dS', 'khs.dO', 'maxwHBa', 'AATSC6p', 'AATSC6s', 'AATSC6v', 'AATSC6c', 'AATSC6e', 'AATSC6i', 'AATSC6m', 'SssssNp', 'AATSC7c', 'nssCH2', 'ASP-2', 'ASP-3', 'ASP-0', 'ASP-1', 'ASP-6', 'ASP-7', 'ASP-4', 'ASP-5', 'ATS0s', 'MATS8v', 'ATS0p', 'MATS8s', 'ATS0v', 'MATS8p', 'MATS8e', 'MATS8c', 'ATS0e', 'ATS0i', 'ATS0m', 'GGI9', 'GGI8', 'GGI1', 'GGI3', 'GGI2', 'GGI5', 'GGI4', 'GGI7', 'GGI6', 'nTRing', 'nT10Ring', 'TIC0', 'TIC1', 'TIC2', 'TIC3', 'TIC4', 'TIC5', 'maxsCl', 'ntCH', 'khs.aaCH', 'ZMIC4', 'ZMIC5', 'ZMIC0', 'ZMIC1', 'ZMIC2', 'ZMIC3', 'minHother', 'ATSC4c', 'ATSC4e', 'ATSC4i', 'ATSC4m', 'ATSC4s', 'ATSC4p', 'ATSC4v', 'SpMax1_Bhs', 'SpMax1_Bhp', 'SpMax1_Bhv', 'hmin', 'SpMax1_Bhe', 'SpMax1_Bhi', 'SpMax1_Bhm', 'MPC6', 'nAtomP', 'MPC4', 'MPC5', 'MPC2', 'VR3_Dzv', 'VR3_Dzs', 'MPC8', 'VR3_Dzp', 'VR3_Dzm', 'SpMAD_Dzp', 'VR3_Dzi', 'VR3_Dze', 'SsF', 'minaaO', 'VR3_DzZ', 'mintCH', 'Sse', 'C3SP2', 'VR1_DzZ', 'VR1_Dzp', 'VR1_Dzs', 'SdCH2', 'SHtCH', 'VR1_Dzi', 'VR1_Dzm', 'VR1_Dze', 'maxdsN', 'AATSC7v', 'AATSC7s', 'AATSC7p', 'AATSC7m', 'AATSC7i', 'nHdsCH', 'AATSC7e', 'BIC2', 'BIC3', 'BIC0', 'BIC1', 'SIC5', 'SIC4', 'SIC1', 'SIC0', 'SIC3', 'SIC2', 'naaCH', 'minHBd', 'minHBa', 'AATSC1p', 'nssO', 'AATSC0i', 'ALogp2', 'nssS', 'AATSC1i', 'SaaS', 'SaaO', 'SaaN', 'maxsBr', 'GATS8m', 'SpMax2_Bhv', 'GATS8i', 'SpMax2_Bhs', 'GATS8e', 'GATS8c', 'SpMax2_Bhe', 'SpMax2_Bhm', 'GATS8v', 'GATS8p', 'GATS8s', 'piPC3', 'piPC2', 'piPC1', 'piPC7', 'piPC6', 'piPC5', 'piPC4', 'piPC9', 'piPC8', 'maxHdsCH', 'nT11Ring', 'ATS1v', 'ATS1p', 'ATS1s', 'ATS1i', 'SpMAD_Dt', 'ATS1e', 'VR2_Dzi', 'n6HeteroRing', 'MPC3', 'ATS2e', 'VR2_Dzv', 'minHBint9', 'VE2_Dzs', 'VE2_Dzp', 'VE2_Dzv', 'ATS2m', 'VE2_Dzi', 'VE2_Dzm', 'maxtCH', 'minaaNH', 'VE2_Dze', 'VE2_DzZ', 'nHAvin', 'meanI', 'nHCsatu', 'nHCsats', 'apol', 'ATS5i', 'nF12Ring', 'mindS', 'mindO', 'MolIP', 'maxdsCH', 'ndCH2', 'TopoPSA', 'ETA_EtaP_B_RC', 'MDEO-11', 'MDEO-12', 'AATSC0s', 'SpMax5_Bhv', 'AATSC0p', 'SpMax5_Bhs', 'AATSC0v', 'SpMax5_Bhp', 'SpMax5_Bhm', 'SpMax5_Bhi', 'AATSC0c', 'SpMax5_Bhe', 'AATSC0e', 'EE_D', 'VE3_DzZ', 'C3SP3', 'VE3_Dzv', 'minddssS', 'ATS6s', 'VE3_Dzs', 'VE3_Dzp', 'ATS6v', 'ATS6i', 'VE3_Dzm', 'ATS6m', 'VE3_Dzi', 'VE3_Dze', 'ATS6e', 'nTG12HeteroRing', 'VPC-6', 'VPC-5', 'VPC-4', 'MLFER_E', 'nBondsD2', 'nT12Ring', 'Mpe', 'maxHdCH2', 'nT5HeteroRing', 'nHeavyAtom', 'nRing', 'GATS5c', 'nF12HeteroRing', 'GATS5e', 'VR1_Dzv', 'minsssN', 'topoShape', 'ndO', 'ndS', 'nssNH', 'VE1_Dt', 'maxHaaCH', 'nHBAcc', 'VE3_D', 'nsCl', 'VE1_D', 'AATSC1s', 'AATSC1v', 'AATSC1m', 'AATSC1c', 'AATSC1e', 'LipoaffinityIndex', 'n6Ring', 'ETA_Eta', 'WTPT-1', 'WTPT-2', 'WTPT-3', 'WTPT-4', 'WTPT-5', 'ETA_EtaP_L', 'ETA_EtaP_F', 'ETA_EtaP_B', 'nT5Ring', 'SHdNH', 'ETA_dEpsilon_C', 'MDEO-22', 'Class']\n",
      "\n",
      "Features shape: (171, 1203)\n",
      "Target shape: (171,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Separate features and target\n",
    "# Assuming the last column or a column named 'Class' contains the target\n",
    "if 'Class' in data.columns:\n",
    "    X = data.drop('Class', axis=1)\n",
    "    y = data['Class']\n",
    "else:\n",
    "    # Assume last column is the target\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.075327Z",
     "iopub.status.busy": "2025-09-18T04:07:14.074981Z",
     "iopub.status.idle": "2025-09-18T04:07:14.091774Z",
     "shell.execute_reply": "2025-09-18T04:07:14.090085Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.075303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA EXPLORATION ===\n",
      "Shape of features (X): (171, 1203)\n",
      "Shape of target (y): (171,)\n",
      "\n",
      "Target distribution:\n",
      "Class\n",
      "NonToxic    115\n",
      "Toxic        56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance:\n",
      "Class\n",
      "NonToxic    0.672515\n",
      "Toxic       0.327485\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target data type: object\n",
      "Unique target values: ['NonToxic' 'Toxic']\n"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(\"\\n=== DATA EXPLORATION ===\")\n",
    "print(f\"Shape of features (X): {X.shape}\")\n",
    "print(f\"Shape of target (y): {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass balance:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Check target data type and unique values\n",
    "print(f\"\\nTarget data type: {y.dtype}\")\n",
    "print(f\"Unique target values: {y.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.092964Z",
     "iopub.status.busy": "2025-09-18T04:07:14.092654Z",
     "iopub.status.idle": "2025-09-18T04:07:14.127069Z",
     "shell.execute_reply": "2025-09-18T04:07:14.125982Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.092939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in features: 0\n",
      "Missing values in target: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(f\"\\nMissing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.128382Z",
     "iopub.status.busy": "2025-09-18T04:07:14.128095Z",
     "iopub.status.idle": "2025-09-18T04:07:14.163758Z",
     "shell.execute_reply": "2025-09-18T04:07:14.162588Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.128359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPROCESSING ===\n",
      "Missing values in features: 0\n",
      "Missing values in target: 0\n",
      "\n",
      "Binary target distribution:\n",
      "Class\n",
      "1    115\n",
      "0     56\n",
      "Name: count, dtype: int64\n",
      "Class balance: Class\n",
      "1    0.672515\n",
      "0    0.327485\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Mapping verification:\n",
      "Original 'NonToxic' ‚Üí Binary 1: [1]\n",
      "Original 'Toxic' ‚Üí Binary 0: [0]\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values if any\n",
    "print(\"=== PREPROCESSING ===\")\n",
    "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n",
    "\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    # Option 1: Drop columns with too many missing values\n",
    "    missing_threshold = 0.3  # Drop columns with >30% missing\n",
    "    missing_prop = X.isnull().sum() / len(X)\n",
    "    cols_to_drop = missing_prop[missing_prop > missing_threshold].index\n",
    "    X = X.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Option 2: Impute remaining missing values\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    print(f\"Missing values imputed\")\n",
    "\n",
    "# Convert target to binary (1 for NonToxic, 0 for Toxic) - FLIPPED LABELS\n",
    "y_binary = (y == 'NonToxic').astype(int)\n",
    "\n",
    "# Verify the binary conversion\n",
    "print(\"\\nBinary target distribution:\")\n",
    "print(y_binary.value_counts())\n",
    "print(f\"Class balance: {y_binary.value_counts(normalize=True)}\")\n",
    "\n",
    "# Double-check the conversion is correct\n",
    "print(f\"\\nMapping verification:\")\n",
    "print(f\"Original 'NonToxic' ‚Üí Binary 1: {y_binary[y == 'NonToxic'].unique()}\")\n",
    "print(f\"Original 'Toxic' ‚Üí Binary 0: {y_binary[y == 'Toxic'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.165321Z",
     "iopub.status.busy": "2025-09-18T04:07:14.165004Z",
     "iopub.status.idle": "2025-09-18T04:07:14.910757Z",
     "shell.execute_reply": "2025-09-18T04:07:14.909482Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.165298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE PREPROCESSING ===\n",
      "Removed 0 constant features\n",
      "Remaining features after variance filtering: 994\n",
      "Removed 434 highly correlated features\n",
      "Final feature count: 560\n"
     ]
    }
   ],
   "source": [
    "# Feature preprocessing\n",
    "print(\"\\n=== FEATURE PREPROCESSING ===\")\n",
    "\n",
    "# Remove constant features\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "X_filtered = constant_filter.fit_transform(X)\n",
    "constant_columns = X.columns[~constant_filter.get_support()]\n",
    "print(f\"Removed {len(constant_columns)} constant features\")\n",
    "\n",
    "# Remove quasi-constant features (variance < 0.01)\n",
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)\n",
    "X_filtered = quasi_constant_filter.fit_transform(X_filtered)\n",
    "selected_features = X.columns[constant_filter.get_support()][quasi_constant_filter.get_support()]\n",
    "X_filtered = pd.DataFrame(X_filtered, columns=selected_features)\n",
    "print(f\"Remaining features after variance filtering: {X_filtered.shape[1]}\")\n",
    "\n",
    "# Remove highly correlated features\n",
    "correlation_matrix = X_filtered.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(\n",
    "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "high_corr_features = [column for column in upper_triangle.columns \n",
    "                      if any(upper_triangle[column] > 0.95)]\n",
    "X_filtered = X_filtered.drop(columns=high_corr_features)\n",
    "print(f\"Removed {len(high_corr_features)} highly correlated features\")\n",
    "print(f\"Final feature count: {X_filtered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.912087Z",
     "iopub.status.busy": "2025-09-18T04:07:14.911762Z",
     "iopub.status.idle": "2025-09-18T04:07:14.946771Z",
     "shell.execute_reply": "2025-09-18T04:07:14.945787Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.912060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (136, 560)\n",
      "Test set size: (35, 560)\n",
      "\n",
      "Train set class distribution:\n",
      "Class\n",
      "1    0.669118\n",
      "0    0.330882\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "Class\n",
      "1    0.685714\n",
      "0    0.314286\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data with stratification to ensure balanced folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Add some randomness to address potential ordering issues\n",
    "np.random.seed(42)\n",
    "shuffle_idx = np.random.permutation(len(X_filtered))\n",
    "X_shuffled = X_filtered.iloc[shuffle_idx].reset_index(drop=True)\n",
    "y_shuffled = y_binary.iloc[shuffle_idx].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_shuffled, y_shuffled, test_size=0.2, random_state=42, \n",
    "    stratify=y_shuffled, shuffle=True\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train_scaled.shape}\")\n",
    "print(f\"Test set size: {X_test_scaled.shape}\")\n",
    "\n",
    "# Check class distribution in train and test sets\n",
    "print(f\"\\nTrain set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.948302Z",
     "iopub.status.busy": "2025-09-18T04:07:14.947976Z",
     "iopub.status.idle": "2025-09-18T04:07:14.956524Z",
     "shell.execute_reply": "2025-09-18T04:07:14.955228Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.948279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate a classification model and return metrics\"\"\"\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Probabilities for AUC\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_train_proba = model.decision_function(X_train)\n",
    "        y_test_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'train_auc': roc_auc_score(y_train, y_train_proba),\n",
    "        'test_auc': roc_auc_score(y_test, y_test_proba),\n",
    "        'precision': precision_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'f1': f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_test_pred, y_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.960480Z",
     "iopub.status.busy": "2025-09-18T04:07:14.960129Z",
     "iopub.status.idle": "2025-09-18T04:07:14.990137Z",
     "shell.execute_reply": "2025-09-18T04:07:14.988942Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.960456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize results storage\n",
    "results = []\n",
    "all_predictions = {}\n",
    "all_probabilities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T04:07:14.991219Z",
     "iopub.status.busy": "2025-09-18T04:07:14.990992Z",
     "iopub.status.idle": "2025-09-18T04:07:15.021271Z",
     "shell.execute_reply": "2025-09-18T04:07:15.019782Z",
     "shell.execute_reply.started": "2025-09-18T04:07:14.991202Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON: ORDINARY VS PENALIZED REGRESSION\n",
      "================================================================================\n",
      "\n",
      "This analysis compares the following models:\n",
      "1. Ordinary Logistic Regression (no regularization) - Baseline\n",
      "2. Ridge Regression (L2 penalty) - Shrinks coefficients\n",
      "3. Lasso Regression (L1 penalty) - Feature selection + shrinkage  \n",
      "4. Elastic Net (L1 + L2 penalty) - Combines both approaches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON: ORDINARY VS PENALIZED REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This analysis compares the following models:\n",
    "1. Ordinary Logistic Regression (no regularization) - Baseline\n",
    "2. Ridge Regression (L2 penalty) - Shrinks coefficients\n",
    "3. Lasso Regression (L1 penalty) - Feature selection + shrinkage  \n",
    "4. Elastic Net (L1 + L2 penalty) - Combines both approaches\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0. ORDINARY LOGISTIC REGRESSION (BASELINE)\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.6286\n",
      "Test AUC: 0.5909\n",
      "Precision: 0.7619\n",
      "Recall: 0.6667\n",
      "F1-Score: 0.7111\n",
      "Overfitting Gap (Train - Test Accuracy): 0.3714\n",
      "‚ö†Ô∏è  Significant overfitting detected - penalized methods should help!\n"
     ]
    }
   ],
   "source": [
    "# 0. Ordinary Logistic Regression (Baseline)\n",
    "print(\"\\n0. ORDINARY LOGISTIC REGRESSION (BASELINE)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# No regularization - this is our baseline to compare against penalized methods\n",
    "ordinary_lr = LogisticRegression(\n",
    "    penalty=None, \n",
    "    max_iter=5000, \n",
    "    solver='lbfgs'\n",
    "    )\n",
    "ordinary_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate ordinary logistic regression\n",
    "ordinary_metrics, ordinary_pred, ordinary_proba = evaluate_model(\n",
    "    ordinary_lr, X_train_scaled, X_test_scaled, y_train, y_test, 'Ordinary LR'\n",
    ")\n",
    "results.append(ordinary_metrics)\n",
    "all_predictions['Ordinary LR'] = ordinary_pred\n",
    "all_probabilities['Ordinary LR'] = ordinary_proba\n",
    "\n",
    "print(f\"Training Accuracy: {ordinary_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {ordinary_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {ordinary_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {ordinary_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ordinary_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {ordinary_metrics['f1']:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfitting = ordinary_metrics['train_accuracy'] - ordinary_metrics['test_accuracy']\n",
    "print(f\"Overfitting Gap (Train - Test Accuracy): {overfitting:.4f}\")\n",
    "if overfitting > 0.05:\n",
    "    print(\"‚ö†Ô∏è  Significant overfitting detected - penalized methods should help!\")\n",
    "else:\n",
    "    print(\"‚úì Low overfitting - but regularization may still improve generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. RIDGE REGRESSION (L2 REGULARIZATION)\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 0.6691\n",
      "Test Accuracy: 0.6857\n",
      "Test AUC: 0.5492\n",
      "Precision: 0.6857\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# 1. Ridge Regression (L2 Regularization)\n",
    "print(\"\\n1. RIDGE REGRESSION (L2 REGULARIZATION)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ridge = LogisticRegressionCV(\n",
    "    Cs=50, # number of C values or specify a list\n",
    "    cv=5, # number of cross-validation folds\n",
    "    penalty='l2',\n",
    "    solver='lbfgs', # or 'liblinear', 'saga'\n",
    "    scoring='accuracy', # or other metrics\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1 # use all available cores\n",
    ")\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate ridge regression\n",
    "ridge_metrics, ridge_pred, ridge_proba = evaluate_model(\n",
    "    ridge, X_train_scaled, X_test_scaled, y_train, y_test, 'Ridge LR'\n",
    ")\n",
    "results.append(ridge_metrics)\n",
    "all_predictions['Ridge LR'] = ridge_pred\n",
    "all_probabilities['Ridge LR'] = ridge_proba\n",
    "print(f\"Training Accuracy: {ridge_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {ridge_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {ridge_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {ridge_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ridge_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {ridge_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. LASSO REGRESSION (L1 REGULARIZATION) - IMPROVED ANALYSIS\n",
      "------------------------------------------------------------\n",
      "Training Accuracy: 0.6691\n",
      "Test Accuracy: 0.6857\n",
      "Test AUC: 0.5000\n",
      "Precision: 0.6857\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# 2. Lasso Regression (L1 Regularization)\n",
    "print(\"\\n2. LASSO REGRESSION (L1 REGULARIZATION)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "lasso = LogisticRegressionCV(\n",
    "    Cs=50, # number of C values or a list of C values\n",
    "    cv=5, # number of cross-validation folds\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    scoring='accuracy', # or other metrics\n",
    "    max_iter=1000, # recommended higher value for convergence\n",
    "    n_jobs=-1 # use all cores\n",
    ")\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate lasso regression\n",
    "lasso_metrics, lasso_pred, lasso_proba = evaluate_model(\n",
    "    lasso, X_train_scaled, X_test_scaled, y_train, y_test, 'Lasso LR'\n",
    ")\n",
    "results.append(lasso_metrics)\n",
    "all_predictions['Lasso LR'] = lasso_pred\n",
    "all_probabilities['Lasso LR'] = lasso_proba\n",
    "print(f\"Training Accuracy: {lasso_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {lasso_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {lasso_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {lasso_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {lasso_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {lasso_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ELASTIC NET (L1 + L2 REGULARIZATION)\n",
      "--------------------------------------------------\n",
      "Training Accuracy: 0.6691\n",
      "Test Accuracy: 0.6857\n",
      "Test AUC: 0.5000\n",
      "Precision: 0.6857\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# 3. Elastic Net (L1 + L2 Regularization)\n",
    "print(\"\\n3. ELASTIC NET (L1 + L2 REGULARIZATION)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "elastic_net = LogisticRegressionCV(\n",
    "    Cs=10, # number of C values or a list of C values\n",
    "    cv=5, # number of cross-validation folds\n",
    "    penalty='elasticnet',\n",
    "    solver='saga',\n",
    "    l1_ratios=[0.1, 0.5, 0.7, 0.9], # mix of L1 and L2\n",
    "    scoring='accuracy', # or other metrics\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1 # use all cores\n",
    ")\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate elastic net regression\n",
    "elastic_net_metrics, elastic_net_pred, elastic_net_proba = evaluate_model(\n",
    "    elastic_net, X_train_scaled, X_test_scaled, y_train, y_test, 'Elastic Net LR'\n",
    ")\n",
    "results.append(elastic_net_metrics)\n",
    "all_predictions['Elastic Net LR'] = elastic_net_pred\n",
    "all_probabilities['Elastic Net LR'] = elastic_net_proba\n",
    "print(f\"Training Accuracy: {elastic_net_metrics['train_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {elastic_net_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {elastic_net_metrics['test_auc']:.4f}\")\n",
    "print(f\"Precision: {elastic_net_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {elastic_net_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {elastic_net_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-18T04:07:15.230757Z",
     "iopub.status.idle": "2025-09-18T04:07:15.231052Z",
     "shell.execute_reply": "2025-09-18T04:07:15.230915Z",
     "shell.execute_reply.started": "2025-09-18T04:07:15.230905Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "Performance Metrics Table:\n",
      "         model  train_accuracy  test_accuracy  train_auc  test_auc  precision  \\\n",
      "0  Ordinary LR          1.0000         0.6286     1.0000    0.5909     0.7619   \n",
      "1        Ridge          0.6691         0.6857     0.7221    0.5530     0.6857   \n",
      "2        Lasso          0.6691         0.6857     0.6947    0.5114     0.6857   \n",
      "3  Elastic Net          0.6691         0.6857     0.5000    0.5000     0.6857   \n",
      "\n",
      "   recall      f1  \n",
      "0  0.6667  0.7111  \n",
      "1  1.0000  0.8136  \n",
      "2  1.0000  0.8136  \n",
      "3  1.0000  0.8136  \n",
      "\n",
      "Relative Improvements over Ordinary Logistic Regression:\n",
      "\n",
      "Ridge:\n",
      "  AUC improvement: -0.0379\n",
      "  Accuracy improvement: +0.0571\n",
      "  Overfitting reduction: +0.3880\n",
      "\n",
      "Lasso:\n",
      "  AUC improvement: -0.0795\n",
      "  Accuracy improvement: +0.0571\n",
      "  Overfitting reduction: +0.3880\n",
      "\n",
      "Elastic Net:\n",
      "  AUC improvement: -0.0909\n",
      "  Accuracy improvement: +0.0571\n",
      "  Overfitting reduction: +0.3880\n",
      "\n",
      "üèÜ Best Model (by AUC): Ordinary LR with AUC = 0.5909\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive results comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display results table\n",
    "print(\"\\nPerformance Metrics Table:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Calculate relative improvements over ordinary logistic regression\n",
    "print(\"\\nRelative Improvements over Ordinary Logistic Regression:\")\n",
    "baseline_metrics = results_df[results_df['model'] == 'Ordinary LR'].iloc[0]\n",
    "for idx, row in results_df.iterrows():\n",
    "    if row['model'] != 'Ordinary LR':\n",
    "        auc_improvement = row['test_auc'] - baseline_metrics['test_auc']\n",
    "        acc_improvement = row['test_accuracy'] - baseline_metrics['test_accuracy']\n",
    "        overfitting_reduction = (baseline_metrics['train_accuracy'] - baseline_metrics['test_accuracy']) - \\\n",
    "                               (row['train_accuracy'] - row['test_accuracy'])\n",
    "        print(f\"\\n{row['model']}:\")\n",
    "        print(f\"  AUC improvement: {auc_improvement:+.4f}\")\n",
    "        print(f\"  Accuracy improvement: {acc_improvement:+.4f}\")\n",
    "        print(f\"  Overfitting reduction: {overfitting_reduction:+.4f}\")\n",
    "\n",
    "# Find best performing model\n",
    "best_auc_idx = results_df['test_auc'].idxmax()\n",
    "best_model = results_df.loc[best_auc_idx]\n",
    "print(f\"\\nüèÜ Best Model (by AUC): {best_model['model']} with AUC = {best_model['test_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
