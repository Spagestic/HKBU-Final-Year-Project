{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13195792,"sourceType":"datasetVersion","datasetId":8362584}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0e1f368d-ac24-44a9-ba9a-6f038b857511","cell_type":"markdown","source":"Toxicity Dataset : https://archive.ics.uci.edu/dataset/728/toxicity-2\n\nThe dataset includes 171 molecules designed for functional domains of a core clock protein, CRY1, responsible for generating circadian rhythm. 56 of the molecules are toxic and the rest are non-toxic. \n\nThe data consists a complete set of 1203 molecular descriptors and needs feature selection before classification since some of the features are redundant. \n\nIntroductory Paper:\nStructure-based design and classifications of small molecules regulating the circadian rhythm period\nBy Seref Gul, F. Rahim, Safak Isin, Fatma Yilmaz, Nuri Ozturk, M. Turkay, I. Kavakli. 2021\nhttps://www.semanticscholar.org/paper/Structure-based-design-and-classifications-of-small-Gul-Rahim/5944836c47bc7d1a2b0464a9a1db94d4bc7f28ce","metadata":{}},{"id":"784a0694","cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:14.013178Z","iopub.execute_input":"2025-11-03T07:43:14.013633Z","iopub.status.idle":"2025-11-03T07:43:15.898847Z","shell.execute_reply.started":"2025-11-03T07:43:14.013604Z","shell.execute_reply":"2025-11-03T07:43:15.897713Z"}},"outputs":[],"execution_count":1},{"id":"4f67d9b8","cell_type":"code","source":"# Load and preprocess data\ndata = pd.read_csv(\"/kaggle/input/toxicity/data.csv\")\nX = data.drop('Class', axis=1) if 'Class' in data.columns else data.iloc[:, :-1]\ny = data['Class'] if 'Class' in data.columns else data.iloc[:, -1]\ny_binary = (y == 'NonToxic').astype(int)\n\nprint(f\"Dataset shape: {data.shape}\")\nprint(f\"Class distribution:\\n{y.value_counts()}\")\nprint(f\"Class balance:\\n{y.value_counts(normalize=True)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:15.900474Z","iopub.execute_input":"2025-11-03T07:43:15.901031Z","iopub.status.idle":"2025-11-03T07:43:16.018108Z","shell.execute_reply.started":"2025-11-03T07:43:15.901000Z","shell.execute_reply":"2025-11-03T07:43:16.016956Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (171, 1204)\nClass distribution:\nClass\nNonToxic    115\nToxic        56\nName: count, dtype: int64\nClass balance:\nClass\nNonToxic    0.672515\nToxic       0.327485\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":2},{"id":"a982a9bb","cell_type":"code","source":"# Shuffle and split\nnp.random.seed(42)\nshuffle_idx = np.random.permutation(len(X))\nX_shuffled, y_shuffled = X.iloc[shuffle_idx].reset_index(drop=True), y_binary.iloc[shuffle_idx].reset_index(drop=True)\nX_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=42, stratify=y_shuffled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:16.019254Z","iopub.execute_input":"2025-11-03T07:43:16.019625Z","iopub.status.idle":"2025-11-03T07:43:16.036924Z","shell.execute_reply.started":"2025-11-03T07:43:16.019597Z","shell.execute_reply":"2025-11-03T07:43:16.035595Z"}},"outputs":[],"execution_count":3},{"id":"3bdded5e","cell_type":"code","source":"# Standardize\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:16.039437Z","iopub.execute_input":"2025-11-03T07:43:16.039773Z","iopub.status.idle":"2025-11-03T07:43:16.116367Z","shell.execute_reply.started":"2025-11-03T07:43:16.039742Z","shell.execute_reply":"2025-11-03T07:43:16.115526Z"}},"outputs":[],"execution_count":4},{"id":"3a36dc4e-af1a-4df2-9503-82c9db4ed502","cell_type":"code","source":"print(f\"Training set: {X_train_scaled.shape}, Test set: {X_test_scaled.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:16.117026Z","iopub.execute_input":"2025-11-03T07:43:16.117268Z","iopub.status.idle":"2025-11-03T07:43:16.123757Z","shell.execute_reply.started":"2025-11-03T07:43:16.117248Z","shell.execute_reply":"2025-11-03T07:43:16.122447Z"}},"outputs":[{"name":"stdout","text":"Training set: (136, 1203), Test set: (35, 1203)\n","output_type":"stream"}],"execution_count":5},{"id":"75ccabd5","cell_type":"code","source":"# Define models to compare\nmodels = {\n    # === LINEAR MODELS ===\n    'LR_No_Penalty': LogisticRegression(penalty=None, max_iter=2000, solver='lbfgs'),\n    'LR_Ridge_C1': LogisticRegression(penalty='l2', C=1.0, max_iter=2000, solver='lbfgs'),\n    'LR_Ridge_C0.1': LogisticRegression(penalty='l2', C=0.1, max_iter=2000, solver='lbfgs'),\n    'LR_Ridge_C10': LogisticRegression(penalty='l2', C=10.0, max_iter=2000, solver='lbfgs'),\n    'LR_Lasso_C1': LogisticRegression(penalty='l1', C=1.0, max_iter=2000, solver='saga'),\n    'LR_Lasso_C0.1': LogisticRegression(penalty='l1', C=0.1, max_iter=2000, solver='saga'),\n    'LR_ElasticNet_L1_0.5': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, max_iter=2000),\n    'LR_ElasticNet_L1_0.7': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.7, C=1.0, max_iter=2000),\n    'Ridge_Classifier': RidgeClassifier(alpha=1.0),\n    'SGD_Classifier': SGDClassifier(loss='log_loss', max_iter=2000, random_state=42),\n    \n    # === DISCRIMINANT ANALYSIS ===\n    'LDA': LinearDiscriminantAnalysis(),\n    'QDA': QuadraticDiscriminantAnalysis(),\n    \n    # === NAIVE BAYES ===\n    'Naive_Bayes': GaussianNB(),\n    \n    # === TREE-BASED MODELS ===\n    'Decision_Tree_D5': DecisionTreeClassifier(max_depth=5, random_state=42),\n    'Decision_Tree_D10': DecisionTreeClassifier(max_depth=10, random_state=42),\n    'Decision_Tree_D20': DecisionTreeClassifier(max_depth=20, random_state=42),\n    'Decision_Tree_Unpruned': DecisionTreeClassifier(random_state=42),\n    \n    # === ENSEMBLE MODELS - BAGGING ===\n    'Random_Forest_N50': RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42),\n    'Random_Forest_N100': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n    'Random_Forest_N200': RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n    'Random_Forest_Deep': RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42),\n    'Extra_Trees_N100': ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42),\n    \n    # === ENSEMBLE MODELS - BOOSTING ===\n    'AdaBoost_N50': AdaBoostClassifier(n_estimators=50, random_state=42, algorithm='SAMME'),\n    'AdaBoost_N100': AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME'),\n    'GradientBoosting_N50': GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42),\n    'GradientBoosting_N100': GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42),\n    'XGBoost_D3_N50': XGBClassifier(max_depth=3, n_estimators=50, random_state=42, eval_metric='logloss', use_label_encoder=False),\n    'XGBoost_D3_N100': XGBClassifier(max_depth=3, n_estimators=100, random_state=42, eval_metric='logloss', use_label_encoder=False),\n    'XGBoost_D5_N100': XGBClassifier(max_depth=5, n_estimators=100, random_state=42, eval_metric='logloss', use_label_encoder=False),\n    \n    # === SVM VARIATIONS ===\n    'SVM_Linear': SVC(kernel='linear', probability=True, random_state=42),\n    'SVM_RBF_C1': SVC(kernel='rbf', C=1.0, probability=True, random_state=42),\n    'SVM_RBF_C10': SVC(kernel='rbf', C=10.0, probability=True, random_state=42),\n    'SVM_Poly_D2': SVC(kernel='poly', degree=2, probability=True, random_state=42),\n    'SVM_Poly_D3': SVC(kernel='poly', degree=3, probability=True, random_state=42),\n    \n    # === K-NEAREST NEIGHBORS ===\n    'KNN_K3': KNeighborsClassifier(n_neighbors=3),\n    'KNN_K5': KNeighborsClassifier(n_neighbors=5),\n    'KNN_K7': KNeighborsClassifier(n_neighbors=7),\n    'KNN_K10': KNeighborsClassifier(n_neighbors=10),\n    \n    # === NEURAL NETWORKS ===\n    'NN_Small': MLPClassifier(hidden_layer_sizes=(25,), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Medium': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Large': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Deep': MLPClassifier(hidden_layer_sizes=(100, 50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Adam': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='adam'),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:16.124997Z","iopub.execute_input":"2025-11-03T07:43:16.125376Z","iopub.status.idle":"2025-11-03T07:43:16.151226Z","shell.execute_reply.started":"2025-11-03T07:43:16.125348Z","shell.execute_reply":"2025-11-03T07:43:16.150258Z"}},"outputs":[],"execution_count":6},{"id":"9c7e3b93","cell_type":"code","source":"# Evaluation function\ndef evaluate_model(model, X_train, X_test, y_train, y_test):\n    \"\"\"Evaluate a classification model and return metrics\"\"\"\n    X_train_selected, X_test_selected = X_train, X_test\n    model.fit(X_train_selected, y_train)\n    \n    # Predictions\n    y_train_pred = model.predict(X_train_selected)\n    y_test_pred = model.predict(X_test_selected)\n    \n    # Probabilities\n    if hasattr(model, 'predict_proba'):\n        y_train_proba = model.predict_proba(X_train_selected)[:, 1]\n        y_test_proba = model.predict_proba(X_test_selected)[:, 1]\n    else:\n        y_train_proba = model.decision_function(X_train_selected)\n        y_test_proba = model.decision_function(X_test_selected)\n    \n    return {\n        'train_acc': accuracy_score(y_train, y_train_pred),\n        'test_acc': accuracy_score(y_test, y_test_pred),\n        'train_auc': roc_auc_score(y_train, y_train_proba),\n        'test_auc': roc_auc_score(y_test, y_test_proba),\n        'precision': precision_score(y_test, y_test_pred),\n        'recall': recall_score(y_test, y_test_pred),\n        'f1': f1_score(y_test, y_test_pred)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:16.152015Z","iopub.execute_input":"2025-11-03T07:43:16.152339Z","iopub.status.idle":"2025-11-03T07:43:16.170418Z","shell.execute_reply.started":"2025-11-03T07:43:16.152309Z","shell.execute_reply":"2025-11-03T07:43:16.169354Z"}},"outputs":[],"execution_count":7},{"id":"104e44f5","cell_type":"code","source":"# Train and evaluate all models (WITHOUT class weights)\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAINING MODELS WITHOUT CLASS WEIGHTS\")\nprint(\"=\"*80)\nresults = []\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    metrics = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n    metrics['model'] = name\n    results.append(metrics)\n    print(f\"  Test Accuracy: {metrics['test_acc']:.4f}, Test AUC: {metrics['test_auc']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:16.171148Z","iopub.execute_input":"2025-11-03T07:43:16.171500Z","iopub.status.idle":"2025-11-03T07:43:55.158724Z","shell.execute_reply.started":"2025-11-03T07:43:16.171468Z","shell.execute_reply":"2025-11-03T07:43:55.157568Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTRAINING MODELS WITHOUT CLASS WEIGHTS\n================================================================================\nTraining LR_No_Penalty...\n  Test Accuracy: 0.5714, Test AUC: 0.5871\nTraining LR_Ridge_C1...\n  Test Accuracy: 0.5714, Test AUC: 0.5644\nTraining LR_Ridge_C0.1...\n  Test Accuracy: 0.5714, Test AUC: 0.5758\nTraining LR_Ridge_C10...\n  Test Accuracy: 0.5714, Test AUC: 0.5606\nTraining LR_Lasso_C1...\n  Test Accuracy: 0.6000, Test AUC: 0.5455\nTraining LR_Lasso_C0.1...\n  Test Accuracy: 0.6857, Test AUC: 0.5644\nTraining LR_ElasticNet_L1_0.5...\n  Test Accuracy: 0.6000, Test AUC: 0.5417\nTraining LR_ElasticNet_L1_0.7...\n  Test Accuracy: 0.6000, Test AUC: 0.5417\nTraining Ridge_Classifier...\n  Test Accuracy: 0.5143, Test AUC: 0.5492\nTraining SGD_Classifier...\n  Test Accuracy: 0.5714, Test AUC: 0.4924\nTraining LDA...\n  Test Accuracy: 0.6000, Test AUC: 0.5473\nTraining QDA...\n  Test Accuracy: 0.5143, Test AUC: 0.4981\nTraining Naive_Bayes...\n  Test Accuracy: 0.4286, Test AUC: 0.5076\nTraining Decision_Tree_D5...\n  Test Accuracy: 0.6286, Test AUC: 0.5795\nTraining Decision_Tree_D10...\n  Test Accuracy: 0.6000, Test AUC: 0.5852\nTraining Decision_Tree_D20...\n  Test Accuracy: 0.6000, Test AUC: 0.5852\nTraining Decision_Tree_Unpruned...\n  Test Accuracy: 0.6000, Test AUC: 0.5852\nTraining Random_Forest_N50...\n  Test Accuracy: 0.6571, Test AUC: 0.6383\nTraining Random_Forest_N100...\n  Test Accuracy: 0.6286, Test AUC: 0.6212\nTraining Random_Forest_N200...\n  Test Accuracy: 0.6286, Test AUC: 0.6136\nTraining Random_Forest_Deep...\n  Test Accuracy: 0.6286, Test AUC: 0.6307\nTraining Extra_Trees_N100...\n  Test Accuracy: 0.6286, Test AUC: 0.6629\nTraining AdaBoost_N50...\n  Test Accuracy: 0.6286, Test AUC: 0.6364\nTraining AdaBoost_N100...\n  Test Accuracy: 0.6286, Test AUC: 0.5985\nTraining GradientBoosting_N50...\n  Test Accuracy: 0.6571, Test AUC: 0.6856\nTraining GradientBoosting_N100...\n  Test Accuracy: 0.6571, Test AUC: 0.6250\nTraining XGBoost_D3_N50...\n  Test Accuracy: 0.6000, Test AUC: 0.6553\nTraining XGBoost_D3_N100...\n  Test Accuracy: 0.6571, Test AUC: 0.6667\nTraining XGBoost_D5_N100...\n  Test Accuracy: 0.5714, Test AUC: 0.5720\nTraining SVM_Linear...\n  Test Accuracy: 0.5429, Test AUC: 0.4432\nTraining SVM_RBF_C1...\n  Test Accuracy: 0.6857, Test AUC: 0.3826\nTraining SVM_RBF_C10...\n  Test Accuracy: 0.4857, Test AUC: 0.4053\nTraining SVM_Poly_D2...\n  Test Accuracy: 0.6857, Test AUC: 0.3826\nTraining SVM_Poly_D3...\n  Test Accuracy: 0.6857, Test AUC: 0.3333\nTraining KNN_K3...\n  Test Accuracy: 0.6571, Test AUC: 0.6951\nTraining KNN_K5...\n  Test Accuracy: 0.6571, Test AUC: 0.7027\nTraining KNN_K7...\n  Test Accuracy: 0.6571, Test AUC: 0.6667\nTraining KNN_K10...\n  Test Accuracy: 0.6571, Test AUC: 0.6553\nTraining NN_Small...\n  Test Accuracy: 0.6000, Test AUC: 0.6496\nTraining NN_Medium...\n  Test Accuracy: 0.6286, Test AUC: 0.5360\nTraining NN_Large...\n  Test Accuracy: 0.5429, Test AUC: 0.5492\nTraining NN_Deep...\n  Test Accuracy: 0.5429, Test AUC: 0.5625\nTraining NN_Adam...\n  Test Accuracy: 0.5429, Test AUC: 0.4962\n","output_type":"stream"}],"execution_count":8},{"id":"aef92fa2","cell_type":"code","source":"# Create results DataFrame\nresults_df = pd.DataFrame(results)\nresults_df = results_df[['model', 'train_acc', 'test_acc', 'train_auc', 'test_auc', 'precision', 'recall', 'f1']]\nresults_df = results_df.sort_values('test_acc', ascending=False).reset_index(drop=True)\n\nprint(\"\\n=== MODEL COMPARISON (NO CLASS WEIGHTS) ===\")\nprint(results_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:55.159777Z","iopub.execute_input":"2025-11-03T07:43:55.160353Z","iopub.status.idle":"2025-11-03T07:43:55.180357Z","shell.execute_reply.started":"2025-11-03T07:43:55.160317Z","shell.execute_reply":"2025-11-03T07:43:55.179196Z"}},"outputs":[{"name":"stdout","text":"\n=== MODEL COMPARISON (NO CLASS WEIGHTS) ===\n                 model  train_acc  test_acc  train_auc  test_auc  precision   recall       f1\n           SVM_Poly_D2   0.720588  0.685714   0.011966  0.382576   0.685714 1.000000 0.813559\n            SVM_RBF_C1   0.727941  0.685714   0.010501  0.382576   0.685714 1.000000 0.813559\n         LR_Lasso_C0.1   0.669118  0.685714   0.723077  0.564394   0.685714 1.000000 0.813559\n           SVM_Poly_D3   0.720588  0.685714   0.006105  0.333333   0.685714 1.000000 0.813559\n     Random_Forest_N50   1.000000  0.657143   1.000000  0.638258   0.714286 0.833333 0.769231\n                KNN_K3   0.757353  0.657143   0.779487  0.695076   0.750000 0.750000 0.750000\n                KNN_K5   0.713235  0.657143   0.757021  0.702652   0.714286 0.833333 0.769231\n                KNN_K7   0.727941  0.657143   0.728816  0.666667   0.714286 0.833333 0.769231\n               KNN_K10   0.654412  0.657143   0.682051  0.655303   0.730769 0.791667 0.760000\n  GradientBoosting_N50   1.000000  0.657143   1.000000  0.685606   0.730769 0.791667 0.760000\n GradientBoosting_N100   1.000000  0.657143   1.000000  0.625000   0.730769 0.791667 0.760000\n       XGBoost_D3_N100   1.000000  0.657143   1.000000  0.666667   0.714286 0.833333 0.769231\n          AdaBoost_N50   1.000000  0.628571   1.000000  0.636364   0.720000 0.750000 0.734694\n         AdaBoost_N100   1.000000  0.628571   1.000000  0.598485   0.720000 0.750000 0.734694\n    Random_Forest_Deep   1.000000  0.628571   1.000000  0.630682   0.703704 0.791667 0.745098\n    Random_Forest_N200   1.000000  0.628571   1.000000  0.613636   0.703704 0.791667 0.745098\n    Random_Forest_N100   1.000000  0.628571   1.000000  0.621212   0.703704 0.791667 0.745098\n      Extra_Trees_N100   1.000000  0.628571   1.000000  0.662879   0.703704 0.791667 0.745098\n      Decision_Tree_D5   0.948529  0.628571   0.989866  0.579545   0.761905 0.666667 0.711111\n             NN_Medium   1.000000  0.628571   1.000000  0.535985   0.739130 0.708333 0.723404\nDecision_Tree_Unpruned   1.000000  0.600000   1.000000  0.585227   0.750000 0.625000 0.681818\n     Decision_Tree_D20   1.000000  0.600000   1.000000  0.585227   0.750000 0.625000 0.681818\n                   LDA   0.955882  0.600000   0.993407  0.547348   0.750000 0.625000 0.681818\n  LR_ElasticNet_L1_0.7   0.992647  0.600000   1.000000  0.541667   0.708333 0.708333 0.708333\n  LR_ElasticNet_L1_0.5   0.992647  0.600000   1.000000  0.541667   0.708333 0.708333 0.708333\n           LR_Lasso_C1   0.992647  0.600000   0.999267  0.545455   0.708333 0.708333 0.708333\n              NN_Small   1.000000  0.600000   1.000000  0.649621   0.708333 0.708333 0.708333\n        XGBoost_D3_N50   1.000000  0.600000   1.000000  0.655303   0.692308 0.750000 0.720000\n     Decision_Tree_D10   1.000000  0.600000   1.000000  0.585227   0.750000 0.625000 0.681818\n         LR_No_Penalty   1.000000  0.571429   1.000000  0.587121   0.714286 0.625000 0.666667\n       XGBoost_D5_N100   1.000000  0.571429   1.000000  0.571970   0.666667 0.750000 0.705882\n           LR_Ridge_C1   1.000000  0.571429   1.000000  0.564394   0.695652 0.666667 0.680851\n        SGD_Classifier   0.985294  0.571429   0.988889  0.492424   0.680000 0.708333 0.693878\n          LR_Ridge_C10   1.000000  0.571429   1.000000  0.560606   0.695652 0.666667 0.680851\n         LR_Ridge_C0.1   0.992647  0.571429   0.999756  0.575758   0.680000 0.708333 0.693878\n            SVM_Linear   1.000000  0.542857   0.000000  0.443182   0.666667 0.666667 0.666667\n              NN_Large   1.000000  0.542857   1.000000  0.549242   0.653846 0.708333 0.680000\n               NN_Deep   1.000000  0.542857   1.000000  0.562500   0.666667 0.666667 0.666667\n               NN_Adam   0.794118  0.542857   0.858364  0.496212   0.681818 0.625000 0.652174\n                   QDA   1.000000  0.514286   1.000000  0.498106   0.684211 0.541667 0.604651\n      Ridge_Classifier   1.000000  0.514286   1.000000  0.549242   0.684211 0.541667 0.604651\n           SVM_RBF_C10   1.000000  0.485714   0.000000  0.405303   0.625000 0.625000 0.625000\n           Naive_Bayes   0.580882  0.428571   0.861783  0.507576   0.750000 0.250000 0.375000\n","output_type":"stream"}],"execution_count":9},{"id":"0c76df29-3bc3-40ff-8239-ebfe4f73e6ea","cell_type":"code","source":"# ===== FEATURE IMPORTANCE ANALYSIS =====\nprint(\"\\n\" + \"=\"*80)\nprint(\"FEATURE IMPORTANCE COMPARISON WITH ORIGINAL STUDY\")\nprint(\"=\"*80)\n\n# Original study's important features\noriginal_features = ['MDEC-23', 'MATS2v', 'ATSC8s', 'VE3_Dt', 'CrippenMR', 'SpMax7_Bhe',\n                     'SpMin1_Bhs', 'C1SP2', 'GATS8e', 'GATS8s', 'SpMax5_Bhv', 'VE3_Dzi', 'VPC-4']\n\nfeature_names = X.columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:55.184284Z","iopub.execute_input":"2025-11-03T07:43:55.184588Z","iopub.status.idle":"2025-11-03T07:43:55.194958Z","shell.execute_reply.started":"2025-11-03T07:43:55.184565Z","shell.execute_reply":"2025-11-03T07:43:55.193732Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nFEATURE IMPORTANCE COMPARISON WITH ORIGINAL STUDY\n================================================================================\n","output_type":"stream"}],"execution_count":10},{"id":"3e7adcb7-6c5e-4ea1-a603-b985281ce327","cell_type":"code","source":"def get_feature_importance(model, model_name, X_train, X_test, y_train, y_test):\n    \"\"\"Extract feature importance for different model types\"\"\"\n    # Tree-based models: use built-in feature_importances_\n    if hasattr(model, 'feature_importances_'):\n        importances = model.feature_importances_\n        method = \"Built-in (Impurity-based)\"\n    # Linear models: use absolute coefficient values\n    elif hasattr(model, 'coef_'):\n        importances = np.abs(model.coef_[0])\n        method = \"Coefficients\"\n    # Other models: use permutation importance\n    else:\n        perm_importance = permutation_importance(\n            model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n        )\n        importances = perm_importance.importances_mean\n        method = \"Permutation\"\n    \n    # Create DataFrame with feature importance\n    importance_df = pd.DataFrame({\n        'feature': feature_names,\n        'importance': importances\n    }).sort_values('importance', ascending=False)\n    \n    return importance_df, method","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:55.195713Z","iopub.execute_input":"2025-11-03T07:43:55.195978Z","iopub.status.idle":"2025-11-03T07:43:55.214061Z","shell.execute_reply.started":"2025-11-03T07:43:55.195957Z","shell.execute_reply":"2025-11-03T07:43:55.212978Z"}},"outputs":[],"execution_count":11},{"id":"0b6cce8d-e5ec-49cf-be29-7a376fb75caf","cell_type":"code","source":"# Extract feature importance for each trained model\nprint(f\"\\nOriginal study identified {len(original_features)} important features using DTC:\")\nprint(original_features)\nprint(\"\\n\" + \"-\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:55.215532Z","iopub.execute_input":"2025-11-03T07:43:55.215831Z","iopub.status.idle":"2025-11-03T07:43:55.236695Z","shell.execute_reply.started":"2025-11-03T07:43:55.215808Z","shell.execute_reply":"2025-11-03T07:43:55.235533Z"}},"outputs":[{"name":"stdout","text":"\nOriginal study identified 13 important features using DTC:\n['MDEC-23', 'MATS2v', 'ATSC8s', 'VE3_Dt', 'CrippenMR', 'SpMax7_Bhe', 'SpMin1_Bhs', 'C1SP2', 'GATS8e', 'GATS8s', 'SpMax5_Bhv', 'VE3_Dzi', 'VPC-4']\n\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":12},{"id":"018cc492-dfa8-427f-b4d9-0a0af32ac086","cell_type":"code","source":"feature_comparison = {}\n\nfor name, model in models.items():\n    print(f\"\\n### {name} ###\")\n    \n    # Get feature importance\n    importance_df, method = get_feature_importance(model, name, X_train_scaled, X_test_scaled, y_train, y_test)\n    \n    # Get top 13 features (same number as original study)\n    top_13 = importance_df.head(13)\n    top_13_features = top_13['feature'].tolist()\n    \n    # Calculate overlap with original study\n    overlap = set(top_13_features) & set(original_features)\n    overlap_count = len(overlap)\n    overlap_pct = (overlap_count / len(original_features)) * 100\n    \n    print(f\"Method: {method}\")\n    print(f\"\\nTop 13 Features:\")\n    print(top_13.to_string(index=False))\n    print(f\"\\nOverlap with original study: {overlap_count}/{len(original_features)} ({overlap_pct:.1f}%)\")\n    if overlap:\n        print(f\"Matching features: {sorted(overlap)}\")\n    \n    feature_comparison[name] = {\n        'top_13': top_13_features,\n        'overlap_count': overlap_count,\n        'overlap_features': sorted(overlap),\n        'method': method\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:43:55.237636Z","iopub.execute_input":"2025-11-03T07:43:55.237952Z","iopub.status.idle":"2025-11-03T07:47:58.271268Z","shell.execute_reply.started":"2025-11-03T07:43:55.237924Z","shell.execute_reply":"2025-11-03T07:47:58.270302Z"}},"outputs":[{"name":"stdout","text":"\n### LR_No_Penalty ###\nMethod: Coefficients\n\nTop 13 Features:\n        feature  importance\n           JGI7    4.427035\n       maxsssCH    4.049126\n        nHBint3    3.663130\n      topoShape    3.568342\n         ALogp2    3.528732\n         WTPT-2    3.461760\nPetitjeanNumber    3.400879\n          C3SP3    3.381391\n      minHBint4    3.334651\n      maxHBint4    3.254575\n        minssNH    3.167231\n        maxssNH    3.122925\n        nF6Ring    3.050619\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_Ridge_C1 ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n   ALogp2    0.485300\n BCUTw-1l    0.450650\n maxsssCH    0.418850\n    minsF    0.418486\n    maxsF    0.407373\n    nBase    0.396368\n  minssNH    0.381735\n   MATS1s    0.373555\n  maxssNH    0.368521\nmaxHBint5    0.357965\n  VE3_Dzs    0.346970\n    C3SP3    0.345447\nminHCsatu    0.336533\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_Ridge_C0.1 ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n   ALogp2    0.184552\n  minssNH    0.174667\n  maxssNH    0.169893\n maxsssCH    0.169388\n     JGI7    0.161604\n    nBase    0.160236\n BCUTw-1l    0.156474\nmaxHBint5    0.153518\ntopoShape    0.152996\nmaxHBint4    0.151024\nminHCsatu    0.150819\n   MATS1s    0.150054\nminHBint4    0.147346\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_Ridge_C10 ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n   ALogp2    0.883392\n BCUTw-1l    0.817325\n    minsF    0.763319\n    maxsF    0.743727\n maxsssCH    0.730328\n    nBase    0.687532\n   MATS1s    0.647935\n  minssNH    0.634342\n  maxssNH    0.608985\nmaxHBint5    0.595325\n  VE3_Dzs    0.584116\n    C3SP3    0.574323\n  minaasC    0.560721\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_Lasso_C1 ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n     JGI7    0.502660\nminHBint4    0.351879\nminHCsatu    0.351458\n  minssNH    0.347392\n  maxssNH    0.338179\nmaxHBint4    0.323298\n   MATS1s    0.295117\n    C3SP3    0.293685\n   ALogp2    0.292476\n     GGI7    0.282097\n    EE_Dt    0.279185\n    nBase    0.267753\nmaxHCsatu    0.265740\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_Lasso_C0.1 ###\nMethod: Coefficients\n\nTop 13 Features:\n    feature  importance\n      C2SP2    0.099964\n     ATSC3e    0.074701\n     GATS7v    0.059416\n      EE_Dt    0.048244\n    AATSC8i    0.019161\n    AATSC7p    0.012475\n     MATS7p    0.005906\n  topoShape    0.000009\n     MATS3v    0.000000\nCrippenLogP    0.000000\n      ATS2s    0.000000\n      ATS2p    0.000000\n      ATS2v    0.000000\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_ElasticNet_L1_0.5 ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n     JGI7    0.398688\n    nBase    0.357958\n   ALogp2    0.355442\nminHCsatu    0.342695\n maxsssCH    0.333121\n  minssNH    0.326039\n   MATS1s    0.325097\n  maxssNH    0.318167\nminHBint4    0.311456\n    C3SP3    0.311167\nmaxHBint4    0.302915\nmaxHCsatu    0.293238\n    minsF    0.276833\n\nOverlap with original study: 0/13 (0.0%)\n\n### LR_ElasticNet_L1_0.7 ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n     JGI7    0.445885\nminHCsatu    0.349651\n  minssNH    0.333583\n   ALogp2    0.331574\n    nBase    0.330496\nminHBint4    0.327567\n  maxssNH    0.325611\n   MATS1s    0.315993\nmaxHBint4    0.311815\n    C3SP3    0.310375\n maxsssCH    0.307410\nmaxHCsatu    0.291100\n     GGI7    0.274380\n\nOverlap with original study: 0/13 (0.0%)\n\n### Ridge_Classifier ###\nMethod: Coefficients\n\nTop 13 Features:\n   feature  importance\n  BCUTw-1l    0.229891\n    ALogp2    0.192972\n     minsF    0.181981\nSpMin8_Bhm    0.179561\n     nBase    0.177753\n     maxsF    0.177266\n    ATSC7v    0.173178\n    minHBa    0.168520\n    MATS4m    0.160959\n  maxsssCH    0.155406\n     JGI10    0.151135\n minHBint8    0.148780\n   MDEC-22    0.146621\n\nOverlap with original study: 0/13 (0.0%)\n\n### SGD_Classifier ###\nMethod: Coefficients\n\nTop 13 Features:\n  feature  importance\n   ALogp2  135.231164\n  minssNH  121.646633\n    minsF  117.488859\n  maxssNH  116.361465\nminHBint4  114.991423\n    maxsF  114.515893\n    C3SP3  112.006566\nmaxHBint4  110.577302\n    nBase  109.188217\ntopoShape  107.451923\n   MATS1s  106.513005\n   minHBa  103.643813\nminHCsatu  103.307514\n\nOverlap with original study: 0/13 (0.0%)\n\n### LDA ###\nMethod: Coefficients\n\nTop 13 Features:\n   feature  importance\n  nAtomLAC    8.013940\nSpMin8_Bhm    3.758168\n   MDEC-22    3.727608\n      JGI4    3.346421\nSpMax8_Bhm    2.700423\n     VE1_D    2.562679\n     VE2_D    2.538413\n   MDEC-44    2.504249\n minHother    2.493808\n      JGI5    2.453359\n   AATSC3m    2.392499\n SpMAD_Dzs    2.383699\n      JGI2    2.345261\n\nOverlap with original study: 0/13 (0.0%)\n\n### QDA ###\nMethod: Permutation\n\nTop 13 Features:\n          feature  importance\n          AATSC7i    0.057143\n        minHBint2    0.034286\n           minsOH    0.031429\n           ATSC7i    0.031429\n        maxHBint8    0.028571\n             VC-6    0.028571\nLipoaffinityIndex    0.028571\n            VPC-6    0.028571\n            mintN    0.025714\n           AATS6s    0.025714\n             JGI8    0.025714\n           maxssO    0.025714\n               nS    0.025714\n\nOverlap with original study: 0/13 (0.0%)\n\n### Naive_Bayes ###\nMethod: Permutation\n\nTop 13 Features:\n  feature  importance\n  nHBint5    0.028571\n  SHBint5    0.028571\n  MDEC-14    0.025714\n   nFRing    0.005714\nnTG12Ring    0.005714\nnFG12Ring    0.005714\n   nTRing    0.002857\n nT12Ring    0.002857\n     VC-6    0.002857\n     VC-3    0.002857\n    nAcid    0.002857\n   SssCH2    0.002857\n    C4SP3    0.002857\n\nOverlap with original study: 0/13 (0.0%)\n\n### Decision_Tree_D5 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n  feature  importance\nSpDiam_Dt    0.137456\n   MATS5i    0.119304\n    ATS5v    0.115541\nmaxHBint3    0.110780\n   MATS5p    0.090300\n  VE2_Dzp    0.088672\n  AATSC4m    0.085839\n   MATS6i    0.068600\n maxHaaCH    0.062119\n       Mi    0.051450\n   GATS7m    0.037783\nSpMAD_DzZ    0.032156\n  AATSC4i    0.000000\n\nOverlap with original study: 0/13 (0.0%)\n\n### Decision_Tree_D10 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n  feature  importance\nSpDiam_Dt    0.118306\n   MATS5i    0.102682\n    ATS5v    0.099443\nmaxHBint3    0.095346\n  AATSC4s    0.078238\n   MATS5p    0.077719\n  VE2_Dzp    0.076318\n  AATSC4m    0.073880\n   MATS6i    0.059042\n maxHaaCH    0.053464\n       Mi    0.044282\n   GATS7m    0.032519\n   AATS8i    0.032025\n\nOverlap with original study: 0/13 (0.0%)\n\n### Decision_Tree_D20 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n  feature  importance\nSpDiam_Dt    0.118306\n   MATS5i    0.102682\n    ATS5v    0.099443\nmaxHBint3    0.095346\n  AATSC4s    0.078238\n   MATS5p    0.077719\n  VE2_Dzp    0.076318\n  AATSC4m    0.073880\n   MATS6i    0.059042\n maxHaaCH    0.053464\n       Mi    0.044282\n   GATS7m    0.032519\n   AATS8i    0.032025\n\nOverlap with original study: 0/13 (0.0%)\n\n### Decision_Tree_Unpruned ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n  feature  importance\nSpDiam_Dt    0.118306\n   MATS5i    0.102682\n    ATS5v    0.099443\nmaxHBint3    0.095346\n  AATSC4s    0.078238\n   MATS5p    0.077719\n  VE2_Dzp    0.076318\n  AATSC4m    0.073880\n   MATS6i    0.059042\n maxHaaCH    0.053464\n       Mi    0.044282\n   GATS7m    0.032519\n   AATS8i    0.032025\n\nOverlap with original study: 0/13 (0.0%)\n\n### Random_Forest_N50 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n   feature  importance\n    MATS6p    0.008502\n      MWC5    0.008288\n    AATS8v    0.007492\n     ATS6i    0.007202\n      VP-0    0.006724\nETA_dBetaP    0.006485\n     EE_Dt    0.006477\nSpMin2_Bhe    0.006373\nnaAromAtom    0.006227\n    ATSC8c    0.006093\n     MLogP    0.005902\n   AATSC6p    0.005703\n     SaasC    0.005680\n\nOverlap with original study: 0/13 (0.0%)\n\n### Random_Forest_N100 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n     feature  importance\n      ATSC3v    0.005690\n        MWC5    0.005216\n      ATSC2e    0.004981\nETA_EtaP_F_L    0.004923\n       SaasC    0.004753\n  naAromAtom    0.004664\n      GATS4c    0.004624\n      MATS6p    0.004563\n  SpMax4_Bhm    0.004537\n       MLogP    0.004328\n     AATSC4m    0.004233\n        JGI7    0.004142\n     AATSC6p    0.003964\n\nOverlap with original study: 0/13 (0.0%)\n\n### Random_Forest_N200 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n  feature  importance\nSpDiam_Dt    0.004684\n   ATSC2c    0.004681\n   ATSC2e    0.004412\n  VR2_Dzp    0.004133\n SpMax_Dt    0.004016\n   ATSC3v    0.003912\n  AATSC8i    0.003798\n   MATS6p    0.003671\n   ATSC7p    0.003495\n  maxssNH    0.003412\n SpMAD_Dt    0.003361\n  VR1_Dzv    0.003319\n   GATS7p    0.003268\n\nOverlap with original study: 0/13 (0.0%)\n\n### Random_Forest_Deep ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n     feature  importance\n      ATSC3v    0.005690\n        MWC5    0.005216\n      ATSC2e    0.004981\nETA_EtaP_F_L    0.004923\n  naAromAtom    0.004664\n      MATS6p    0.004552\n  SpMax4_Bhm    0.004537\n      GATS4c    0.004516\n       SaasC    0.004469\n       MLogP    0.004328\n     AATSC4m    0.004233\n        JGI7    0.004142\n     AATSC6p    0.003964\n\nOverlap with original study: 0/13 (0.0%)\n\n### Extra_Trees_N100 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n        feature  importance\n        nHBint3    0.004424\n         ATSC3v    0.004038\n      maxHBint5    0.003776\n      topoShape    0.003714\n     SpMin3_Bhi    0.003536\n       minHssNH    0.003466\nPetitjeanNumber    0.003464\n         GATS7p    0.003425\n          C2SP2    0.003412\n        AATSC7m    0.003396\n         MATS6v    0.003374\n         AATS1v    0.003293\n           ndsN    0.003248\n\nOverlap with original study: 0/13 (0.0%)\n\n### AdaBoost_N50 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n   feature  importance\n SpDiam_Dt    0.053435\n    ATSC3v    0.048466\n    GATS7v    0.047706\n      CIC2    0.043438\n     C1SP2    0.041957\n    GATS3c    0.038351\n   AATSC6m    0.034228\n     SCH-7    0.034059\n    GATS7e    0.033730\n    GATS1s    0.033651\nSpMin4_Bhi    0.033329\n     VPC-4    0.033252\n   minssNH    0.027448\n\nOverlap with original study: 2/13 (15.4%)\nMatching features: ['C1SP2', 'VPC-4']\n\n### AdaBoost_N100 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n       feature  importance\n         C1SP2    0.050877\n        GATS3c    0.030835\n    SpMax7_Bhi    0.030164\n     SpDiam_Dt    0.027172\n        GATS1s    0.026192\n       minssNH    0.025158\n        ATSC2e    0.025155\n        ATSC3v    0.024645\n        GATS7v    0.024259\n   ETA_Eta_F_L    0.023174\nETA_dEpsilon_A    0.023093\n    SpMax3_Bhm    0.022874\n          CIC2    0.022089\n\nOverlap with original study: 1/13 (7.7%)\nMatching features: ['C1SP2']\n\n### GradientBoosting_N50 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n   feature  importance\n SpDiam_Dt    0.070046\n     ATS3m    0.039372\n   VE1_Dzp    0.035547\n   AATSC4m    0.029452\n   VR1_Dzv    0.028357\n    ATSC7p    0.027797\n    GATS3c    0.027493\n   AATSC5p    0.026434\nSpMin3_Bhe    0.025770\nSpMax8_Bhp    0.024922\n     ATS5v    0.019762\n     fragC    0.019693\n    ATSC3v    0.019674\n\nOverlap with original study: 0/13 (0.0%)\n\n### GradientBoosting_N100 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n   feature  importance\n SpDiam_Dt    0.068205\n     ATS3m    0.038040\n   VE1_Dzp    0.034601\n   AATSC4m    0.028569\n   VR1_Dzv    0.027567\n    GATS3c    0.027369\n    ATSC7p    0.027359\n   AATSC5p    0.025540\nSpMin3_Bhe    0.024944\nSpMax8_Bhp    0.024079\n   AATSC7c    0.019711\n    ATSC3v    0.019387\n     ATS5v    0.019094\n\nOverlap with original study: 0/13 (0.0%)\n\n### XGBoost_D3_N50 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n        feature  importance\n          ATS3m    0.077217\n  ETA_Epsilon_4    0.035780\nPetitjeanNumber    0.032045\n          ATS2p    0.031506\n         ATSC5i    0.029864\n         MATS3s    0.027988\n     SpMax4_Bhm    0.025862\n         GATS1i    0.025141\n         MATS7p    0.024923\n     SpMax6_Bhv    0.024104\n     SpMin3_Bhe    0.023699\n      SpDiam_Dt    0.022072\n          ASP-6    0.018209\n\nOverlap with original study: 0/13 (0.0%)\n\n### XGBoost_D3_N100 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n      feature  importance\n        ATS3m    0.080561\nETA_Epsilon_4    0.037329\n        ATS2p    0.032870\n       ATSC5i    0.031158\n       MATS3s    0.029200\n   SpMax4_Bhm    0.026982\n       GATS1i    0.026230\n       MATS7p    0.026002\n   SpMax6_Bhv    0.025148\n   SpMin3_Bhe    0.024725\n    SpDiam_Dt    0.023027\n        ASP-6    0.018997\n         CIC2    0.017939\n\nOverlap with original study: 0/13 (0.0%)\n\n### XGBoost_D5_N100 ###\nMethod: Built-in (Impurity-based)\n\nTop 13 Features:\n      feature  importance\n       GATS2p    0.044971\n        ATS3m    0.042093\n     SpMAD_Dt    0.041799\nETA_Epsilon_4    0.036846\n    SpDiam_Dt    0.034236\n     BCUTc-1h    0.030237\n       MATS5c    0.030056\n   SpMax4_Bhm    0.026632\n   SpMax6_Bhv    0.025196\n   SpMax5_Bhm    0.023242\n      AATSC4m    0.020663\n       ATSC8e    0.020303\n      VR1_Dzp    0.019834\n\nOverlap with original study: 0/13 (0.0%)\n\n### SVM_Linear ###\nMethod: Coefficients\n\nTop 13 Features:\n   feature  importance\n    ALogp2    0.230262\n  BCUTw-1l    0.201860\n     minsF    0.198028\n     maxsF    0.193295\n  maxsssCH    0.179018\n     nBase    0.166889\n   minaasC    0.155031\n    MATS1s    0.151742\n   minssNH    0.151584\nSpMin8_Bhm    0.149367\n   MDEC-22    0.148947\n   maxssNH    0.143424\n    ATSC7v    0.139934\n\nOverlap with original study: 0/13 (0.0%)\n\n### SVM_RBF_C1 ###\nMethod: Permutation\n\nTop 13 Features:\n    feature  importance\n     MATS3v         0.0\n       ndNH         0.0\n        JGT         0.0\n      ATS2i         0.0\nCrippenLogP         0.0\n      ATS2s         0.0\n      ATS2p         0.0\n      ATS2v         0.0\n   SHBint10         0.0\n    AATSC4i         0.0\n    AATSC4m         0.0\n    AATSC4c         0.0\n    AATSC4e         0.0\n\nOverlap with original study: 0/13 (0.0%)\n\n### SVM_RBF_C10 ###\nMethod: Permutation\n\nTop 13 Features:\n    feature  importance\n     MATS3v         0.0\n        JGT         0.0\nCrippenLogP         0.0\n      ATS2s         0.0\n      ATS2p         0.0\n      ATS2v         0.0\n   SHBint10         0.0\n    AATSC4i         0.0\n    AATSC4c         0.0\n    AATSC4e         0.0\n     SHssNH         0.0\n    khs.dsN         0.0\n     maxHBa         0.0\n\nOverlap with original study: 0/13 (0.0%)\n\n### SVM_Poly_D2 ###\nMethod: Permutation\n\nTop 13 Features:\n    feature  importance\n     MATS3v         0.0\n       ndNH         0.0\n        JGT         0.0\n      ATS2i         0.0\nCrippenLogP         0.0\n      ATS2s         0.0\n      ATS2p         0.0\n      ATS2v         0.0\n   SHBint10         0.0\n    AATSC4i         0.0\n    AATSC4m         0.0\n    AATSC4c         0.0\n    AATSC4e         0.0\n\nOverlap with original study: 0/13 (0.0%)\n\n### SVM_Poly_D3 ###\nMethod: Permutation\n\nTop 13 Features:\n    feature  importance\n     MATS3v         0.0\n       ndNH         0.0\n        JGT         0.0\n      ATS2i         0.0\nCrippenLogP         0.0\n      ATS2s         0.0\n      ATS2p         0.0\n      ATS2v         0.0\n   SHBint10         0.0\n    AATSC4i         0.0\n    AATSC4m         0.0\n    AATSC4c         0.0\n    AATSC4e         0.0\n\nOverlap with original study: 0/13 (0.0%)\n\n### KNN_K3 ###\nMethod: Permutation\n\nTop 13 Features:\n   feature  importance\n  BCUTp-1l    0.040000\nSpMax1_Bhs    0.031429\n       nsF    0.028571\n    GATS2s    0.028571\n        nF    0.028571\n     minsF    0.028571\n     maxsF    0.028571\n      nssO    0.028571\n    MATS5i    0.028571\n    khs.sF    0.028571\n      SssO    0.028571\n       SsF    0.028571\n   khs.ssO    0.028571\n\nOverlap with original study: 0/13 (0.0%)\n\n### KNN_K5 ###\nMethod: Permutation\n\nTop 13 Features:\n    feature  importance\n       VC-4    0.020000\n     GATS2e    0.005714\n    MDEO-22    0.002857\n    MDEO-12    0.002857\n    nHBint3    0.002857\n       SssO    0.002857\n      C2SP3    0.000000\n      C2SP2    0.000000\n      C2SP1    0.000000\n     GATS2p    0.000000\n      AVP-4    0.000000\n       SssS    0.000000\nETA_Shape_Y    0.000000\n\nOverlap with original study: 0/13 (0.0%)\n\n### KNN_K7 ###\nMethod: Permutation\n\nTop 13 Features:\n        feature  importance\nnTG12HeteroRing    0.002857\nnFG12HeteroRing    0.002857\n        AATSC4i    0.000000\n          ATS2i    0.000000\n    CrippenLogP    0.000000\n          ATS2s    0.000000\n          ATS2p    0.000000\n          ATS2v    0.000000\n       SHBint10    0.000000\n         MATS3v    0.000000\n        SHother    0.000000\n        AATSC4m    0.000000\n        AATSC4c    0.000000\n\nOverlap with original study: 0/13 (0.0%)\n\n### KNN_K10 ###\nMethod: Permutation\n\nTop 13 Features:\n   feature  importance\n      VC-4    0.045714\n      GGI1    0.028571\n        nX    0.028571\nSpMax5_Bhs    0.028571\n      GGI2    0.028571\n      SC-4    0.028571\n     ATS5i    0.028571\n   minaasC    0.028571\n      TIC0    0.028571\n    ATSC8i    0.028571\n  minssssC    0.028571\n    khs.sF    0.028571\n   SM1_Dzi    0.028571\n\nOverlap with original study: 0/13 (0.0%)\n\n### NN_Small ###\nMethod: Permutation\n\nTop 13 Features:\n        feature  importance\n        nHBint3    0.005714\nnTG12HeteroRing    0.005714\n        MDEC-11    0.002857\n           VC-4    0.002857\n        MDEC-14    0.002857\nnFG12HeteroRing    0.002857\n         ATSC0p    0.000000\n      maxssssNp    0.000000\n        AATSC6v    0.000000\n           bpol    0.000000\n            nBr    0.000000\n        AATSC7c    0.000000\n             MW    0.000000\n\nOverlap with original study: 0/13 (0.0%)\n\n### NN_Medium ###\nMethod: Permutation\n\nTop 13 Features:\n       feature  importance\n       nHBint5    0.040000\n       SHBint6    0.037143\n       AATSC6s    0.037143\n       SHBint5    0.025714\n     maxHBint5    0.025714\n       AATSC6e    0.022857\n         minsF    0.022857\n         C1SP2    0.022857\n         maxsF    0.022857\n          JGI4    0.020000\nETA_BetaP_ns_d    0.017143\n ETA_Beta_ns_d    0.014286\n        ATSC1v    0.011429\n\nOverlap with original study: 1/13 (7.7%)\nMatching features: ['C1SP2']\n\n### NN_Large ###\nMethod: Permutation\n\nTop 13 Features:\nfeature  importance\n minsOm    0.025714\nAATSC8v    0.025714\n  maxsF    0.022857\n  minsF    0.022857\n   SaaN    0.020000\n  C1SP2    0.020000\n minHBd    0.020000\nkhs.aaN    0.020000\n ATSC1i    0.020000\n nAtomP    0.020000\nMDEN-33    0.020000\n maxHBd    0.020000\n   naaN    0.020000\n\nOverlap with original study: 1/13 (7.7%)\nMatching features: ['C1SP2']\n\n### NN_Deep ###\nMethod: Permutation\n\nTop 13 Features:\n feature  importance\n  MATS3v         0.0\n   ATS2s         0.0\n   ATS2v         0.0\nSHBint10         0.0\n AATSC4i         0.0\n AATSC4m         0.0\n AATSC4c         0.0\n AATSC4e         0.0\n  SHssNH         0.0\n khs.dsN         0.0\n  maxHBa         0.0\n khs.sBr         0.0\n AATSC4s         0.0\n\nOverlap with original study: 0/13 (0.0%)\n\n### NN_Adam ###\nMethod: Permutation\n\nTop 13 Features:\n      feature  importance\n n7HeteroRing    0.025714\nnT7HeteroRing    0.025714\n      maxaasN    0.020000\n           nH    0.017143\n        naasN    0.017143\n       MATS1v    0.014286\n        ATS8e    0.014286\n        Kier3    0.014286\n      minssNH    0.014286\n       ATSC8p    0.014286\n      AATSC8v    0.014286\n       minaaN    0.014286\n       AATS0v    0.014286\n\nOverlap with original study: 0/13 (0.0%)\n","output_type":"stream"}],"execution_count":13},{"id":"141f02f1-0953-440e-a338-d1cfd3ced58c","cell_type":"code","source":"# Summary comparison table\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY: OVERLAP WITH ORIGINAL STUDY\")\nprint(\"=\"*80)\nsummary_df = pd.DataFrame({\n    'Model': list(feature_comparison.keys()),\n    'Overlap Count': [v['overlap_count'] for v in feature_comparison.values()],\n    'Overlap %': [(v['overlap_count']/13)*100 for v in feature_comparison.values()],\n    'Method': [v['method'] for v in feature_comparison.values()]\n}).sort_values('Overlap Count', ascending=False)\n\nprint(summary_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:47:58.272374Z","iopub.execute_input":"2025-11-03T07:47:58.272737Z","iopub.status.idle":"2025-11-03T07:47:58.285526Z","shell.execute_reply.started":"2025-11-03T07:47:58.272709Z","shell.execute_reply":"2025-11-03T07:47:58.284243Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nSUMMARY: OVERLAP WITH ORIGINAL STUDY\n================================================================================\n                 Model  Overlap Count  Overlap %                    Method\n          AdaBoost_N50              2  15.384615 Built-in (Impurity-based)\n         AdaBoost_N100              1   7.692308 Built-in (Impurity-based)\n              NN_Large              1   7.692308               Permutation\n             NN_Medium              1   7.692308               Permutation\n           SVM_RBF_C10              0   0.000000               Permutation\n  GradientBoosting_N50              0   0.000000 Built-in (Impurity-based)\n GradientBoosting_N100              0   0.000000 Built-in (Impurity-based)\n        XGBoost_D3_N50              0   0.000000 Built-in (Impurity-based)\n       XGBoost_D3_N100              0   0.000000 Built-in (Impurity-based)\n       XGBoost_D5_N100              0   0.000000 Built-in (Impurity-based)\n            SVM_Linear              0   0.000000              Coefficients\n            SVM_RBF_C1              0   0.000000               Permutation\n         LR_No_Penalty              0   0.000000              Coefficients\n           SVM_Poly_D2              0   0.000000               Permutation\n                KNN_K3              0   0.000000               Permutation\n                KNN_K5              0   0.000000               Permutation\n                KNN_K7              0   0.000000               Permutation\n               KNN_K10              0   0.000000               Permutation\n              NN_Small              0   0.000000               Permutation\n               NN_Deep              0   0.000000               Permutation\n           SVM_Poly_D3              0   0.000000               Permutation\n      Extra_Trees_N100              0   0.000000 Built-in (Impurity-based)\n           LR_Ridge_C1              0   0.000000              Coefficients\n                   LDA              0   0.000000              Coefficients\n         LR_Ridge_C0.1              0   0.000000              Coefficients\n          LR_Ridge_C10              0   0.000000              Coefficients\n           LR_Lasso_C1              0   0.000000              Coefficients\n         LR_Lasso_C0.1              0   0.000000              Coefficients\n  LR_ElasticNet_L1_0.5              0   0.000000              Coefficients\n  LR_ElasticNet_L1_0.7              0   0.000000              Coefficients\n      Ridge_Classifier              0   0.000000              Coefficients\n        SGD_Classifier              0   0.000000              Coefficients\n                   QDA              0   0.000000               Permutation\n    Random_Forest_Deep              0   0.000000 Built-in (Impurity-based)\n           Naive_Bayes              0   0.000000               Permutation\n      Decision_Tree_D5              0   0.000000 Built-in (Impurity-based)\n     Decision_Tree_D10              0   0.000000 Built-in (Impurity-based)\n     Decision_Tree_D20              0   0.000000 Built-in (Impurity-based)\nDecision_Tree_Unpruned              0   0.000000 Built-in (Impurity-based)\n     Random_Forest_N50              0   0.000000 Built-in (Impurity-based)\n    Random_Forest_N100              0   0.000000 Built-in (Impurity-based)\n    Random_Forest_N200              0   0.000000 Built-in (Impurity-based)\n               NN_Adam              0   0.000000               Permutation\n","output_type":"stream"}],"execution_count":14},{"id":"aaa8061a-88eb-4883-a323-3947d2edc1c2","cell_type":"code","source":"# Find features commonly selected across multiple models\nprint(\"\\n\" + \"=\"*80)\nprint(\"FEATURES SELECTED BY MULTIPLE MODELS (in top 13)\")\nprint(\"=\"*80)\n\nall_top_features = []\nfor comp in feature_comparison.values():\n    all_top_features.extend(comp['top_13'])\n\nfeature_counts = pd.Series(all_top_features).value_counts()\nfrequent_features = feature_counts[feature_counts >= 3]\n\nif len(frequent_features) > 0:\n    print(f\"\\nFeatures selected by 3+ models:\")\n    for feat, count in frequent_features.items():\n        in_original = \"\" if feat in original_features else \" \"\n        print(f\"  [{in_original}] {feat}: {count}/{len(models)} models\")\nelse:\n    print(\"No features were consistently selected across 3+ models\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:47:58.286734Z","iopub.execute_input":"2025-11-03T07:47:58.287028Z","iopub.status.idle":"2025-11-03T07:47:58.310550Z","shell.execute_reply.started":"2025-11-03T07:47:58.287007Z","shell.execute_reply":"2025-11-03T07:47:58.309298Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nFEATURES SELECTED BY MULTIPLE MODELS (in top 13)\n================================================================================\n\nFeatures selected by 3+ models:\n  [ ] AATSC4m: 14/43 models\n  [ ] SpDiam_Dt: 12/43 models\n  [ ] minssNH: 12/43 models\n  [ ] ALogp2: 10/43 models\n  [ ] maxssNH: 10/43 models\n  [ ] nBase: 9/43 models\n  [ ] minsF: 9/43 models\n  [ ] maxsF: 8/43 models\n  [ ] ATSC3v: 8/43 models\n  [ ] ATS2p: 8/43 models\n  [ ] maxsssCH: 8/43 models\n  [ ] MATS1s: 8/43 models\n  [ ] MATS3v: 7/43 models\n  [ ] ATS2s: 7/43 models\n  [ ] ATS2v: 7/43 models\n  [ ] JGI7: 7/43 models\n  [ ] C3SP3: 7/43 models\n  [ ] AATSC4i: 7/43 models\n  [ ] AATSC4c: 6/43 models\n  [ ] maxHBint4: 6/43 models\n  [ ] SHBint10: 6/43 models\n  [ ] minHCsatu: 6/43 models\n  [ ] minHBint4: 6/43 models\n  [ ] CrippenLogP: 6/43 models\n  [ ] ATS5v: 6/43 models\n  [ ] ATS3m: 5/43 models\n  [ ] SpMax4_Bhm: 5/43 models\n  [ ] MATS5i: 5/43 models\n  [ ] BCUTw-1l: 5/43 models\n  [ ] maxHBint5: 5/43 models\n  [ ] topoShape: 5/43 models\n  [ ] AATSC4e: 5/43 models\n  [ ] ATSC2e: 4/43 models\n  [ ] GATS7m: 4/43 models\n  [ ] MATS6p: 4/43 models\n  [ ] Mi: 4/43 models\n  [] C1SP2: 4/43 models\n  [ ] maxHaaCH: 4/43 models\n  [ ] MATS6i: 4/43 models\n  [ ] GATS3c: 4/43 models\n  [ ] VE2_Dzp: 4/43 models\n  [ ] ATS2i: 4/43 models\n  [ ] JGT: 4/43 models\n  [ ] MATS5p: 4/43 models\n  [ ] maxHBint3: 4/43 models\n  [ ] nHBint3: 4/43 models\n  [ ] SpMin3_Bhe: 4/43 models\n  [ ] AATSC4s: 4/43 models\n  [ ] VC-4: 3/43 models\n  [ ] naAromAtom: 3/43 models\n  [ ] AATS8i: 3/43 models\n  [ ] MWC5: 3/43 models\n  [ ] MLogP: 3/43 models\n  [ ] AATSC6p: 3/43 models\n  [ ] SaasC: 3/43 models\n  [ ] ATSC7p: 3/43 models\n  [ ] ndNH: 3/43 models\n  [ ] SpMax6_Bhv: 3/43 models\n  [ ] ETA_Epsilon_4: 3/43 models\n  [ ] CIC2: 3/43 models\n  [ ] VR1_Dzv: 3/43 models\n  [ ] MDEC-22: 3/43 models\n  [ ] EE_Dt: 3/43 models\n  [ ] MATS7p: 3/43 models\n  [ ] C2SP2: 3/43 models\n  [ ] SpMin8_Bhm: 3/43 models\n  [ ] GATS7v: 3/43 models\n  [ ] maxHCsatu: 3/43 models\n  [ ] minaasC: 3/43 models\n  [ ] PetitjeanNumber: 3/43 models\n","output_type":"stream"}],"execution_count":15},{"id":"43cb9843-b0c3-430b-a2bb-320f332160da","cell_type":"code","source":"# Save detailed comparison\ncomparison_results = []\nfor model_name, comp in feature_comparison.items():\n    for i, feat in enumerate(comp['top_13'], 1):\n        comparison_results.append({\n            'model': model_name,\n            'rank': i,\n            'feature': feat,\n            'in_original_study': feat in original_features\n        })\n\ncomparison_df = pd.DataFrame(comparison_results)\ncomparison_df\n# comparison_df.to_csv('feature_importance_comparison.csv', index=False)\n# print(\"\\n Feature importance saved to 'feature_importance_comparison.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:47:58.311650Z","iopub.execute_input":"2025-11-03T07:47:58.312013Z","iopub.status.idle":"2025-11-03T07:47:58.356060Z","shell.execute_reply.started":"2025-11-03T07:47:58.311990Z","shell.execute_reply":"2025-11-03T07:47:58.354544Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"             model  rank    feature  in_original_study\n0    LR_No_Penalty     1       JGI7              False\n1    LR_No_Penalty     2   maxsssCH              False\n2    LR_No_Penalty     3    nHBint3              False\n3    LR_No_Penalty     4  topoShape              False\n4    LR_No_Penalty     5     ALogp2              False\n..             ...   ...        ...                ...\n554        NN_Adam     9    minssNH              False\n555        NN_Adam    10     ATSC8p              False\n556        NN_Adam    11    AATSC8v              False\n557        NN_Adam    12     minaaN              False\n558        NN_Adam    13     AATS0v              False\n\n[559 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>rank</th>\n      <th>feature</th>\n      <th>in_original_study</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LR_No_Penalty</td>\n      <td>1</td>\n      <td>JGI7</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LR_No_Penalty</td>\n      <td>2</td>\n      <td>maxsssCH</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LR_No_Penalty</td>\n      <td>3</td>\n      <td>nHBint3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LR_No_Penalty</td>\n      <td>4</td>\n      <td>topoShape</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LR_No_Penalty</td>\n      <td>5</td>\n      <td>ALogp2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>554</th>\n      <td>NN_Adam</td>\n      <td>9</td>\n      <td>minssNH</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>NN_Adam</td>\n      <td>10</td>\n      <td>ATSC8p</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>NN_Adam</td>\n      <td>11</td>\n      <td>AATSC8v</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>NN_Adam</td>\n      <td>12</td>\n      <td>minaaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>558</th>\n      <td>NN_Adam</td>\n      <td>13</td>\n      <td>AATS0v</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>559 rows  4 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"id":"9a51f80f-6347-4a51-84fe-19274e0620c3","cell_type":"code","source":"# ===== CLASS WEIGHT COMPARISON =====\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAINING MODELS WITH CLASS WEIGHTS\")\nprint(\"=\"*80)\n\n# Calculate class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nweight_dict = {0: class_weights[0], 1: class_weights[1]}\nprint(f\"\\nComputed class weights: {weight_dict}\")\nprint(f\"Toxic (0): {class_weights[0]:.3f}, NonToxic (1): {class_weights[1]:.3f}\")\n\n# Calculate scale_pos_weight for XGBoost\nn_toxic = np.sum(y_train == 0)\nn_nontoxic = np.sum(y_train == 1)\nscale_pos_weight = n_toxic / n_nontoxic\nprint(f\"XGBoost scale_pos_weight: {scale_pos_weight:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:47:58.357178Z","iopub.execute_input":"2025-11-03T07:47:58.357514Z","iopub.status.idle":"2025-11-03T07:47:58.368066Z","shell.execute_reply.started":"2025-11-03T07:47:58.357489Z","shell.execute_reply":"2025-11-03T07:47:58.366791Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTRAINING MODELS WITH CLASS WEIGHTS\n================================================================================\n\nComputed class weights: {0: 1.511111111111111, 1: 0.7472527472527473}\nToxic (0): 1.511, NonToxic (1): 0.747\nXGBoost scale_pos_weight: 0.495\n","output_type":"stream"}],"execution_count":17},{"id":"58ba5d4b-a1f6-4ad5-9db8-056366ccc92f","cell_type":"code","source":"# Define models WITH class weights\nmodels_weighted = {\n    # === LINEAR MODELS ===\n    'LR_No_Penalty': LogisticRegression(penalty=None, max_iter=2000, solver='lbfgs', class_weight='balanced'),\n    'LR_Ridge_C1': LogisticRegression(penalty='l2', C=1.0, max_iter=2000, solver='lbfgs', class_weight='balanced'),\n    'LR_Ridge_C0.1': LogisticRegression(penalty='l2', C=0.1, max_iter=2000, solver='lbfgs', class_weight='balanced'),\n    'LR_Ridge_C10': LogisticRegression(penalty='l2', C=10.0, max_iter=2000, solver='lbfgs', class_weight='balanced'),\n    'LR_Lasso_C1': LogisticRegression(penalty='l1', C=1.0, max_iter=2000, solver='saga', class_weight='balanced'),\n    'LR_Lasso_C0.1': LogisticRegression(penalty='l1', C=0.1, max_iter=2000, solver='saga', class_weight='balanced'),\n    'LR_ElasticNet_L1_0.5': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, max_iter=2000, class_weight='balanced'),\n    'LR_ElasticNet_L1_0.7': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.7, C=1.0, max_iter=2000, class_weight='balanced'),\n    'Ridge_Classifier': RidgeClassifier(alpha=1.0, class_weight='balanced'),\n    'SGD_Classifier': SGDClassifier(loss='log_loss', max_iter=2000, random_state=42, class_weight='balanced'),\n    \n    # === DISCRIMINANT ANALYSIS ===\n    # LDA and QDA do not support class_weight parameter\n    'LDA': LinearDiscriminantAnalysis(),\n    'QDA': QuadraticDiscriminantAnalysis(),\n    \n    # === NAIVE BAYES ===\n    # GaussianNB does not support class_weight parameter\n    'Naive_Bayes': GaussianNB(),\n    \n    # === TREE-BASED MODELS ===\n    'Decision_Tree_D5': DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced'),\n    'Decision_Tree_D10': DecisionTreeClassifier(max_depth=10, random_state=42, class_weight='balanced'),\n    'Decision_Tree_D20': DecisionTreeClassifier(max_depth=20, random_state=42, class_weight='balanced'),\n    'Decision_Tree_Unpruned': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n    \n    # === ENSEMBLE MODELS - BAGGING ===\n    'Random_Forest_N50': RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, class_weight='balanced'),\n    'Random_Forest_N100': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced'),\n    'Random_Forest_N200': RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, class_weight='balanced'),\n    'Random_Forest_Deep': RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, class_weight='balanced'),\n    'Extra_Trees_N100': ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced'),\n    \n    # === ENSEMBLE MODELS - BOOSTING ===\n    # AdaBoost does not support class_weight parameter directly\n    'AdaBoost_N50': AdaBoostClassifier(n_estimators=50, random_state=42, algorithm='SAMME'),\n    'AdaBoost_N100': AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME'),\n    # GradientBoosting does not support class_weight parameter directly\n    'GradientBoosting_N50': GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42),\n    'GradientBoosting_N100': GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42),\n    # XGBoost uses scale_pos_weight instead of class_weight\n    'XGBoost_D3_N50': XGBClassifier(max_depth=3, n_estimators=50, scale_pos_weight=scale_pos_weight, random_state=42, eval_metric='logloss', use_label_encoder=False),\n    'XGBoost_D3_N100': XGBClassifier(max_depth=3, n_estimators=100, scale_pos_weight=scale_pos_weight, random_state=42, eval_metric='logloss', use_label_encoder=False),\n    'XGBoost_D5_N100': XGBClassifier(max_depth=5, n_estimators=100, scale_pos_weight=scale_pos_weight, random_state=42, eval_metric='logloss', use_label_encoder=False),\n    \n    # === SVM VARIATIONS ===\n    'SVM_Linear': SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced'),\n    'SVM_RBF_C1': SVC(kernel='rbf', C=1.0, probability=True, random_state=42, class_weight='balanced'),\n    'SVM_RBF_C10': SVC(kernel='rbf', C=10.0, probability=True, random_state=42, class_weight='balanced'),\n    'SVM_Poly_D2': SVC(kernel='poly', degree=2, probability=True, random_state=42, class_weight='balanced'),\n    'SVM_Poly_D3': SVC(kernel='poly', degree=3, probability=True, random_state=42, class_weight='balanced'),\n    \n    # === K-NEAREST NEIGHBORS ===\n    # KNN does not support class_weight parameter\n    'KNN_K3': KNeighborsClassifier(n_neighbors=3),\n    'KNN_K5': KNeighborsClassifier(n_neighbors=5),\n    'KNN_K7': KNeighborsClassifier(n_neighbors=7),\n    'KNN_K10': KNeighborsClassifier(n_neighbors=10),\n    \n    # === NEURAL NETWORKS ===\n    # MLPClassifier does not support class_weight parameter\n    'NN_Small': MLPClassifier(hidden_layer_sizes=(25,), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Medium': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Large': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Deep': MLPClassifier(hidden_layer_sizes=(100, 50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='lbfgs'),\n    'NN_Adam': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42, early_stopping=True, solver='adam'),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:47:58.369198Z","iopub.execute_input":"2025-11-03T07:47:58.369500Z","iopub.status.idle":"2025-11-03T07:47:58.392156Z","shell.execute_reply.started":"2025-11-03T07:47:58.369479Z","shell.execute_reply":"2025-11-03T07:47:58.390811Z"}},"outputs":[],"execution_count":18},{"id":"5d7d5474-b532-4962-9c16-c8d2c5125b59","cell_type":"code","source":"# Train weighted models\nresults_weighted = []\nfor name, model in models_weighted.items():\n    print(f\"Training {name} (weighted)...\")\n    metrics = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n    metrics['model'] = name\n    results_weighted.append(metrics)\n    print(f\"  Test Accuracy: {metrics['test_acc']:.4f}, Test AUC: {metrics['test_auc']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:47:58.393592Z","iopub.execute_input":"2025-11-03T07:47:58.393960Z","iopub.status.idle":"2025-11-03T07:48:37.963721Z","shell.execute_reply.started":"2025-11-03T07:47:58.393927Z","shell.execute_reply":"2025-11-03T07:48:37.962502Z"}},"outputs":[{"name":"stdout","text":"Training LR_No_Penalty (weighted)...\n  Test Accuracy: 0.6000, Test AUC: 0.5682\nTraining LR_Ridge_C1 (weighted)...\n  Test Accuracy: 0.5714, Test AUC: 0.5644\nTraining LR_Ridge_C0.1 (weighted)...\n  Test Accuracy: 0.5714, Test AUC: 0.5758\nTraining LR_Ridge_C10 (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.5606\nTraining LR_Lasso_C1 (weighted)...\n  Test Accuracy: 0.6000, Test AUC: 0.5417\nTraining LR_Lasso_C0.1 (weighted)...\n  Test Accuracy: 0.5143, Test AUC: 0.5492\nTraining LR_ElasticNet_L1_0.5 (weighted)...\n  Test Accuracy: 0.5714, Test AUC: 0.5455\nTraining LR_ElasticNet_L1_0.7 (weighted)...\n  Test Accuracy: 0.6000, Test AUC: 0.5417\nTraining Ridge_Classifier (weighted)...\n  Test Accuracy: 0.4857, Test AUC: 0.5530\nTraining SGD_Classifier (weighted)...\n  Test Accuracy: 0.5714, Test AUC: 0.4962\nTraining LDA (weighted)...\n  Test Accuracy: 0.6000, Test AUC: 0.5473\nTraining QDA (weighted)...\n  Test Accuracy: 0.5143, Test AUC: 0.4981\nTraining Naive_Bayes (weighted)...\n  Test Accuracy: 0.4286, Test AUC: 0.5076\nTraining Decision_Tree_D5 (weighted)...\n  Test Accuracy: 0.5714, Test AUC: 0.6042\nTraining Decision_Tree_D10 (weighted)...\n  Test Accuracy: 0.5143, Test AUC: 0.4735\nTraining Decision_Tree_D20 (weighted)...\n  Test Accuracy: 0.5143, Test AUC: 0.4735\nTraining Decision_Tree_Unpruned (weighted)...\n  Test Accuracy: 0.5143, Test AUC: 0.4735\nTraining Random_Forest_N50 (weighted)...\n  Test Accuracy: 0.6286, Test AUC: 0.6572\nTraining Random_Forest_N100 (weighted)...\n  Test Accuracy: 0.6857, Test AUC: 0.6780\nTraining Random_Forest_N200 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.6553\nTraining Random_Forest_Deep (weighted)...\n  Test Accuracy: 0.6857, Test AUC: 0.6818\nTraining Extra_Trees_N100 (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.6402\nTraining AdaBoost_N50 (weighted)...\n  Test Accuracy: 0.6286, Test AUC: 0.6364\nTraining AdaBoost_N100 (weighted)...\n  Test Accuracy: 0.6286, Test AUC: 0.5985\nTraining GradientBoosting_N50 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.6856\nTraining GradientBoosting_N100 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.6250\nTraining XGBoost_D3_N50 (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.5455\nTraining XGBoost_D3_N100 (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.5303\nTraining XGBoost_D5_N100 (weighted)...\n  Test Accuracy: 0.4571, Test AUC: 0.5038\nTraining SVM_Linear (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.4432\nTraining SVM_RBF_C1 (weighted)...\n  Test Accuracy: 0.5143, Test AUC: 0.3826\nTraining SVM_RBF_C10 (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.3939\nTraining SVM_Poly_D2 (weighted)...\n  Test Accuracy: 0.4857, Test AUC: 0.3485\nTraining SVM_Poly_D3 (weighted)...\n  Test Accuracy: 0.4286, Test AUC: 0.3674\nTraining KNN_K3 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.6951\nTraining KNN_K5 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.7027\nTraining KNN_K7 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.6667\nTraining KNN_K10 (weighted)...\n  Test Accuracy: 0.6571, Test AUC: 0.6553\nTraining NN_Small (weighted)...\n  Test Accuracy: 0.6000, Test AUC: 0.6496\nTraining NN_Medium (weighted)...\n  Test Accuracy: 0.6286, Test AUC: 0.5360\nTraining NN_Large (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.5492\nTraining NN_Deep (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.5625\nTraining NN_Adam (weighted)...\n  Test Accuracy: 0.5429, Test AUC: 0.4962\n","output_type":"stream"}],"execution_count":19},{"id":"c3f78025-1ad3-47af-9349-54a99773abf5","cell_type":"code","source":"# Create comparison DataFrames\nresults_df_weighted = pd.DataFrame(results_weighted)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:48:37.964932Z","iopub.execute_input":"2025-11-03T07:48:37.965971Z","iopub.status.idle":"2025-11-03T07:48:37.971279Z","shell.execute_reply.started":"2025-11-03T07:48:37.965942Z","shell.execute_reply":"2025-11-03T07:48:37.970214Z"}},"outputs":[],"execution_count":20},{"id":"013587d2-070e-476f-a7b5-39eaa2213f9a","cell_type":"code","source":"# Merge for side-by-side comparison\ncomparison = pd.merge(\n    results_df[['model', 'test_acc', 'precision', 'recall', 'f1']],\n    results_df_weighted[['model', 'test_acc', 'precision', 'recall', 'f1']],\n    on='model',\n    suffixes=('_original', '_weighted')\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:48:37.972257Z","iopub.execute_input":"2025-11-03T07:48:37.972602Z","iopub.status.idle":"2025-11-03T07:48:37.998383Z","shell.execute_reply.started":"2025-11-03T07:48:37.972574Z","shell.execute_reply":"2025-11-03T07:48:37.997194Z"}},"outputs":[],"execution_count":21},{"id":"f30b8512-adf6-4ab3-9de4-977f0c01e8fb","cell_type":"code","source":"# Calculate improvements\ncomparison['acc_change'] = comparison['test_acc_weighted'] - comparison['test_acc_original']\ncomparison['recall_change'] = comparison['recall_weighted'] - comparison['recall_original']\ncomparison['f1_change'] = comparison['f1_weighted'] - comparison['f1_original']\ncomparison","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:48:37.999343Z","iopub.execute_input":"2025-11-03T07:48:37.999608Z","iopub.status.idle":"2025-11-03T07:48:38.047605Z","shell.execute_reply.started":"2025-11-03T07:48:37.999587Z","shell.execute_reply":"2025-11-03T07:48:38.046362Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                     model  test_acc_original  precision_original  \\\n0              SVM_Poly_D2           0.685714            0.685714   \n1               SVM_RBF_C1           0.685714            0.685714   \n2            LR_Lasso_C0.1           0.685714            0.685714   \n3              SVM_Poly_D3           0.685714            0.685714   \n4        Random_Forest_N50           0.657143            0.714286   \n5                   KNN_K3           0.657143            0.750000   \n6                   KNN_K5           0.657143            0.714286   \n7                   KNN_K7           0.657143            0.714286   \n8                  KNN_K10           0.657143            0.730769   \n9     GradientBoosting_N50           0.657143            0.730769   \n10   GradientBoosting_N100           0.657143            0.730769   \n11         XGBoost_D3_N100           0.657143            0.714286   \n12            AdaBoost_N50           0.628571            0.720000   \n13           AdaBoost_N100           0.628571            0.720000   \n14      Random_Forest_Deep           0.628571            0.703704   \n15      Random_Forest_N200           0.628571            0.703704   \n16      Random_Forest_N100           0.628571            0.703704   \n17        Extra_Trees_N100           0.628571            0.703704   \n18        Decision_Tree_D5           0.628571            0.761905   \n19               NN_Medium           0.628571            0.739130   \n20  Decision_Tree_Unpruned           0.600000            0.750000   \n21       Decision_Tree_D20           0.600000            0.750000   \n22                     LDA           0.600000            0.750000   \n23    LR_ElasticNet_L1_0.7           0.600000            0.708333   \n24    LR_ElasticNet_L1_0.5           0.600000            0.708333   \n25             LR_Lasso_C1           0.600000            0.708333   \n26                NN_Small           0.600000            0.708333   \n27          XGBoost_D3_N50           0.600000            0.692308   \n28       Decision_Tree_D10           0.600000            0.750000   \n29           LR_No_Penalty           0.571429            0.714286   \n30         XGBoost_D5_N100           0.571429            0.666667   \n31             LR_Ridge_C1           0.571429            0.695652   \n32          SGD_Classifier           0.571429            0.680000   \n33            LR_Ridge_C10           0.571429            0.695652   \n34           LR_Ridge_C0.1           0.571429            0.680000   \n35              SVM_Linear           0.542857            0.666667   \n36                NN_Large           0.542857            0.653846   \n37                 NN_Deep           0.542857            0.666667   \n38                 NN_Adam           0.542857            0.681818   \n39                     QDA           0.514286            0.684211   \n40        Ridge_Classifier           0.514286            0.684211   \n41             SVM_RBF_C10           0.485714            0.625000   \n42             Naive_Bayes           0.428571            0.750000   \n\n    recall_original  f1_original  test_acc_weighted  precision_weighted  \\\n0          1.000000     0.813559           0.485714            0.750000   \n1          1.000000     0.813559           0.514286            0.733333   \n2          1.000000     0.813559           0.514286            0.684211   \n3          1.000000     0.813559           0.428571            1.000000   \n4          0.833333     0.769231           0.628571            0.689655   \n5          0.750000     0.750000           0.657143            0.750000   \n6          0.833333     0.769231           0.657143            0.714286   \n7          0.833333     0.769231           0.657143            0.714286   \n8          0.791667     0.760000           0.657143            0.730769   \n9          0.791667     0.760000           0.657143            0.730769   \n10         0.791667     0.760000           0.657143            0.730769   \n11         0.833333     0.769231           0.542857            0.642857   \n12         0.750000     0.734694           0.628571            0.720000   \n13         0.750000     0.734694           0.628571            0.720000   \n14         0.791667     0.745098           0.685714            0.724138   \n15         0.791667     0.745098           0.657143            0.700000   \n16         0.791667     0.745098           0.685714            0.724138   \n17         0.791667     0.745098           0.542857            0.666667   \n18         0.666667     0.711111           0.571429            0.714286   \n19         0.708333     0.723404           0.628571            0.739130   \n20         0.625000     0.681818           0.514286            0.666667   \n21         0.625000     0.681818           0.514286            0.666667   \n22         0.625000     0.681818           0.600000            0.750000   \n23         0.708333     0.708333           0.600000            0.708333   \n24         0.708333     0.708333           0.571429            0.695652   \n25         0.708333     0.708333           0.600000            0.708333   \n26         0.708333     0.708333           0.600000            0.708333   \n27         0.750000     0.720000           0.542857            0.642857   \n28         0.625000     0.681818           0.514286            0.666667   \n29         0.625000     0.666667           0.600000            0.750000   \n30         0.750000     0.705882           0.457143            0.600000   \n31         0.666667     0.680851           0.571429            0.695652   \n32         0.708333     0.693878           0.571429            0.714286   \n33         0.666667     0.680851           0.542857            0.681818   \n34         0.708333     0.693878           0.571429            0.680000   \n35         0.666667     0.666667           0.542857            0.666667   \n36         0.708333     0.680000           0.542857            0.653846   \n37         0.666667     0.666667           0.542857            0.666667   \n38         0.625000     0.652174           0.542857            0.681818   \n39         0.541667     0.604651           0.514286            0.684211   \n40         0.541667     0.604651           0.485714            0.650000   \n41         0.625000     0.625000           0.542857            0.681818   \n42         0.250000     0.375000           0.428571            0.750000   \n\n    recall_weighted  f1_weighted  acc_change  recall_change  f1_change  \n0          0.375000     0.500000   -0.200000      -0.625000  -0.313559  \n1          0.458333     0.564103   -0.171429      -0.541667  -0.249457  \n2          0.541667     0.604651   -0.171429      -0.458333  -0.208908  \n3          0.166667     0.285714   -0.257143      -0.833333  -0.527845  \n4          0.833333     0.754717   -0.028571       0.000000  -0.014514  \n5          0.750000     0.750000    0.000000       0.000000   0.000000  \n6          0.833333     0.769231    0.000000       0.000000   0.000000  \n7          0.833333     0.769231    0.000000       0.000000   0.000000  \n8          0.791667     0.760000    0.000000       0.000000   0.000000  \n9          0.791667     0.760000    0.000000       0.000000   0.000000  \n10         0.791667     0.760000    0.000000       0.000000   0.000000  \n11         0.750000     0.692308   -0.114286      -0.083333  -0.076923  \n12         0.750000     0.734694    0.000000       0.000000   0.000000  \n13         0.750000     0.734694    0.000000       0.000000   0.000000  \n14         0.875000     0.792453    0.057143       0.083333   0.047355  \n15         0.875000     0.777778    0.028571       0.083333   0.032680  \n16         0.875000     0.792453    0.057143       0.083333   0.047355  \n17         0.666667     0.666667   -0.085714      -0.125000  -0.078431  \n18         0.625000     0.666667   -0.057143      -0.041667  -0.044444  \n19         0.708333     0.723404    0.000000       0.000000   0.000000  \n20         0.583333     0.622222   -0.085714      -0.041667  -0.059596  \n21         0.583333     0.622222   -0.085714      -0.041667  -0.059596  \n22         0.625000     0.681818    0.000000       0.000000   0.000000  \n23         0.708333     0.708333    0.000000       0.000000   0.000000  \n24         0.666667     0.680851   -0.028571      -0.041667  -0.027482  \n25         0.708333     0.708333    0.000000       0.000000   0.000000  \n26         0.708333     0.708333    0.000000       0.000000   0.000000  \n27         0.750000     0.692308   -0.057143       0.000000  -0.027692  \n28         0.583333     0.622222   -0.085714      -0.041667  -0.059596  \n29         0.625000     0.681818    0.028571       0.000000   0.015152  \n30         0.625000     0.612245   -0.114286      -0.125000  -0.093637  \n31         0.666667     0.680851    0.000000       0.000000   0.000000  \n32         0.625000     0.666667    0.000000      -0.083333  -0.027211  \n33         0.625000     0.652174   -0.028571      -0.041667  -0.028677  \n34         0.708333     0.693878    0.000000       0.000000   0.000000  \n35         0.666667     0.666667    0.000000       0.000000   0.000000  \n36         0.708333     0.680000    0.000000       0.000000   0.000000  \n37         0.666667     0.666667    0.000000       0.000000   0.000000  \n38         0.625000     0.652174    0.000000       0.000000   0.000000  \n39         0.541667     0.604651    0.000000       0.000000   0.000000  \n40         0.541667     0.590909   -0.028571       0.000000  -0.013742  \n41         0.625000     0.652174    0.057143       0.000000   0.027174  \n42         0.250000     0.375000    0.000000       0.000000   0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>test_acc_original</th>\n      <th>precision_original</th>\n      <th>recall_original</th>\n      <th>f1_original</th>\n      <th>test_acc_weighted</th>\n      <th>precision_weighted</th>\n      <th>recall_weighted</th>\n      <th>f1_weighted</th>\n      <th>acc_change</th>\n      <th>recall_change</th>\n      <th>f1_change</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVM_Poly_D2</td>\n      <td>0.685714</td>\n      <td>0.685714</td>\n      <td>1.000000</td>\n      <td>0.813559</td>\n      <td>0.485714</td>\n      <td>0.750000</td>\n      <td>0.375000</td>\n      <td>0.500000</td>\n      <td>-0.200000</td>\n      <td>-0.625000</td>\n      <td>-0.313559</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVM_RBF_C1</td>\n      <td>0.685714</td>\n      <td>0.685714</td>\n      <td>1.000000</td>\n      <td>0.813559</td>\n      <td>0.514286</td>\n      <td>0.733333</td>\n      <td>0.458333</td>\n      <td>0.564103</td>\n      <td>-0.171429</td>\n      <td>-0.541667</td>\n      <td>-0.249457</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LR_Lasso_C0.1</td>\n      <td>0.685714</td>\n      <td>0.685714</td>\n      <td>1.000000</td>\n      <td>0.813559</td>\n      <td>0.514286</td>\n      <td>0.684211</td>\n      <td>0.541667</td>\n      <td>0.604651</td>\n      <td>-0.171429</td>\n      <td>-0.458333</td>\n      <td>-0.208908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVM_Poly_D3</td>\n      <td>0.685714</td>\n      <td>0.685714</td>\n      <td>1.000000</td>\n      <td>0.813559</td>\n      <td>0.428571</td>\n      <td>1.000000</td>\n      <td>0.166667</td>\n      <td>0.285714</td>\n      <td>-0.257143</td>\n      <td>-0.833333</td>\n      <td>-0.527845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random_Forest_N50</td>\n      <td>0.657143</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.769231</td>\n      <td>0.628571</td>\n      <td>0.689655</td>\n      <td>0.833333</td>\n      <td>0.754717</td>\n      <td>-0.028571</td>\n      <td>0.000000</td>\n      <td>-0.014514</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNN_K3</td>\n      <td>0.657143</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.657143</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNN_K5</td>\n      <td>0.657143</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.769231</td>\n      <td>0.657143</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNN_K7</td>\n      <td>0.657143</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.769231</td>\n      <td>0.657143</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNN_K10</td>\n      <td>0.657143</td>\n      <td>0.730769</td>\n      <td>0.791667</td>\n      <td>0.760000</td>\n      <td>0.657143</td>\n      <td>0.730769</td>\n      <td>0.791667</td>\n      <td>0.760000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GradientBoosting_N50</td>\n      <td>0.657143</td>\n      <td>0.730769</td>\n      <td>0.791667</td>\n      <td>0.760000</td>\n      <td>0.657143</td>\n      <td>0.730769</td>\n      <td>0.791667</td>\n      <td>0.760000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>GradientBoosting_N100</td>\n      <td>0.657143</td>\n      <td>0.730769</td>\n      <td>0.791667</td>\n      <td>0.760000</td>\n      <td>0.657143</td>\n      <td>0.730769</td>\n      <td>0.791667</td>\n      <td>0.760000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>XGBoost_D3_N100</td>\n      <td>0.657143</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.769231</td>\n      <td>0.542857</td>\n      <td>0.642857</td>\n      <td>0.750000</td>\n      <td>0.692308</td>\n      <td>-0.114286</td>\n      <td>-0.083333</td>\n      <td>-0.076923</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>AdaBoost_N50</td>\n      <td>0.628571</td>\n      <td>0.720000</td>\n      <td>0.750000</td>\n      <td>0.734694</td>\n      <td>0.628571</td>\n      <td>0.720000</td>\n      <td>0.750000</td>\n      <td>0.734694</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AdaBoost_N100</td>\n      <td>0.628571</td>\n      <td>0.720000</td>\n      <td>0.750000</td>\n      <td>0.734694</td>\n      <td>0.628571</td>\n      <td>0.720000</td>\n      <td>0.750000</td>\n      <td>0.734694</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random_Forest_Deep</td>\n      <td>0.628571</td>\n      <td>0.703704</td>\n      <td>0.791667</td>\n      <td>0.745098</td>\n      <td>0.685714</td>\n      <td>0.724138</td>\n      <td>0.875000</td>\n      <td>0.792453</td>\n      <td>0.057143</td>\n      <td>0.083333</td>\n      <td>0.047355</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random_Forest_N200</td>\n      <td>0.628571</td>\n      <td>0.703704</td>\n      <td>0.791667</td>\n      <td>0.745098</td>\n      <td>0.657143</td>\n      <td>0.700000</td>\n      <td>0.875000</td>\n      <td>0.777778</td>\n      <td>0.028571</td>\n      <td>0.083333</td>\n      <td>0.032680</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Random_Forest_N100</td>\n      <td>0.628571</td>\n      <td>0.703704</td>\n      <td>0.791667</td>\n      <td>0.745098</td>\n      <td>0.685714</td>\n      <td>0.724138</td>\n      <td>0.875000</td>\n      <td>0.792453</td>\n      <td>0.057143</td>\n      <td>0.083333</td>\n      <td>0.047355</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Extra_Trees_N100</td>\n      <td>0.628571</td>\n      <td>0.703704</td>\n      <td>0.791667</td>\n      <td>0.745098</td>\n      <td>0.542857</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>-0.085714</td>\n      <td>-0.125000</td>\n      <td>-0.078431</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Decision_Tree_D5</td>\n      <td>0.628571</td>\n      <td>0.761905</td>\n      <td>0.666667</td>\n      <td>0.711111</td>\n      <td>0.571429</td>\n      <td>0.714286</td>\n      <td>0.625000</td>\n      <td>0.666667</td>\n      <td>-0.057143</td>\n      <td>-0.041667</td>\n      <td>-0.044444</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NN_Medium</td>\n      <td>0.628571</td>\n      <td>0.739130</td>\n      <td>0.708333</td>\n      <td>0.723404</td>\n      <td>0.628571</td>\n      <td>0.739130</td>\n      <td>0.708333</td>\n      <td>0.723404</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Decision_Tree_Unpruned</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.625000</td>\n      <td>0.681818</td>\n      <td>0.514286</td>\n      <td>0.666667</td>\n      <td>0.583333</td>\n      <td>0.622222</td>\n      <td>-0.085714</td>\n      <td>-0.041667</td>\n      <td>-0.059596</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Decision_Tree_D20</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.625000</td>\n      <td>0.681818</td>\n      <td>0.514286</td>\n      <td>0.666667</td>\n      <td>0.583333</td>\n      <td>0.622222</td>\n      <td>-0.085714</td>\n      <td>-0.041667</td>\n      <td>-0.059596</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LDA</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.625000</td>\n      <td>0.681818</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.625000</td>\n      <td>0.681818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>LR_ElasticNet_L1_0.7</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>LR_ElasticNet_L1_0.5</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.571429</td>\n      <td>0.695652</td>\n      <td>0.666667</td>\n      <td>0.680851</td>\n      <td>-0.028571</td>\n      <td>-0.041667</td>\n      <td>-0.027482</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>LR_Lasso_C1</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NN_Small</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.600000</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.708333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>XGBoost_D3_N50</td>\n      <td>0.600000</td>\n      <td>0.692308</td>\n      <td>0.750000</td>\n      <td>0.720000</td>\n      <td>0.542857</td>\n      <td>0.642857</td>\n      <td>0.750000</td>\n      <td>0.692308</td>\n      <td>-0.057143</td>\n      <td>0.000000</td>\n      <td>-0.027692</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Decision_Tree_D10</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.625000</td>\n      <td>0.681818</td>\n      <td>0.514286</td>\n      <td>0.666667</td>\n      <td>0.583333</td>\n      <td>0.622222</td>\n      <td>-0.085714</td>\n      <td>-0.041667</td>\n      <td>-0.059596</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LR_No_Penalty</td>\n      <td>0.571429</td>\n      <td>0.714286</td>\n      <td>0.625000</td>\n      <td>0.666667</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.625000</td>\n      <td>0.681818</td>\n      <td>0.028571</td>\n      <td>0.000000</td>\n      <td>0.015152</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>XGBoost_D5_N100</td>\n      <td>0.571429</td>\n      <td>0.666667</td>\n      <td>0.750000</td>\n      <td>0.705882</td>\n      <td>0.457143</td>\n      <td>0.600000</td>\n      <td>0.625000</td>\n      <td>0.612245</td>\n      <td>-0.114286</td>\n      <td>-0.125000</td>\n      <td>-0.093637</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>LR_Ridge_C1</td>\n      <td>0.571429</td>\n      <td>0.695652</td>\n      <td>0.666667</td>\n      <td>0.680851</td>\n      <td>0.571429</td>\n      <td>0.695652</td>\n      <td>0.666667</td>\n      <td>0.680851</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>SGD_Classifier</td>\n      <td>0.571429</td>\n      <td>0.680000</td>\n      <td>0.708333</td>\n      <td>0.693878</td>\n      <td>0.571429</td>\n      <td>0.714286</td>\n      <td>0.625000</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>-0.083333</td>\n      <td>-0.027211</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>LR_Ridge_C10</td>\n      <td>0.571429</td>\n      <td>0.695652</td>\n      <td>0.666667</td>\n      <td>0.680851</td>\n      <td>0.542857</td>\n      <td>0.681818</td>\n      <td>0.625000</td>\n      <td>0.652174</td>\n      <td>-0.028571</td>\n      <td>-0.041667</td>\n      <td>-0.028677</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>LR_Ridge_C0.1</td>\n      <td>0.571429</td>\n      <td>0.680000</td>\n      <td>0.708333</td>\n      <td>0.693878</td>\n      <td>0.571429</td>\n      <td>0.680000</td>\n      <td>0.708333</td>\n      <td>0.693878</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SVM_Linear</td>\n      <td>0.542857</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.542857</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>NN_Large</td>\n      <td>0.542857</td>\n      <td>0.653846</td>\n      <td>0.708333</td>\n      <td>0.680000</td>\n      <td>0.542857</td>\n      <td>0.653846</td>\n      <td>0.708333</td>\n      <td>0.680000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>NN_Deep</td>\n      <td>0.542857</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.542857</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>NN_Adam</td>\n      <td>0.542857</td>\n      <td>0.681818</td>\n      <td>0.625000</td>\n      <td>0.652174</td>\n      <td>0.542857</td>\n      <td>0.681818</td>\n      <td>0.625000</td>\n      <td>0.652174</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>QDA</td>\n      <td>0.514286</td>\n      <td>0.684211</td>\n      <td>0.541667</td>\n      <td>0.604651</td>\n      <td>0.514286</td>\n      <td>0.684211</td>\n      <td>0.541667</td>\n      <td>0.604651</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Ridge_Classifier</td>\n      <td>0.514286</td>\n      <td>0.684211</td>\n      <td>0.541667</td>\n      <td>0.604651</td>\n      <td>0.485714</td>\n      <td>0.650000</td>\n      <td>0.541667</td>\n      <td>0.590909</td>\n      <td>-0.028571</td>\n      <td>0.000000</td>\n      <td>-0.013742</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>SVM_RBF_C10</td>\n      <td>0.485714</td>\n      <td>0.625000</td>\n      <td>0.625000</td>\n      <td>0.625000</td>\n      <td>0.542857</td>\n      <td>0.681818</td>\n      <td>0.625000</td>\n      <td>0.652174</td>\n      <td>0.057143</td>\n      <td>0.000000</td>\n      <td>0.027174</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Naive_Bayes</td>\n      <td>0.428571</td>\n      <td>0.750000</td>\n      <td>0.250000</td>\n      <td>0.375000</td>\n      <td>0.428571</td>\n      <td>0.750000</td>\n      <td>0.250000</td>\n      <td>0.375000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"id":"9582998c-0ac3-41ad-a713-5a8554aff733","cell_type":"code","source":"# Detailed confusion matrix comparison\nprint(\"\\n\" + \"=\"*100)\nprint(\"CONFUSION MATRIX COMPARISON (Original vs Weighted)\")\nprint(\"=\"*100)\n\nfor name, model_original in models.items():\n    model_weighted = models_weighted[name]\n    \n    # Get predictions\n    y_pred_original = model_original.predict(X_test_scaled)\n    y_pred_weighted = model_weighted.predict(X_test_scaled)\n    \n    # Confusion matrices\n    cm_original = confusion_matrix(y_test, y_pred_original)\n    cm_weighted = confusion_matrix(y_test, y_pred_weighted)\n    \n    print(f\"\\n### {name} ###\")\n    print(\"\\nOriginal (No Class Weights):\")\n    print(f\"                Predicted Toxic    Predicted NonToxic\")\n    print(f\"Actual Toxic          {cm_original[0,0]:3d}                 {cm_original[0,1]:3d}\")\n    print(f\"Actual NonToxic       {cm_original[1,0]:3d}                 {cm_original[1,1]:3d}\")\n    \n    print(\"\\nWith Class Weights:\")\n    print(f\"                Predicted Toxic    Predicted NonToxic\")\n    print(f\"Actual Toxic          {cm_weighted[0,0]:3d}                 {cm_weighted[0,1]:3d}\")\n    print(f\"Actual NonToxic       {cm_weighted[1,0]:3d}                 {cm_weighted[1,1]:3d}\")\n    \n    # Calculate recall for minority class\n    recall_toxic_orig = cm_original[0,0] / (cm_original[0,0] + cm_original[0,1]) if (cm_original[0,0] + cm_original[0,1]) > 0 else 0\n    recall_toxic_weighted = cm_weighted[0,0] / (cm_weighted[0,0] + cm_weighted[0,1]) if (cm_weighted[0,0] + cm_weighted[0,1]) > 0 else 0\n    \n    print(f\"\\nRecall for Toxic class: {recall_toxic_orig:.3f}  {recall_toxic_weighted:.3f} (={recall_toxic_weighted-recall_toxic_orig:+.3f})\")\n    \n    # False negatives\n    fn_orig = cm_original[0,1]\n    fn_weighted = cm_weighted[0,1]\n    print(f\"False Negatives (Toxic  NonToxic): {fn_orig}  {fn_weighted} (={fn_weighted-fn_orig:+d})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:48:38.048444Z","iopub.execute_input":"2025-11-03T07:48:38.048780Z","iopub.status.idle":"2025-11-03T07:48:38.350521Z","shell.execute_reply.started":"2025-11-03T07:48:38.048756Z","shell.execute_reply":"2025-11-03T07:48:38.349093Z"}},"outputs":[{"name":"stdout","text":"\n====================================================================================================\nCONFUSION MATRIX COMPARISON (Original vs Weighted)\n====================================================================================================\n\n### LR_No_Penalty ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.455  0.545 (=+0.091)\nFalse Negatives (Toxic  NonToxic): 6  5 (=-1)\n\n### LR_Ridge_C1 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         8                  16\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         8                  16\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### LR_Ridge_C0.1 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         7                  17\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### LR_Ridge_C10 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         8                  16\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### LR_Lasso_C1 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### LR_Lasso_C0.1 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            0                  11\nActual NonToxic         0                  24\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic        11                  13\n\nRecall for Toxic class: 0.000  0.455 (=+0.455)\nFalse Negatives (Toxic  NonToxic): 11  6 (=-5)\n\n### LR_ElasticNet_L1_0.5 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         8                  16\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### LR_ElasticNet_L1_0.7 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### Ridge_Classifier ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic        11                  13\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic        11                  13\n\nRecall for Toxic class: 0.455  0.364 (=-0.091)\nFalse Negatives (Toxic  NonToxic): 6  7 (=+1)\n\n### SGD_Classifier ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.273  0.455 (=+0.182)\nFalse Negatives (Toxic  NonToxic): 8  6 (=-2)\n\n### LDA ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.545  0.545 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 5  5 (=+0)\n\n### QDA ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic        11                  13\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic        11                  13\n\nRecall for Toxic class: 0.455  0.455 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 6  6 (=+0)\n\n### Naive_Bayes ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            9                   2\nActual NonToxic        18                   6\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            9                   2\nActual NonToxic        18                   6\n\nRecall for Toxic class: 0.818  0.818 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 2  2 (=+0)\n\n### Decision_Tree_D5 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         8                  16\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.545  0.455 (=-0.091)\nFalse Negatives (Toxic  NonToxic): 5  6 (=+1)\n\n### Decision_Tree_D10 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic        10                  14\n\nRecall for Toxic class: 0.545  0.364 (=-0.182)\nFalse Negatives (Toxic  NonToxic): 5  7 (=+2)\n\n### Decision_Tree_D20 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic        10                  14\n\nRecall for Toxic class: 0.545  0.364 (=-0.182)\nFalse Negatives (Toxic  NonToxic): 5  7 (=+2)\n\n### Decision_Tree_Unpruned ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            6                   5\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic        10                  14\n\nRecall for Toxic class: 0.545  0.364 (=-0.182)\nFalse Negatives (Toxic  NonToxic): 5  7 (=+2)\n\n### Random_Forest_N50 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         4                  20\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            2                   9\nActual NonToxic         4                  20\n\nRecall for Toxic class: 0.273  0.182 (=-0.091)\nFalse Negatives (Toxic  NonToxic): 8  9 (=+1)\n\n### Random_Forest_N100 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         3                  21\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### Random_Forest_N200 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            2                   9\nActual NonToxic         3                  21\n\nRecall for Toxic class: 0.273  0.182 (=-0.091)\nFalse Negatives (Toxic  NonToxic): 8  9 (=+1)\n\n### Random_Forest_Deep ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         3                  21\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### Extra_Trees_N100 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         8                  16\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### AdaBoost_N50 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         6                  18\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         6                  18\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### AdaBoost_N100 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         6                  18\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         6                  18\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### GradientBoosting_N50 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         5                  19\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### GradientBoosting_N100 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         5                  19\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### XGBoost_D3_N50 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         6                  18\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            1                  10\nActual NonToxic         6                  18\n\nRecall for Toxic class: 0.273  0.091 (=-0.182)\nFalse Negatives (Toxic  NonToxic): 8  10 (=+2)\n\n### XGBoost_D3_N100 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         4                  20\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            1                  10\nActual NonToxic         6                  18\n\nRecall for Toxic class: 0.273  0.091 (=-0.182)\nFalse Negatives (Toxic  NonToxic): 8  10 (=+2)\n\n### XGBoost_D5_N100 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            2                   9\nActual NonToxic         6                  18\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            1                  10\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.182  0.091 (=-0.091)\nFalse Negatives (Toxic  NonToxic): 9  10 (=+1)\n\n### SVM_Linear ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         8                  16\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         8                  16\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### SVM_RBF_C1 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            0                  11\nActual NonToxic         0                  24\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            7                   4\nActual NonToxic        13                  11\n\nRecall for Toxic class: 0.000  0.636 (=+0.636)\nFalse Negatives (Toxic  NonToxic): 11  4 (=-7)\n\n### SVM_RBF_C10 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            2                   9\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.182  0.364 (=+0.182)\nFalse Negatives (Toxic  NonToxic): 9  7 (=-2)\n\n### SVM_Poly_D2 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            0                  11\nActual NonToxic         0                  24\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            8                   3\nActual NonToxic        15                   9\n\nRecall for Toxic class: 0.000  0.727 (=+0.727)\nFalse Negatives (Toxic  NonToxic): 11  3 (=-8)\n\n### SVM_Poly_D3 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            0                  11\nActual NonToxic         0                  24\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic           11                   0\nActual NonToxic        20                   4\n\nRecall for Toxic class: 0.000  1.000 (=+1.000)\nFalse Negatives (Toxic  NonToxic): 11  0 (=-11)\n\n### KNN_K3 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         6                  18\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         6                  18\n\nRecall for Toxic class: 0.455  0.455 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 6  6 (=+0)\n\n### KNN_K5 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         4                  20\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         4                  20\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### KNN_K7 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         4                  20\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         4                  20\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### KNN_K10 ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         5                  19\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         5                  19\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### NN_Small ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         7                  17\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n\n### NN_Medium ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            5                   6\nActual NonToxic         7                  17\n\nRecall for Toxic class: 0.455  0.455 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 6  6 (=+0)\n\n### NN_Large ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            2                   9\nActual NonToxic         7                  17\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            2                   9\nActual NonToxic         7                  17\n\nRecall for Toxic class: 0.182  0.182 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 9  9 (=+0)\n\n### NN_Deep ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         8                  16\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            3                   8\nActual NonToxic         8                  16\n\nRecall for Toxic class: 0.273  0.273 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 8  8 (=+0)\n\n### NN_Adam ###\n\nOriginal (No Class Weights):\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         9                  15\n\nWith Class Weights:\n                Predicted Toxic    Predicted NonToxic\nActual Toxic            4                   7\nActual NonToxic         9                  15\n\nRecall for Toxic class: 0.364  0.364 (=+0.000)\nFalse Negatives (Toxic  NonToxic): 7  7 (=+0)\n","output_type":"stream"}],"execution_count":23},{"id":"a337206f-8f05-4d26-a169-f0d9d540a82d","cell_type":"code","source":"# Save all comparisons\n# comparison.to_csv('class_weight_comparison.csv', index=False)\n# results_df.to_csv('model_results_original.csv', index=False)\n# results_df_weighted.to_csv('model_results_weighted.csv', index=False)\n# print(\"\\n All results saved to CSV files\")\n# print(\"  - model_results_original.csv\")\n# print(\"  - model_results_weighted.csv\")\n# print(\"  - class_weight_comparison.csv\")\n# print(\"  - feature_importance_comparison.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:48:38.351574Z","iopub.execute_input":"2025-11-03T07:48:38.351875Z","iopub.status.idle":"2025-11-03T07:48:38.357530Z","shell.execute_reply.started":"2025-11-03T07:48:38.351852Z","shell.execute_reply":"2025-11-03T07:48:38.356249Z"}},"outputs":[],"execution_count":24},{"id":"8b28b8fd-d752-48dd-b8e4-4fa64481a352","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f3a590b3-a7bf-48a9-a497-69b9a70bed43","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"51947737-d1b0-4686-9342-980c08d8a51a","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}